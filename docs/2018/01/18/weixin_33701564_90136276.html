<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>(TensorFlow)变分自编码器实现 « NotBeCN</title>
  <meta name="description" content="             变分自编码器（VAEs）是学习低维数据表示的强大模型。TensorFlow的分发包提供了一种简单的方法来实现不同类型的VAE。    在这篇文章中，我将引导你完成在MNIST上训练简单VAE的步骤，主要侧重于实战。    1.定义网络：    VAE由三部分组成：编码器q（z | x ）...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2018/01/18/weixin_33701564_90136276.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">(TensorFlow)变分自编码器实现</h1>
    <p class="post-meta">Jan 18, 2018</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="line-height:150%;background:#FDFDFD;">变分自编码器（<span style="font-family:Georgia, serif;">VAEs</span>）是学习低维数据表示的强大模型。<span style="font-family:Georgia, serif;">TensorFlow</span>的分发包提供了一种简单的方法来实现不同类型的<span style="font-family:Georgia, serif;">VAE</span>。</p> 
   <p style="line-height:150%;background:#FDFDFD;">在这篇文章中，我将引导你完成在<span style="font-family:Georgia, serif;">MNIST</span>上训练简单<span style="font-family:Georgia, serif;">VAE</span>的步骤，主要侧重于实战。</p> 
   <p style="line-height:150%;background:#FDFDFD;"><b><span style="font-size:14pt;line-height:150%;">1.</span></b><b><span style="font-size:14pt;line-height:150%;">定义网络：</span></b></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;font-family:Georgia, serif;background:#FDFDFD;">VAE</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">由三部分组成：编码器</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">q</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">（</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">z </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">| </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">x </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">）</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">，先验</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">p</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">（</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">z </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">）</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">，解码器</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">p</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">（</span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">x </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">| </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">z </span><span style="font-size:12pt;line-height:150%;border:none 1pt;background:#FDFDFD;">）</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">。</span></p> 
   <p align="left" style="text-align:center;line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;"><img src="https://yqfile.alicdn.com/8dc1a90339e35707cab9b41c8cd48606c9297823.png" width="400" height="109" alt="8dc1a90339e35707cab9b41c8cd48606c9297823"><br></span></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">编码器将图像映射到针对该图像的代码的分布上。这种分布也被称为<em><span style="font-style:normal;">后验（</span></em></span><em><span style="font-size:12pt;line-height:150%;background:#FDFDFD;font-style:normal;">posterior</span></em><em><span style="font-size:12pt;line-height:150%;background:#FDFDFD;font-style:normal;">）</span></em><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">，因为它反映了我们关于代码应该用于给定图像之后的准确度。</span></p> 
   <p align="left" style="line-height:150%;"></p> 
   <pre><code class="language-python">import tensorflow as tf
tfd = tf.contrib.distributions
def make_encoder(data, code_size):
  x = tf.layers.flatten(data)
  x = tf.layers.dense(x, 200, tf.nn.relu)
  x = tf.layers.dense(x, 200, tf.nn.relu)
  loc = tf.layers.dense(x, code_size)
  scale = tf.layers.dense(x, code_size, tf.nn.softplus)
  return tfd.MultivariateNormalDiag(loc, scale)</code></pre> 
   <p></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">先验（</span><span style="font-size:12pt;line-height:150%;font-family:Georgia, serif;background:#FDFDFD;">prior</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">）是固定的，上面我们还定义了我们期望的代码块分布。这对</span><span style="font-size:12pt;line-height:150%;font-family:Georgia, serif;background:#FDFDFD;">VAE</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">可以使用的代码块提供了一个非常弹性的选择空间。它通常只是一个零均值和单位方差的正态分布。</span></p> 
   <p align="left" style="line-height:150%;"></p> 
   <pre><code class="language-python">def make_prior(code_size):
  loc = tf.zeros(code_size)
  scale = tf.ones(code_size)
  return tfd.MultivariateNormalDiag(loc, scale)</code></pre> 
   <p></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">解码器需要编写一个代码块并将其映射回合理的图像分布。它允许我们重建图像，或为我们选择的任何代码块生成新图像。</span></p> 
   <p align="left" style="line-height:150%;"></p> 
   <pre><code class="language-none">import numpy as np
def make_decoder(code, data_shape):
  x = code
  x = tf.layers.dense(x, 200, tf.nn.relu)
  x = tf.layers.dense(x, 200, tf.nn.relu)
  logit = tf.layers.dense(x, np.prod(data_shape))
  logit = tf.reshape(logit, [-1] + data_shape)
  return tfd.Independent(tfd.Bernoulli(logit), 2)</code></pre> 
   <p></p> 
   <p align="left" style="line-height:150%;background:rgb(253,253,253);"><span style="font-size:12pt;line-height:150%;">在这里，我们对数据使用伯努利分布，将像素建模为二进制值。根据数据的类型和领域，您可能需要以不同的方式对其进行建模，例如再次以正态分布的形式进行建模。</span></p> 
   <p align="left" style="line-height:150%;background:rgb(253,253,253);"><span style="font-size:12pt;line-height:150%;">该</span><span style="font-size:12pt;line-height:150%;">tfd.Independent(..., 2)</span><span style="font-size:12pt;line-height:150%;">告诉</span><span style="font-size:12pt;line-height:150%;">TensorFlow</span><span style="font-size:12pt;line-height:150%;">，内部两个尺寸——（宽度和高度）。在我们的例子中，属于同一个数据点，即使他们有独立的参数。这使我们能够评估分布下图像的概率，而不仅仅是单个像素。</span></p> 
   <p align="left" style="line-height:150%;background:rgb(253,253,253);"><b><span style="font-size:14pt;line-height:150%;">2.</span></b><b><span style="font-size:14pt;line-height:150%;">重新使用模型</span></b></p> 
   <p align="left" style="line-height:150%;background:rgb(253,253,253);"><span style="font-size:12pt;line-height:150%;">我们希望使用解码器网络两次，计算下一节中描述的重构损失，以及一些随机采样的可视化代码块。</span></p> 
   <p align="left" style="line-height:150%;background:rgb(253,253,253);"><span style="font-size:12pt;line-height:150%;">在</span><span style="font-size:12pt;line-height:150%;">TensorFlow</span><span style="font-size:12pt;line-height:150%;">中，如果您调用两次网络功能，它将创建两个独立的网络。</span><span style="font-size:12pt;line-height:150%;">TensorFlow</span><span style="font-size:12pt;line-height:150%;">模板允许您打包一个函数，以便多次调用它将重用相同的网络参数。</span></p> 
   <p align="left" style="line-height:150%;background:rgb(253,253,253);"></p> 
   <pre><code class="language-none">make_encoder = tf.make_template('encoder', make_encoder)
make_decoder = tf.make_template('decoder', make_decoder)
</code></pre> 
   <p></p> 
   <p style="line-height:150%;background:#FDFDFD;">之前没有可训练的参数，所以我们不需要将其包装到模板中。</p> 
   <h2 style="line-height:150%;background:#FDFDFD;"> <span style="font-size:14pt;line-height:150%;">3.</span><span style="font-size:14pt;line-height:150%;">定义损失</span> </h2> 
   <p style="line-height:150%;background:#FDFDFD;">我们希望找到为我们的数据集分配最高可能性的网络参数。然而，数据点的可能性取决于最好的代码块，这点在训练中是我们不知道。</p> 
   <p style="line-height:150%;background:#FDFDFD;">代替的，我们将使用（<span style="font-family:Georgia, serif;">ELBO</span>）对数据可能性进行近似训练。</p> 
   <p style="text-align:center;line-height:150%;background:rgb(253,253,253);"><img src="https://yqfile.alicdn.com/bfe3a7762a7ab65a07a401f317ed936fc4bbd59b.png" width="400" height="32" alt="bfe3a7762a7ab65a07a401f317ed936fc4bbd59b"><br></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">这里的重要细节是，</span><span style="font-size:12pt;line-height:150%;font-family:Georgia, serif;background:#FDFDFD;">ELBO</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">仅使用<em><span style="font-style:normal;">给定我们当前对其代码块的估计的</span></em>数据点的可能性，我们可以对其进行抽样。</span></p> 
   <p align="left" style="line-height:150%;"></p> 
   <pre><code class="language-python">data = tf.placeholder(tf.float32, [None, 28, 28])
prior = make_prior(code_size=2)
posterior = make_encoder(data, code_size=2)
code = posterior.sample()
likelihood = make_decoder(code, [28, 28]).log_prob(data)
divergence = tfd.kl_divergence(posterior, prior)
elbo = tf.reduce_mean(likelihood - divergence)</code></pre> 
   <p></p> 
   <p style="line-height:150%;background:#FDFDFD;">一个直观的解释是，最大化<span style="font-family:Georgia, serif;">ELBO</span>可以最大限度地提供给定当前代码的数据的可能性，同时鼓励代码接近我们先前的代码应该是什么样子的信念。</p> 
   <h2 style="line-height:150%;background:#FDFDFD;"> <span style="font-size:14pt;line-height:150%;">4.</span><span style="font-size:14pt;line-height:150%;">运行训练</span> </h2> 
   <p style="line-height:150%;background:#FDFDFD;">我们使用梯度下降来最大化<span style="font-family:Georgia, serif;">ELBO</span>。这是一个非常可行的方案，因为采样操作是在内部使用重新参数化技巧来实现的，所以<span style="font-family:Georgia, serif;">TensorFlow</span>可以通过它们反向传播。</p> 
   <p style="line-height:150%;background:#FDFDFD;"></p> 
   <pre><code class="language-python">optimize = tf.train.AdamOptimizer(0.001).minimize(-elbo)</code></pre> 
   <p></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">而且，我们从之前的样本中抽取一些随机代码来可视化</span><span style="font-size:12pt;line-height:150%;font-family:Georgia, serif;background:#FDFDFD;">VAE</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">学到的相应图像。这就是上面我们使用</span><code><span style="font-size:12pt;line-height:150%;font-family:'Roboto Mono', serif;">tf.make_template()</span></code><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">的原因</span><span style="font-size:12pt;line-height:150%;font-family:Georgia, serif;background:#FDFDFD;">&nbsp;</span><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">，让我们再次调用解码器网络。<br></span></p> 
   <pre><code class="language-none">samples = make_decoder(prior.sample(10), [28, 28]).mean()</code></pre> 
   <p></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">最后，我们加载数据并</span><a href="https://danijar.com/what-is-a-tensorflow-session/" rel="nofollow"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">创建一个会话</span></a><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">来运行训练：<br></span></p> 
   <pre><code class="language-python">from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data/')
with tf.train.MonitoredSession() as sess:
  for epoch in range(20):
    test_elbo, test_codes, test_samples = sess.run(
        [elbo, code, samples], {data: mnist.test.images})
    print('Epoch', epoch, 'elbo', test_elbo)
    plot_codes(test_codes)
    plot_sample(test_samples)
    for _ in range(600):
      sess.run(optimize, {data: mnist.train.next_batch(100)[0]})</code></pre> 
   <p></p> 
   <p align="left" style="line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">如果你想玩代码，看看</span><a href="https://gist.github.com/danijar/1cb4d81fed37fd06ef60d08c1181f557" rel="nofollow"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">完整的代码示例</span></a><span style="font-size:12pt;line-height:150%;background:#FDFDFD;">，它也包含在这篇文章中其他省略的绘图，以及前几个训练阶段的解码样本。</span></p> 
   <p align="left" style="text-align:center;line-height:150%;"><span style="font-size:12pt;line-height:150%;background:#FDFDFD;"><img src="https://yqfile.alicdn.com/d1b57a079acd47d7bb17088e905fb0ba440def5b.png" width="400" height="188" alt="d1b57a079acd47d7bb17088e905fb0ba440def5b"><br></span></p> 
   <p style="line-height:150%;background:#FDFDFD;">正如你所看到的，潜在的空间很快就会被分成几组不同的数字。如果您为代码块和较大的网络使用更多维度，您还将看到生成的图像变得越来越清晰。</p> 
   <h2 style="line-height:150%;background:#FDFDFD;"> <span style="font-size:14pt;line-height:150%;">5.</span><span style="font-size:14pt;line-height:150%;">结论</span> </h2> 
   <p style="line-height:150%;background:#FDFDFD;">我们已经学会在<span style="font-family:Georgia, serif;">TensorFlow</span>中建立一个<span style="font-family:Georgia, serif;">VAE</span>，并在<span style="font-family:Georgia, serif;">MNIST</span>数字上训练它。下一步，您可以自己运行代码并对其进行扩展，例如使用<span style="font-family:Georgia, serif;">CNN</span>编码器和解码器。</p> 
   <p style="margin-left:0cm;line-height:125%;"><span style="font-size:13.5pt;line-height:125%;">本文由北邮<a href="http://weibo.com/fly51fly?spm=5176.100239.blogcont70733.21.q4e60Y" rel="nofollow">@爱可可-爱生活</a>老师推荐，<a href="http://weibo.com/taobaodeveloperclub?spm=5176.100239.blogcont70733.22.q4e60Y" rel="nofollow">阿里云云栖社区</a>组织翻译。</span></p> 
   <p style="line-height:125%;background:#FFFFFF;vertical-align:baseline;"><span style="font-size:13.5pt;line-height:125%;">文章原标题《building-variational-auto-encoders-in-tensorflow》，</span></p> 
   <h2 style="margin-left:0cm;line-height:125%;background:#FDFDFD;"> <span style="font-size:13.5pt;line-height:125%;font-weight:normal;">作者：</span><span style="font-size:12pt;line-height:125%;font-weight:normal;">Danijar Hafner</span><span style="font-size:12pt;line-height:125%;font-weight:normal;">：</span><span style="font-size:12pt;line-height:125%;font-weight:normal;">旨在建立基于人脑概念的智能机器的研究人员</span> </h2> 
   <p style="margin-left:0cm;line-height:125%;"><span style="font-size:13.5pt;line-height:125%;">译者：虎说八道，审阅：</span></p> 
   <p style="line-height:125%;"><span style="font-size:13.5pt;line-height:125%;color:#2E75B6;">文章为简译，更为详细的内容，请查看</span><span style="font-size:13.5pt;line-height:125%;color:#4F81BD;"><a href="https://danijar.com/building-variational-auto-encoders-in-tensorflow/" rel="nofollow">原文</a></span></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
