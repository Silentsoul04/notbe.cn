<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>kafka官方文档学习笔记2--QuickStart « NotBeCN</title>
  <meta name="description" content="             下载kafka    https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz    解压安装包    &gt; tar -xzf kafka_2.11-1.0.0.tgz&gt; cd ka...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2018/01/17/weixin_33805992_90123270.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">kafka官方文档学习笔记2--QuickStart</h1>
    <p class="post-meta">Jan 17, 2018</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <h3>下载kafka</h3> 
   <p><a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz" rel="nofollow">https://www.apache.org/dyn/closer.cgi?path=/kafka/1.0.0/kafka_2.11-1.0.0.tgz</a></p> 
   <h3>解压安装包</h3> 
   <pre><code class="bash">&gt; tar -xzf kafka_2.11-1.0.0.tgz
&gt; cd kafka_2.11-1.0.0/bin</code></pre> 
   <p>查看bin目录下主要几个脚本功能如下：</p> 
   <table>
    <thead>
     <tr>
      <th>脚本</th> 
      <th>功能</th> 
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>kafka-server-start.sh</td> 
      <td>启动kafka服务器；</td> 
     </tr>
     <tr>
      <td>kafka-server-stop.sh</td> 
      <td>停止kafka服务器；</td> 
     </tr>
     <tr>
      <td>kafka-topics.sh</td> 
      <td>topic管理；</td> 
     </tr>
     <tr>
      <td>kafka-console-producer.sh</td> 
      <td>基于命令行的生产者；</td> 
     </tr>
     <tr>
      <td>kafka-console-consumer.sh</td> 
      <td>基于命令行的消费者；</td> 
     </tr>
     <tr>
      <td>kafka-run-class.sh</td> 
      <td>运行java类的脚本，由kafka-server-start.sh和kafka-server-stop.sh、kafka-topics.sh等脚本调用；</td> 
     </tr>
     <tr>
      <td>zookeeper-server-start.sh</td> 
      <td>启动kafka自带的zookeeper服务器；</td> 
     </tr>
     <tr>
      <td>zookeeper-server-stop.sh</td> 
      <td>停止kafka自带的zookeeper服务器；</td> 
     </tr>
     <tr>
      <td>zookeeper-shell.sh</td> 
      <td>在命令行连接zookeeper的客户端工具；</td> 
     </tr>
     <tr>
      <td>connect-standalone.sh</td> 
      <td>在命令行启动单点的connector；</td> 
     </tr>
     <tr>
      <td>connect-distributed.sh</td> 
      <td>在命令行启动基于集群connector；</td> 
     </tr>
    </tbody>
   </table>
   <blockquote>
    <p>注：kafka的安装包除了包括kafka自身的工具以外，也包括了一系列简易的zookeeper工具，能够通过zookeeper-server-start.sh脚本启动简易的单点zookeeper实例，供kafka使用。但一般仅限于测试环境使用；</p>
   </blockquote> 
   <p>config目录下存放的是kafka服务、自带zk服务以及基于命令行的生产者、消费者工具对应的配置文件，常用如下：</p> 
   <table>
    <thead>
     <tr>
      <th>脚本</th> 
      <th>功能</th> 
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>server.properties</td> 
      <td>kafka实例的配置文件，配置kafka最重要的配置文件；</td> 
     </tr>
     <tr>
      <td>log4j.properties</td> 
      <td>kafka日志配置；</td> 
     </tr>
     <tr>
      <td>zookeeper.properties</td> 
      <td>自带zk的配置文件；</td> 
     </tr>
     <tr>
      <td>producer.properties</td> 
      <td>基于命令行的生产者工具配置文件；（测试用）</td> 
     </tr>
     <tr>
      <td>consumer.properties</td> 
      <td>基于命令行的消费者工具配置文件；（测试用）</td> 
     </tr>
     <tr>
      <td>connect-standalone.properties</td> 
      <td>自带单点connector的配置文件，存放connector的序列化方式、监听broker的地址端口等通用配置；（测试用）</td> 
     </tr>
     <tr>
      <td>connect-file-source.properties</td> 
      <td>配置文件读取connector，用于逐行读取文件，导入入topic；（测试用）</td> 
     </tr>
     <tr>
      <td>connect-file-sink.properties</td> 
      <td>配置文件写入connector，用于将topic中的数据导出到topic中；（测试用）</td> 
     </tr>
    </tbody>
   </table>
   <h3>启动zk服务，默认端口：2181</h3> 
   <pre><code class="bash">&gt; bin/zookeeper-server-start.sh config/zookeeper.properties
[2018-01-16 20:22:52,327] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...</code></pre> 
   <h3>启动kafka服务，默认端口：9092</h3> 
   <pre><code class="bash">&gt; bin/kafka-server-start.sh config/server.properties
[2018-01-16 20:23:52,758] INFO KafkaConfig values:
...</code></pre> 
   <p>经过如上两步，我们就启动了一个简易的kafka集群（具有1个zookeeper实例和1个kafka实例的集群）</p> 
   <h3>查看zookeeper中存放的kafka信息</h3> 
   <pre><code class="bash">&gt; bin/zookeeper-shell.sh localhost:2181
Connecting to localhost:2181
Welcome to ZooKeeper!
JLine support is disabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
ls /
[cluster, controller, controller_epoch, brokers, zookeeper, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]
ls /brokers
[ids, topics, seqid]
ls /brokers/topics
[test]
ls /brokers/ids
[0]</code></pre> 
   <blockquote>
    <p>"ls /"命令列出了zk根节点下的所有元素，可以看到kafka在zk中存放了集群（cluster）、实例（brokers）、消费者（consumers）等信息；zookeeper服务作为kafka的元数据管理服务，因而每次对kafka服务操作都需要指定zookeeper服务的地址，以便于获取kafka的元数据，连接到正确的kafka集群；</p>
   </blockquote> 
   <h3>创建topic</h3> 
   <pre><code class="bash">&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
Created topic "test".</code></pre> 
   <p>创建一个名为test的topic，包含1个复本，1个分区；</p> 
   <h3>查看集群中的所有topic</h3> 
   <pre><code class="bash">&gt; bin/kafka-topics.sh --list --zookeeper localhost:2181
test</code></pre> 
   <h3>启动生产者，并写入测试消息</h3> 
   <pre><code class="bash">&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
&gt; Hello World1
&gt; I'm a programer</code></pre> 
   <h3>启动消费者，接收消息</h3> 
   <pre><code class="bash">&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
Hello World1
I'm a programer</code></pre> 
   <blockquote>
    <p>可以看到生产者写入的消息，都能够立刻被消费者接收并打印出来。需要注意的是，生产者和消费者通过topic这个概念来建立联系，只有消费者指定与生产者相同的topic，才能够消费其产生的消费；</p>
   </blockquote> 
   <h3>删除topic</h3> 
   <pre><code class="bash">&gt; bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test
Topic test is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
</code></pre> 
   <h3>建立多个kafka实例的集群</h3> 
   <p>拷贝配置文件，修改实例ID、日志目录、监听端口：</p> 
   <pre><code class="bash">&gt; cp config/server.properties config/server-1.properties
&gt; cp config/server.properties config/server-2.properties</code></pre> 
   <p>修改配置项如下：</p> 
   <pre><code class="properties">config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dir=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dir=/tmp/kafka-logs-2</code></pre> 
   <p>启动实例：</p> 
   <pre><code class="bash">&gt; bin/kafka-server-start.sh config/server-1.properties &amp;
...
&gt; bin/kafka-server-start.sh config/server-2.properties &amp;
...</code></pre> 
   <p>新建topic</p> 
   <pre><code class="bash">&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
Created topic "my-replicated-topic".</code></pre> 
   <p>新建一个名为my-replicated-topic的topic，有3个副本和1个分区；</p> 
   <h3>查看topic状态描述</h3> 
   <pre><code class="bash">&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic    PartitionCount:1    ReplicationFactor:3    Configs:
    Topic: my-replicated-topic    Partition: 0    Leader: 0    Replicas: 0,1,2    Isr: 0,1,2</code></pre> 
   <p>topic上有几个partition，就会展示几行记录；字段含义如下：</p> 
   <ul>
    <li>leader：标识当前partition的leader节点是那个，通过broker.id标识；一个partition只有一个leader节点，负责接收和处理读写请求；</li> 
    <li>replicas：标识当前partition的所有副本所在的节点，无论节点是否是leader节点，也无论节点是否"存活"，通过broker.id标识；</li> 
    <li>isr：标识存活且与leader节点同步的节点，即可用的副本（包括leader借点）；通过broker.id标识；</li> 
   </ul>
   <p>查看最初创建的test状态描述：</p> 
   <pre><code class="bash">&gt;  bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test
Topic:test    PartitionCount:1    ReplicationFactor:1    Configs:
    Topic: test    Partition: 0    Leader: 0    Replicas: 0    Isr: 0</code></pre> 
   <p>可以看到，因为test只有1个副本、1个partition，所以只能分布在一个实例上；</p> 
   <h3>模拟leader切换</h3> 
   <p>对于包含多个副本的topic而言，当一个副本所在的实例不可用时，将会从其它可用副本中选择一个作为leader；<br>在集群节点都正常的情况下，查看topic的状态：</p> 
   <pre><code class="bash">&gt;  bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic    PartitionCount:1    ReplicationFactor:3    Configs:
    Topic: my-replicated-topic    Partition: 0    Leader: 0    Replicas: 0,1,2    Isr: 0,1,2</code></pre> 
   <p>关掉broker.id=0的实例，再次查看，发现leader节点已经切换，同时isr中不包含"不可用"节点0：</p> 
   <pre><code class="bash">&gt;  bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic    PartitionCount:1    ReplicationFactor:3    Configs:
    Topic: my-replicated-topic    Partition: 0    Leader: 1    Replicas: 0,1,2    Isr: 1,2</code></pre> 
   <p>重新启动broker.id=0的实例，再次查看，发现isr中包括了节点0，说明可用。</p> 
   <h3>使用kafka connect导入/导出数据</h3> 
   <p>kafka connect是kafka与外部系统交互的工具，通过运行不同的connector，实现与不同外部系统的交互，包括数据的导入/导出。如下模拟从文件导入数据到kafka，以及从kafka导出数据到文件；</p> 
   <ol>
    <li>首先，创建文件，写入测试数据：</li>
   </ol>
   <pre><code class="bash">&gt; cd kafka_2.11-1.0.0
&gt; echo "Hello World" &gt; test.txt</code></pre> 
   <blockquote>
    <p>注：一定是在kafka根目录中创建名为test.txt的文件，否则不会读取；</p>
   </blockquote> 
   <p>2.启动2个单点的connector，这两个connector都是kafka自带的，一个用于读取文件写入topic，另一个用于将topic中数据导出到文件；</p> 
   <pre><code class="bash">&gt; bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
[2018-01-17 10:37:32,568] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:65)</code></pre> 
   <p>connect-console-source.properties文件内容：</p> 
   <pre><code class="bash">name=local-console-source
# connector入口
connector.class=org.apache.kafka.connect.file.FileStreamSourceConnector
tasks.max=1
# connector关联的topic
topic=connect-test</code></pre> 
   <p>connect-console-sink.properties文件内容：</p> 
   <pre><code class="bash">name=local-console-sink
# connector入口
connector.class=org.apache.kafka.connect.file.FileStreamSinkConnector
tasks.max=1
# connector关联的topic
topics=connect-test</code></pre> 
   <p>在kafka根目录可以看到生成了名为test.sink.txt的文件，其中的内容即为test.txt中的内容，持续向test.txt中append内容，test.sink.txt中的内容也随之append；</p> 
   <blockquote>
    <p>注：因为同步过程是监听文件的增量变化，如果改变test.txt中旧有内容，则旧数据不发生变化，覆盖同一行旧数据，貌似会产生一个空行；</p>
   </blockquote> 
   <p>整个同步过程是：</p> 
   <pre><code class="bash">test.txt -&gt;   FileStreamSourceConnector -&gt; connect-test（topic） -&gt; FileStreamSinkConnector -&gt; test.sink.txt</code></pre> 
   <p>由于是通过topic存放过往数据，因此在topic中也可以看到相应的数据：</p> 
   <pre><code class="bash">&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
{"schema":{"type":"string","optional":false},"payload":"Hello World"}
{"schema":{"type":"string","optional":false},"payload":""}
{"schema":{"type":"string","optional":false},"payload":"Hello World1"}
{"schema":{"type":"string","optional":false},"payload":"Hello World2"}</code></pre> 
   <h3>使用kafka stream处理数据</h3> 
   <p>参考官方文档：<a href="http://kafka.apache.org/10/documentation/streams/quickstart" rel="nofollow">http://kafka.apache.org/10/documentation/streams/quickstart</a></p> 
   <h3>kafka生态</h3> 
   <p>kafka周边包含很多组件，参看wiki：<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem" rel="nofollow">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
