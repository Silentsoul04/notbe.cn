<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Spark通过YARN提交任务不成功（包含YARN cluster和YARN client) « NotBeCN</title>
  <meta name="description" content="             　无论用YARN cluster和YARN client来跑，均会出现如下问题。        &nbsp;                       [spark@master spark-1.6.1-bin-hadoop2.6]$ jps2049 NameNode2706 Jps2...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/28/weixin_33857679_90123576.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">Spark通过YARN提交任务不成功（包含YARN cluster和YARN client)</h1>
    <p class="post-meta">Nov 28, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　无论用YARN cluster和YARN client来跑，均会出现如下问题。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201703/855959-20170330123916842-470568093.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="font-size:12px;line-height:1.5;"><a title="复制代码" style="border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>[spark@master spark-1.6.1-bin-hadoop2.6<span style="font-size:12px;line-height:1.5;">]$ jps
</span>2049<span style="font-size:12px;line-height:1.5;"> NameNode
</span>2706<span style="font-size:12px;line-height:1.5;"> Jps
</span>2372<span style="font-size:12px;line-height:1.5;"> ResourceManager
</span>2660<span style="font-size:12px;line-height:1.5;"> Master
</span>2203<span style="font-size:12px;line-height:1.5;"> SecondaryNameNode
[spark@master spark</span>-1.6.1-bin-hadoop2.6]$ $SPARK_HOME/bin/spark-<span style="font-size:12px;line-height:1.5;">submit \
</span>&gt;  <strong><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">--master yarn\ </span></strong>&gt;  <strong><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">--deploy-mode client \ </span></strong>&gt;  --<span style="font-size:12px;line-height:1.5;">name javawordcount \
</span>&gt;  --num-executors 1<span style="font-size:12px;line-height:1.5;"> \
</span>&gt;  --driver-<span style="font-size:12px;line-height:1.5;">memory 512m \
</span>&gt;  --executor-<span style="font-size:12px;line-height:1.5;">memory 512m \
</span>&gt;  --executor-cores 1<span style="font-size:12px;line-height:1.5;"> \
</span>&gt;  --<span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">class</span><span style="font-size:12px;line-height:1.5;"> zhouls.bigdata.MyJavaWordCount \
</span>&gt;  /home/spark/testspark/mySpark-1.0-<span style="font-size:12px;line-height:1.5;">SNAPSHOT.jar \
</span>&gt;  hdfs:<span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">master:9000/testspark/inputData/wordcount/wc.txt \</span>
&gt;  hdfs:<span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">master:9000/testspark/outData/MyJavaWordCount</span>
17/03/30 20:36:57 INFO spark.SparkContext: Running Spark version 1.6.1
17/03/30 20:36:58 WARN util.NativeCodeLoader: Unable to load <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">native</span>-hadoop library <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">for</span> your platform... using builtin-<span style="font-size:12px;line-height:1.5;">java classes where applicable
</span>17/03/30 20:36:59<span style="font-size:12px;line-height:1.5;"> INFO spark.SecurityManager: Changing view acls to: spark
</span>17/03/30 20:36:59<span style="font-size:12px;line-height:1.5;"> INFO spark.SecurityManager: Changing modify acls to: spark
</span>17/03/30 20:36:59<span style="font-size:12px;line-height:1.5;"> INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)
</span>17/03/30 20:37:01 INFO util.Utils: Successfully started service 'sparkDriver' on port 54074<span style="font-size:12px;line-height:1.5;">.
</span>17/03/30 20:37:03<span style="font-size:12px;line-height:1.5;"> INFO slf4j.Slf4jLogger: Slf4jLogger started
</span>17/03/30 20:37:03<span style="font-size:12px;line-height:1.5;"> INFO Remoting: Starting remoting
</span>17/03/30 20:37:04 INFO Remoting: Remoting started; listening on addresses :[akka.tcp:<span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">sparkDriverActorSystem@192.168.80.10:52224]</span>
17/03/30 20:37:04 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 52224<span style="font-size:12px;line-height:1.5;">.
</span>17/03/30 20:37:04<span style="font-size:12px;line-height:1.5;"> INFO spark.SparkEnv: Registering MapOutputTracker
</span>17/03/30 20:37:04<span style="font-size:12px;line-height:1.5;"> INFO spark.SparkEnv: Registering BlockManagerMaster
</span>17/03/30 20:37:04 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-b6575213-cc8e-4a50-bc83-<span style="font-size:12px;line-height:1.5;">6ab089a65341
</span>17/03/30 20:37:04 INFO storage.MemoryStore: MemoryStore started with capacity 146.2<span style="font-size:12px;line-height:1.5;"> MB
</span>17/03/30 20:37:05 INFO spark.SparkEnv: Registering OutputCommitCoordinator<br>
17/03/30 20:37:06 INFO server.Server: jetty-8.y.z-SNAPSHOT<br>
17/03/30 20:37:06 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040<br>
17/03/30 20:37:06 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.<br>
17/03/30 20:37:06 INFO ui.SparkUI: Started SparkUI at http://192.168.80.10:4040<br>
17/03/30 20:37:06 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-fdfdb880-f6cf-47eb-8981-1176e657d466/httpd-f5d25b97-30bd-4f13-b925-d96026063a63<br>
17/03/30 20:37:06 INFO spark.HttpServer: Starting HTTP Server<br>
17/03/30 20:37:06 INFO server.Server: jetty-8.y.z-SNAPSHOT<br>
17/03/30 20:37:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54651<br>
17/03/30 20:37:06 INFO util.Utils: Successfully started service 'HTTP file server' on port 54651.<br>
17/03/30 20:37:07 INFO spark.SparkContext: Added JAR file:/home/spark/testspark/mySpark-1.0-SNAPSHOT.jar at http://192.168.80.10:54651/jars/mySpark-1.0-SNAPSHOT.jar with timestamp 1490877427613<br>
17/03/30 20:37:08 INFO client.RMProxy: Connecting to ResourceManager at master/192.168.80.10:8032<br>
17/03/30 20:37:09 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers<br>
17/03/30 20:37:09 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)<br>
17/03/30 20:37:09 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead<br>
17/03/30 20:37:09 INFO yarn.Client: Setting up container launch context for our AM<br>
17/03/30 20:37:09 INFO yarn.Client: Setting up the launch environment for our AM container<br>
17/03/30 20:37:09 INFO yarn.Client: Preparing resources for our AM container<br>
17/03/30 20:37:14 INFO yarn.Client: Uploading resource file:/usr/local/spark/spark-1.6.1-bin-hadoop2.6/lib/spark-assembly-1.6.1-hadoop2.6.0.jar -&gt; hdfs://master:9000/user/spark/.sparkStaging/application_1490877371054_0001/spark-assembly-1.6.1-hadoop2.6.0.jar<br>
17/03/30 20:37:36 INFO yarn.Client: Uploading resource file:/tmp/spark-fdfdb880-f6cf-47eb-8981-1176e657d466/__spark_conf__3748671039525906996.zip -&gt; hdfs://master:9000/user/spark/.sparkStaging/application_1490877371054_0001/__spark_conf__3748671039525906996.zip<br>
17/03/30 20:37:38 INFO spark.SecurityManager: Changing view acls to: spark<br>
17/03/30 20:37:38 INFO spark.SecurityManager: Changing modify acls to: spark<br>
17/03/30 20:37:38 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(spark); users with modify permissions: Set(spark)<br>
17/03/30 20:37:38 INFO yarn.Client: Submitting application 1 to ResourceManager<br>
17/03/30 20:37:39 INFO impl.YarnClientImpl: Submitted application application_1490877371054_0001<br>
17/03/30 20:37:40 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:40 INFO yarn.Client: <br>
&nbsp;&nbsp; &nbsp; client token: N/A&nbsp;&nbsp; &nbsp; client token: N/A<br>
&nbsp;&nbsp; &nbsp; diagnostics: N/A<br>
&nbsp;&nbsp; &nbsp; ApplicationMaster host: N/A<br>
&nbsp;&nbsp; &nbsp; ApplicationMaster RPC port: -1<br>
&nbsp;&nbsp; &nbsp; queue: default<br>
&nbsp;&nbsp; &nbsp; start time: 1490877458881<br>
&nbsp;&nbsp; &nbsp; final status: UNDEFINED<br>
&nbsp;&nbsp; &nbsp; tracking URL: http://master:8088/proxy/application_1490877371054_0001/<br>
&nbsp;&nbsp; &nbsp; user: spark<br>
17/03/30 20:37:41 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:42 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:43 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:44 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:45 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:46 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:47 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:48 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:49 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:50 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:51 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:52 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:53 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:54 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:55 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:56 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:57 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:58 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:37:59 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:00 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:01 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:02 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:03 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:04 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:05 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:06 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:07 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:08 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:09 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:10 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:12 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:13 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:14 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:15 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:16 INFO yarn.Client: Application report for application_1490877371054_0001 (state: ACCEPTED)<br>
17/03/30 20:38:17 INFO yarn.Client: Application report for application_1490877371054_0001 (state: FAILED)<br>
17/03/30 20:38:17 INFO yarn.Client: <br>
&nbsp;&nbsp; &nbsp; client token: N/A<br>
&nbsp;&nbsp; &nbsp; diagnostics: Application application_1490877371054_0001 failed 2 times due to AM Container for appattempt_1490877371054_0001_000002 exited with&nbsp; exitCode: -103<br>
For more detailed output, check application tracking page:http://master:8088/proxy/application_1490877371054_0001/Then, click on links to logs of each attempt.<br>
Diagnostics: Container [pid=2417,containerID=container_1490877371054_0001_02_000001] is running beyond virtual memory limits. Current usage: 79.2 MB of 1 GB physical memory used; 2.2 GB of 2.1 GB virtual memory used. Killing container.<br>
Dump of the process-tree for container_1490877371054_0001_02_000001 :<br>
&nbsp;&nbsp; &nbsp;|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE<br>
&nbsp;&nbsp; &nbsp;|- 2421 2417 2417 2417 (java) 283 147 2256482304 19967 /usr/local/jdk/jdk1.8.0_60/bin/java -server -Xmx512m -Djava.io.tmpdir=/usr/local/hadoop/hadoop-2.6.0/tmp/nm-local-dir/usercache/spark/appcache/application_1490877371054_0001/container_1490877371054_0001_02_000001/tmp -Dspark.yarn.app.container.log.dir=/usr/local/hadoop/hadoop-2.6.0/logs/userlogs/application_1490877371054_0001/container_1490877371054_0001_02_000001 org.apache.spark.deploy.yarn.ExecutorLauncher --arg 192.168.80.10:54074 --executor-memory 512m --executor-cores 1 --properties-file /usr/local/hadoop/hadoop-2.6.0/tmp/nm-local-dir/usercache/spark/appcache/application_1490877371054_0001/container_1490877371054_0001_02_000001/__spark_conf__/__spark_conf__.properties <br>
&nbsp;&nbsp; &nbsp;|- 2417 2415 2417 2417 (bash) 0 1 108650496 305 /bin/bash -c /usr/local/jdk/jdk1.8.0_60/bin/java -server -Xmx512m -Djava.io.tmpdir=/usr/local/hadoop/hadoop-2.6.0/tmp/nm-local-dir/usercache/spark/appcache/application_1490877371054_0001/container_1490877371054_0001_02_000001/tmp -Dspark.yarn.app.container.log.dir=/usr/local/hadoop/hadoop-2.6.0/logs/userlogs/application_1490877371054_0001/container_1490877371054_0001_02_000001 org.apache.spark.deploy.yarn.ExecutorLauncher --arg '192.168.80.10:54074' --executor-memory 512m --executor-cores 1 --properties-file /usr/local/hadoop/hadoop-2.6.0/tmp/nm-local-dir/usercache/spark/appcache/application_1490877371054_0001/container_1490877371054_0001_02_000001/__spark_conf__/__spark_conf__.properties 1&gt; /usr/local/hadoop/hadoop-2.6.0/logs/userlogs/application_1490877371054_0001/container_1490877371054_0001_02_000001/stdout 2&gt; /usr/local/hadoop/hadoop-2.6.0/logs/userlogs/application_1490877371054_0001/container_1490877371054_0001_02_000001/stderr <br><br>
Container killed on request. Exit code is 143<br>
Container exited with a non-zero exit code 143<br>
Failing this attempt. Failing the application.<br>
&nbsp;&nbsp; &nbsp; ApplicationMaster host: N/A<br>
&nbsp;&nbsp; &nbsp; ApplicationMaster RPC port: -1<br>
&nbsp;&nbsp; &nbsp; queue: default<br>
&nbsp;&nbsp; &nbsp; start time: 1490877458881<br>
&nbsp;&nbsp; &nbsp; final status: FAILED<br>
&nbsp;&nbsp; &nbsp; tracking URL: http://master:8088/cluster/app/application_1490877371054_0001<br>
&nbsp;&nbsp; &nbsp; user: spark<br>
17/03/30 20:38:17 INFO yarn.Client: Deleting staging directory .sparkStaging/application_1490877371054_0001<br>
17/03/30 20:38:17 ERROR spark.SparkContext: Error initializing SparkContext.<br>
org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:124)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:64)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:530)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:59)<br>
&nbsp;&nbsp; &nbsp;at zhouls.bigdata.MyJavaWordCount.main(MyJavaWordCount.java:31)<br>
&nbsp;&nbsp; &nbsp;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br>
&nbsp;&nbsp; &nbsp;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br>
&nbsp;&nbsp; &nbsp;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br>
&nbsp;&nbsp; &nbsp;at java.lang.reflect.Method.invoke(Method.java:497)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}<br>
17/03/30 20:38:17 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}<br>
17/03/30 20:38:17 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.80.10:4040<br>
17/03/30 20:38:17 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors<br>
17/03/30 20:38:17 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down<br>
17/03/30 20:38:17 INFO cluster.YarnClientSchedulerBackend: Stopped<br>
17/03/30 20:38:17 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!<br>
17/03/30 20:38:17 INFO storage.MemoryStore: MemoryStore cleared<br>
17/03/30 20:38:17 INFO storage.BlockManager: BlockManager stopped<br>
17/03/30 20:38:17 INFO storage.BlockManagerMaster: BlockManagerMaster stopped<br>
17/03/30 20:38:17 WARN metrics.MetricsSystem: Stopping a MetricsSystem that is not running<br>
17/03/30 20:38:17 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!<br>
17/03/30 20:38:17 INFO spark.SparkContext: Successfully stopped SparkContext<br>
Exception in thread "main" org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:124)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:64)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:144)<br>
&nbsp;&nbsp;&nbsp; at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:530)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:59)<br>
&nbsp;&nbsp; &nbsp;at zhouls.bigdata.MyJavaWordCount.main(MyJavaWordCount.java:31)<br>
&nbsp;&nbsp; &nbsp;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br>
&nbsp;&nbsp; &nbsp;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br>
&nbsp;&nbsp; &nbsp;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br>
&nbsp;&nbsp; &nbsp;at java.lang.reflect.Method.invoke(Method.java:497)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)<br>
&nbsp;&nbsp; &nbsp;at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)<br>
17/03/30 20:38:17 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.<br>
17/03/30 20:38:18 INFO util.ShutdownHookManager: Shutdown hook called<br>
17/03/30 20:38:18 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.<br>
17/03/30 20:38:18 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-fdfdb880-f6cf-47eb-8981-1176e657d466<br>
17/03/30 20:38:18 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-fdfdb880-f6cf-47eb-8981-1176e657d466/httpd-f5d25b97-30bd-4f13-b925-d96026063a63<br>
[spark@master spark-1.6.1-bin-hadoop2.6] </pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="font-size:12px;line-height:1.5;"><a title="复制代码" style="border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201703/855959-20170330123934467-255087515.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201703/855959-20170330123944826-1271621764.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-size:18pt;">解决思路</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　第一种解决版本：首先想到是集群中内存资源不足，可以检查下每台机器是否有足够剩余内存( free -g)；也可能是其他已经提交的Spark应用占了大部分资源；</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　第二种解决办法：如果1&gt;正常，我们可以看看YARN集群是否启动成功。注意“坑”可能就在这里： 即使Slave上的nodemanager进程存在，要注意检查resource manager日志，看看各个node manager是否启动成功，我的问题就出现在这里：进程在，但是日志显示node manager状态为UNHEALTHY，所以YARN集群能识别到的总内存资源为0。。。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　检查了UNHEALTHY的原因，是因为/tmp下一个目录被识别为bad, 因为是临时目录，我把每个node manager的对应目录删掉，然后重启YARN集群，最终问题解决。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br></p> 
   <p><font><span style="font-size:14px;">本文转自大数据躺过的坑博客园博客，原文链接：http://www.cnblogs.com/zlslch/p/6645549.html，如需转载请自行联系原作者</span></font><br></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
