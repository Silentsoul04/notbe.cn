<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>高斯混合模型GMM的C++实现 « NotBeCN</title>
  <meta name="description" content="             单高斯分布模型SGM    高斯密度函数估计是一种参数化模型。有单高斯模型（Single Gaussian Model, SGM）和高斯混合模型（Gaussian mixture model，GMM）两类。类似于聚类，根据高斯概率密度函数（PDF，见公式1）参数的不同，每一个高斯模型可以...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/14/weixin_34060741_90123336.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">高斯混合模型GMM的C++实现</h1>
    <p class="post-meta">Nov 14, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <h3 style="font-size:16px;line-height:1.5;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">单高斯分布模型SGM</h3> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">高斯密度函数估计是一种参数化模型。有单高斯模型（Single Gaussian Model, SGM）和高斯混合模型（Gaussian mixture model，GMM）两类。类似于聚类，根据高斯概率密度函数（PDF，见公式1）参数的不同，每一个高斯模型可以看作一种类别，输入一个样本x，即可通过PDF计算其值，然后通过一个阈值来判断该样本是否属于高斯模型。很明显，SGM适合于仅有两类别问题的划分，而GMM由于具有多个模型，划分更为精细，适用于多类别的划分，可以应用于复杂对象建模。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">多维变量X服从高斯分布时，它的概率密度函数PDF为：</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10162850-ccfc9c965ef64c06ae009aac26842eab.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">x是维度为d的列向量，u是模型期望，Σ是模型方差。在实际应用中u通常用样本均值来代替，Σ通常用样本方差来代替。很容易判断一个样x本是否属于类别C。因为每个类别都有自己的u和Σ，把x代入（1）式，当概率大于一定阈值时我们就认为x属于C类。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">从几何上讲，单高斯分布模型在二维空间应该近似于椭圆，在三维空间上近似于椭球。遗憾的是在很多分类问题中，属于同一类别的样本点并不满足“椭圆”分布的特性。这就引入了高斯混合模型。</p> 
   <h3 style="font-size:16px;line-height:1.5;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">高斯混合模型GMM</h3> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">高斯混合模型是单一高斯机率密度函数的延伸，由于&nbsp;GMM 能够平滑地近似任意形状的密度分布，因此近年来常被用在语音、图像识别等方面，得到不错的效果。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">GMM认为数据是从几个SGM中生成出来的，即</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10163211-02f08e212f17463c8683e1073618c4ce.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">K需要事先确定好，就像K-means中的K一样。π<sub><span style="font-size:12px;">k</span></sub>是权值因子。其中的任意一个高斯分布N(x;u<sub><span style="font-size:12px;">k</span></sub>,Σ<sub><span style="font-size:12px;">k</span></sub>)叫作这个模型的一个component。这里有个问题，为什么我们要假设数据是由若干个高斯分布组合而成的，而不假设是其他分布呢？实际上不管是什么分布，只K取得足够大，这个XX Mixture Model就会变得足够复杂，就可以用来逼近任意连续的概率密度分布，只是因为高斯函数具有良好的计算性能，所GMM被广泛地应用。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><span>GMM是一种聚类算法，每个component就是一个聚类中心</span>。即在只有样本点，不知道样本分类（含有隐含变量）的情况下，计算出模型参数（π，u和Σ），这可以用EM算法来求解。再用训练好的模型去差别样本所属的分类，方法是：step1随机选择K个component中的一个（被选中的概率是π<sub><span style="font-size:12px;">k</span></sub>）；step2把样本代入刚选好的component，判断是否属于这个类别，如果不属于则回到step1。</p> 
   <h3 style="font-size:16px;line-height:1.5;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">样本分类已知情况下的GMM</h3> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">当每个样本所属分类已知时，GMM的参数非常好确定，直接利用<span>Maximum Likelihood。设样本容量为N，属于K个分类的样本数量分别是N<sub><span style="font-size:12px;">1</span></sub>,N<sub><span style="font-size:12px;">2</span></sub>,...,N<sub><span style="font-size:12px;">k，</span></sub>属于第k个分类的样本集合是L(k)。<br></span></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10163758-e2a8f0b87cd443e9870cc392e0a191a6.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10163824-2206f6f4114a4193af5b509470f41d07.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10163850-87df975ebea1440ab2a5a1f66bab1ad2.x-png" alt="" style="border:none;"></p> 
   <h3 style="font-size:16px;line-height:1.5;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">样本分类未知情况下的GMM</h3> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">有N个数据点，服从某种分布Pr(x;θ)，我们想找到一组参数θ，使得生成这些数据点的概率最大，这个概率就是</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10164005-8fb3143e9ccf40bd9fd914d6d7d551e0.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">称为似然函数（Lilelihood Function）。通常单个点的概率很小，连乘之后数据会更小，容易造成浮点数下溢，所以一般取其对数，变成</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10164055-d687140fac8a4ccbbf2e94893589d435.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">称为log-likelihood function。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">GMM的log-likelihood function就是：</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10164159-022b5c4c123646f38a6f7c3206c82f4c.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">这里每个样本x<sub><span style="font-size:12px;">i</span></sub>所属的类别z<sub><span style="font-size:12px;">k</span></sub>是不知道的。Z是隐含变量。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">我们就是要找到最佳的模型参数，使得(6)式所示的期望最大，“期望最大化算法”名字由此而来。</p> 
   <h3 style="font-size:16px;line-height:1.5;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">EM估计GMM参数</h3> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">1）初始值：</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">方案1：协方差矩阵Σ<sub><span style="font-size:12px;">k</span></sub>设为单位矩阵，每个模型比例的先验概率π<sub><span style="font-size:12px;">k</span></sub><span style="font-size:12px;">=1/N，</span>均值u<sub><span style="font-size:12px;">k</span></sub>设为随机数。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">方案2：由k均值（k-means）聚类算法对样本进行聚类，利用各类的均值作为u<sub><span style="font-size:12px;">k</span></sub>，并计算Σ<sub><span style="font-size:12px;">k</span></sub><span style="font-size:12px;">，π<sub><span style="font-size:12px;">k</span></sub></span>取各类样本占样本总数的比例。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">2）EM算法：</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><span>E-Step</span>&nbsp;E就是Expectation的意思，就是假设模型参数已知的情况下求隐含变量Z分别取z<sub><span style="font-size:12px;">1</span></sub>,z<sub><span style="font-size:12px;">2</span></sub>,...的期望，亦即Z分别取z<sub><span style="font-size:12px;">1</span></sub>,z<sub><span style="font-size:12px;">2</span></sub>,...的概率。在GMM中就是求数据点由各个 component生成的概率。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10180310-366355af14e745ba9e711841e6f4fcea.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">注意到我们在Z的后验概率前面乘以了一个权值因子α<sub><span style="font-size:12px;">k</span></sub>，它表示在训练集中数据点属于类别z<sub><span style="font-size:12px;">k</span></sub>的频率，在GMM中它就是π<sub><span style="font-size:12px;">k</span></sub>。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10180413-2fe1b9a855334f6c95417e1f5c630806.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><span><span>M-Step</span>&nbsp;M就是Maximization的意思，就是用最大似然的方法求出模型参数。现在我们认为上一步求出的r(i,k)就是“数据点x<sub><span style="font-size:12px;">i</span></sub>由component k生成的概率”。根据公式(3),(4),(5)可以推出均值、协方差和权值的更新公式为：</span></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10180544-2a66e3bb75b34e54aca5008f5af5e8bf.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10180558-82b3b7de32c74ccebdd5858ca8af7c18.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10180610-8031731f6e00406ab3b0debbd9628676.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images0.cnblogs.com/blog/434101/201305/10180621-70f4c79726d34e7195653770366e4da2.x-png" alt="" style="border:none;"></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">3）收敛条件：</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">不断地迭代E和M步骤，重复更新上面的三个值，直到参数的变化不显著。</p> 
   <h3 style="font-size:16px;line-height:1.5;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">GMM的C++实现</h3> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">C++代码下载：<a href="http://files.cnblogs.com/luxiaoxun/GMM.rar" rel="nofollow" style="color:rgb(0,0,0);">GMM.rar</a></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">GitHub代码：<a href="https://github.com/luxiaoxun/KMeans-GMM-HMM" rel="nofollow" style="color:rgb(0,0,0);">https://github.com/luxiaoxun/KMeans-GMM-HMM</a></p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;">代码来自网络，做了简单的测试。</p> 
   <p style="color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;font-size:15px;"><br></p> 
   <p><font color="#333333"><span style="font-size:15px;">&nbsp; &nbsp; 本文转自阿凡卢博客园博客，原文链接：http://www.cnblogs.com/luxiaoxun/archive/2013/05/10/3071672.html</span></font><span style="font-size:15px;color:rgb(51,51,51);font-family:Verdana, Arial, Helvetica, sans-serif;">，如需转载请自行联系原作者</span></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
