<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>朴素贝叶斯文本分类简单介绍 « NotBeCN</title>
  <meta name="description" content="             本文介绍朴素贝叶斯算法如何对文本进行分类。比如，每个用户的购物评论就是一篇文本，识别出这篇文本属于正向评论还是负面评论 就是分类的过程，而类别就是：{正面评论，负面评论}。正面评论为Positive，用标识符'+'表示；负面评论为Negative，用标识符'-'表示。    &nbsp;...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/16/weixin_34256074_90125186.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">朴素贝叶斯文本分类简单介绍</h1>
    <p class="post-meta">Nov 16, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">本文介绍朴素贝叶斯算法如何对文本进行分类。比如，每个用户的购物评论就是一篇文本，识别出这篇文本属于正向评论还是负面评论 就是分类的过程，而类别就是：{正面评论，负面评论}。正面评论为Positive，用标识符'+'表示；负面评论为Negative，用标识符'-'表示。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">一，分类目标</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">寻找文本的某些特征，然后根据这些特征将文本归为某个类。</span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="line-height:1.5;">The goal of classification is to take a single observation, extract some useful
features, and thereby classify the observation into one of a set of discrete classes.</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">使用监督式机器学习方法对文本进行分类：首先假设已经有分好类的N篇文档：</span><span style="font-family:'Microsoft YaHei';font-size:15px;">(d<sub>1</sub>,c<sub>1</sub>)、(d<sub>2</sub>,c<sub>2</sub>)、(d<sub>3</sub>,c<sub>3</sub>)……(d<sub>n</sub>,c<sub>n</sub>)</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">d<sub>i</sub>表示第i篇文档，c<sub>i</sub>表示第i个类别。目标是：寻找一个分类器，这个分类器能够：当丢给它一篇新文档d，它就输出d （最有可能）属于哪个类别c</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">二，分类器的介绍</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">①Generative classifier</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">朴素贝叶斯分类器属于Generative classifier。　　</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">②Discriminative classifier</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">逻辑回归属于Discriminative classifier。</span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="line-height:1.5;"><span style="color:rgb(255,0,0);line-height:1.5;">Generative classifiers</span> like naive Bayes build a model of each class. Given an observation,they return the class most likely to have generated the observation. 
<span style="color:rgb(255,0,0);line-height:1.5;">Discriminative classifiers</span> like logistic regression instead learn what features from the input are most useful to discriminate between the different possible classes.</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">三，词袋模型（Bag Of Words）</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">前面提到，文本分类需要寻找文本的特征。而词袋模型就是表示文本特征的一种方式。给定一篇文档，它会有很多特征，比如文档中每个单词出现的次数、某些单词出现的位置、单词的长度、单词出现的频率……而词袋模型只考虑一篇文档中单词出现的频率(次数)，用每个单词出现的频率作为文档的特征（或者说用单词出现的频率来代表该文档）。词袋模型的示意图如下：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171226205619995-1083921907.png" alt="" style="border:0px;"></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="line-height:1.5;">We represent a text document as if it were a<strong> bag-of-words</strong>, 
that is, an unordered set of words with their <span style="color:rgb(255,0,0);line-height:1.5;">position ignored</span>, keeping only their frequency in the document.</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">四，朴素贝叶斯分类器</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">朴素贝叶斯分类器是一个概率分类器。假设现有的类别C={c<sub>1</sub>，c<sub>2</sub>，……c<sub>m</sub>}。给定一篇文档d，文档d最有可能属于哪个类呢？这个问题用数学公式表示如下：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171226210115854-658793505.png" alt="" style="border:0px;">（公式一）</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">c<sup>^&nbsp;</sup>就是：在所有的类别C={c<sub>1</sub>，c<sub>2</sub>，……c<sub>m</sub>} 中，使得：条件概率P(c|d)取最大值的类别。</span></span><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">使用贝叶斯公式，将（公式一）转换成如下形式：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171226210750010-1533051477.png" alt="" style="border:0px;">(公式二)</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">对类别C中的每个类型，计算&nbsp;[p(d|c)*p(c)]/p(d) 的值，然后选取最大值对应的那个类型c<sub>i</sub>&nbsp;，该c<sub>i</sub>就是最优解c<sup>^</sup>，因此，可以忽略掉分母 p(d)，（公式二）变成如下形式：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171226211045557-74397339.png" alt="" style="border:0px;">(公式三)</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">这个公式由两部分组成，前面那部分P(d|c) 称为似然函数，后面那部分P(c) 称为先验概率。</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">前面提到使用词袋模型来表示 文档d，文档d的每个特征表示为：d={f<sub>1</sub>,f<sub>2</sub>,f<sub>3</sub>……f<sub>n</sub>}，那么这里的特征f<sub>i&nbsp;</sub>其实就是单词w<sub>i&nbsp;</sub>出现的频率（次数），公式三转化成如下形式：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226211710776-964709599.png" alt="" style="border:0px;">(公式四)</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">对文档d 做个假设：假设各个特征之间是相互独立的。那么p(f<sub>1</sub>,f<sub>2……</sub>f<sub>n</sub>|c)=p(f<sub>1</sub>|c)*p(f<sub>2</sub>|c)*……*p(f<sub>n</sub>|c)，公式四转化成如下形式：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226212220323-719753246.png" alt="" style="border:0px;">（公式五）</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">由于每个概率值很小（比如0.0001）若干个很小的概率值直接相乘，得到的结果会越来越小。为了避免计算过程出现下溢(underflower)，引入对数函数Log，在 log space中进行计算。然后使用词袋模型的每个单词w<sub>i</sub>&nbsp;出现频率作为特征，得到如下公式</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226212307135-987620490.png" alt="" style="border:0px;">（公式六）</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">五，训练朴素贝叶斯分类器</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">训练朴素贝叶斯的过程其实就是计算先验概率和似然函数的过程。</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">①先验概率P(c)的计算</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">P(c)的意思是：在所有的文档中，类别为c的文档出现的概率有多大？假设训练数据中一共有N<sub>doc</sub>篇文档，只要数一下类别c的文档有多少个就能计算p(c)了，类别c的文档共有N<sub>c</sub>篇，先验概率的计算公式如下：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226213011213-1391781480.png" alt="" style="border:0px;">(公式七)</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">【先验概率 其实就是 准备干一件事情时，目前已经掌握了哪些信息了】关于先验信息理解，可参考：<a href="http://www.cnblogs.com/hapjin/p/6653920.html" rel="nofollow" style="color:#000000;">这篇文章</a>。</span></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="line-height:1.5;">For the document prior P(c) we ask what percentage of the documents in our training set are in each class c. 
Let Nc be the number of documents in our training data with
class c and Ndoc be the total number of documents</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">②似然函数P(w<sub>i</sub>|c)的计算</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">由于是用词袋模型表示一篇文档d，对于文档d中的每个单词w<sub>i</sub>，找到训练数据集中所有类别为c的文档，数一数 单词w<sub>i</sub>在这些文档（类别为c）中出现的次数：count(w<sub>i</sub>,c)</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">然后，再数一数训练数据集中类别为c的文档一共有多少个单词<img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226214118338-1681169402.png" alt="" style="border:0px;">。计算 二者之间的比值，就是似然函数的值。似然函数计算公式如下：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226214227823-734438657.png" alt="" style="border:0px;">（公式八）</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">其中V，就是词库。（有些单词在词库中，但是不属于类别C，那么 count(w,c)=0）</span></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="line-height:1.5;">Here the vocabulary V consists of the union of all the word types in all classes, not just the words in one class c.</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">从上面计算似然函数的过程来看，其实相当于一个发掘（统计）潜藏规律的过程。</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">六，unknow words的情形</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">假设只考虑文本二分类：将文档分成 positve类别，或者negative类别，C={positive, negative}</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">在训练数据集中，类别为positive的所有文档 都没有 包含 单词w<sub>i</sub>&nbsp;=&nbsp;fantastic（fantastic可能出现在类别为negative的文档中）</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">那么 count(w<sub>i</sub>=fantastic，c<sub>i</sub>=positive)=0 。那么：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226215826948-1150985441.png" alt="" style="border:0px;"></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">而注意到前面公式五中的累乘，整篇文档的似然函数值为0，也就是说：如果文档d中有个单词fantastic在类别为c的训练数据集文档中从未出现过，那文档d被分类到类别c的概率为0，尽管文档d中还有一些其他单词（特征），而这些单词所代表的特征认为文档d应该被分类 到 类别c中</span></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="line-height:1.5;">But since naive Bayes naively multiplies all the feature likelihoods together, zero
probabilities in the likelihood term for any class will cause the probability of the
class to be zero, no matter the other evidence!</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">解决方案就是<span style="color:rgb(255,0,0);"><strong>&nbsp;add-one smoothing</strong></span>。（不介绍了），其实就是将“出现次数加1”。似然函数公式变成如下形式：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171226220422698-2092013242.png" alt="" style="border:0px;">（公式九）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">其中|V|是词库中所有单词的个数。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">七，朴素贝叶斯分类示例</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">假设训练数据集有五篇文档，其中Negative类别的文档有三篇，用符号 '-' 标识；Positive类别的文档有二篇，用符号 '+' 标识，它们的内容如下：</span></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);"> 
    <div class="cnblogs_code_toolbar" style="font-family:'Courier New';font-size:12px;">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="line-height:1.5;">-  just plain boring
-  entirely predictable <span style="color:rgb(255,0,0);line-height:1.5;">and</span> lacks energy
-  no surprises <span style="color:rgb(255,0,0);line-height:1.5;">and</span> <span style="color:rgb(0,0,255);line-height:1.5;">very</span> few laughs


+  <span style="color:rgb(0,0,255);line-height:1.5;">very</span> powerful
+  <span style="color:rgb(255,153,0);line-height:1.5;">the</span> most fun film of <span style="color:rgb(255,153,0);line-height:1.5;">the</span> summer</span></pre> 
    <pre><span style="line-height:1.5;"></span></pre> 
    <pre><span style="font-size:14px;font-family:'lucida Grande', Verdana, 'Microsoft YaHei';">，如需转载请自行联系原作者</span></pre> 
    <div class="cnblogs_code_toolbar" style="font-family:'Courier New';font-size:12px;">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">测试数据集T 有一篇文档d<sub>t</sub>，内容如下：</span></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre>predictable with no fun</pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">朴素贝叶斯分类器会把“predictable with no fun”归为哪个类呢？根据第五节“训练朴素贝叶斯分类器”，需要计算先验概率和似然函数。</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">由于训练数据集中一共有5篇文档，其中类别 '+' 的文档有2篇，类别为 '-' 的文档有3篇，</span></span><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">因此先验概率：P(c)=P('-')=N<sub>c</sub>/N<sub>doc</sub>=3/5=0.6&nbsp; &nbsp;</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">类别为'+' 的文档有2篇，故&nbsp;</span></span><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">P(c)=P('+')=N<sub>c</sub>/N<sub>doc</sub>=2/5=0.4</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">对测试数据集文档d<sub>t</sub>中的每个单词，似然函数采用“<em><span style="color:rgb(51,204,204);">add-one</span></em>&nbsp;smoothing”处理，计算相应的似然概率：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">首先单词 predictable 在训练数据集中 类别为'-'的文档中只出现了<span style="color:rgb(255,0,0);"><strong>1</strong></span>次，类别为'-'的文档一共有14个单词，训练数据集中两种类型的文档加起来一共有23个单词，但是有三个单词(and、</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">very、the)重复出现了两次，故词库V的大小为 20。因此单词predictable对应的似然概率如下：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">p(predictable|'-')=(<span style="color:rgb(255,0,0);"><strong>1</strong></span>+<em><span style="color:rgb(51,204,204);">1</span></em>)/(14+20)=2/34</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">同理：<span style="color:rgb(255,102,0);">p(predictable|'+')=(0+1)/(9+20)=2/29&nbsp;</span>&nbsp;&nbsp;（predictable没有在类别为'+'的训练数据集中出现过）</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">类似地：p(no|'=')=(1+1)/(14+20)&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<span style="color:rgb(255,102,0);">p(no|'+')=(0+1)/(9+20)</span></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">p(fun|'-')=(0+1)/(14+20)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span style="color:rgb(255,102,0);">&nbsp;p(fun|'+')=(1+1)/(9+20)</span></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">因此，测试集中的文档d归类为 '-' 的概率为：0.6 * （2*2*1）/34<sup>3</sup>&nbsp;= 6.1*10<sup>-5</sup></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">测试集中的文档d归类为 '+' 的概率为：0.4*<span style="color:rgb(255,102,0);">（1*1*2）/29<sup>3</sup>&nbsp;=3.2*10<sup>-5</sup></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<span style="font-family:'Microsoft YaHei';font-size:15px;">比较上面两个概率的大小，就可以知道将“predictable with no fun”归为 '-' 类别。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">八，参考资料</span></span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a href="http://web.stanford.edu/class/cs124/" rel="nofollow" style="color:#000000;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">CS 124: From Languages to Information</span></span></a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><a id="post_title_link_6653920" href="http://www.cnblogs.com/hapjin/p/6653920.html" rel="nofollow" style="color:#000000;">机器学习中的贝叶斯方法---先验概率、似然函数、后验概率的理解及如何使用贝叶斯进行模型预测（1）</a></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a id="post_title_link_6656642" href="http://www.cnblogs.com/hapjin/p/6656642.html" rel="nofollow" style="color:#000000;">机器学习中的贝叶斯方法---先验概率、似然函数、后验概率的理解及如何使用贝叶斯进行模型预测（2）</a></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
