<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>stanford coursera 机器学习编程作业 exercise 6（支持向量机-support vector machines） « NotBeCN</title>
  <meta name="description" content="             在本练习中，先介绍了SVM的一些基本知识，再使用SVM（支持向量机 ）实现一个垃圾邮件分类器。    &nbsp;    在开始之前，先简单介绍一下SVM    ①从逻辑回归的 cost function 到SVM 的 cost function    逻辑回归的假设函数如下：     ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/09/weixin_33877885_90122539.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">stanford coursera 机器学习编程作业 exercise 6（支持向量机-support vector machines）</h1>
    <p class="post-meta">Nov 9, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在本练习中，先介绍了SVM的一些基本知识，再使用SVM（支持向量机 ）实现一个垃圾邮件分类器。</span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-size:18px;"><strong><span style="font-family:'Microsoft YaHei';">在开始之前，先简单介绍一下SVM</span></strong></span></p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">①从逻辑回归的 cost function 到SVM 的 cost function</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">逻辑回归的假设函数如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="496" height="281" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207101821366-1546454336.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">h<sub>θ</sub>(x)取值范围为[0,1]，约定h<sub>θ</sub>(x)&gt;=0.5，也即θ<sup>T</sup>·x&nbsp; &gt;=0时，y=1；比如h<sub>θ</sub>(x)=0.6，此时表示有60%的概率相信 y 等于1</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">显然，<span style="color:rgb(255,0,0);">要想让y取值为1，h<sub>θ</sub>(x)越大越好，因为h<sub>θ</sub>(x)越大，y 取值为1的概率也就越大，也即：更好把握相信 y 等于1</span>。而要想h<sub>θ</sub>(x)越大，也就是θ<sup>T</sup>·x远远大于0</span></p> 
   <p>&nbsp;</p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:15px;">The larger <span style="font-family:'Microsoft YaHei';font-size:16px;">θ<sup>T</sup>·x</span> is, the larger also is <span style="font-family:'Microsoft YaHei';font-size:16px;">h<sub>θ</sub>(x)</span> = p(y = 1|x; w, b), and thus also the higher our degree of “confidence”
that the label is 1</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">同理，y 等于0，也可以通过类似的推理得到：要想让 y 取值为0，则h<sub>θ</sub>(x)越小越好，而要想h<sub>θ</sub>(x)越小，也就是θ<sup>T</sup>·x远远小于0</span></p> 
   <p>&nbsp;</p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">逻辑回归的代价函数(cost function)如下：(为了方便讨论，假设 training examples 只有一个，即：m = 1)</span></p> 
   <p><span style="color:rgb(255,0,0);font-family:'Microsoft YaHei';font-size:16px;"><img width="522" height="76" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207102705366-547398299.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从上面的cost function公式 可以看出：当y==0时，只有<span style="color:rgb(255,0,0);">右边</span>的那部分式子起作用；当y==1时，(1-y==0)只有<span style="color:rgb(255,0,0);">左边</span>的那部分式子起作用。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">y==1时，逻辑回归的代价函数的图形表示如下：可以看出，逻辑回归的代价函数在整个坐标轴上是连续的。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="284" height="252" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207103203272-968045916.png"></span></p> 
   <p>&nbsp;</p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在上面的y==1时的逻辑回归代价函数的基础上，构造一条<strong>新的代价函数</strong>曲线，<em>记为cost<sub>1</sub>(z)</em> ,(<span style="color:rgb(255,0,255);">用紫色的两条直线 线段表示，z==1处是转折点</span>)，如下图：<strong>在z==1 点，新的代价函数是不连续的</strong>。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207103754163-193650304.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">同理，y==0时，逻辑回归的代价函数的图形表示如下图：可以看出，逻辑回归的代价函数在整个坐标轴上是连续的。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="285" height="259" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207104539538-410771451.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在上面的y==0时的逻辑回归代价函数的基础上，构造一条<strong>新的代价函数</strong>曲线，<em>记为cost<sub>0</sub>(z)</em>(<span style="color:rgb(255,0,255);">用紫色的两条直线 线段表示，z== -1处是转折点)，如下图：<strong>在z== -1 点，新的代价函数是不连续的</strong>。</span></span></p> 
   <p>&nbsp;</p> 
   <p><img width="304" height="275" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207104631038-1558217142.png"></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">使用上面新构造的两条函数曲线：<em>cost<sub>0</sub>(z)</em>&nbsp; 和 <em>cost<sub>1</sub>(z)</em>&nbsp; (z 等于θ<sup>T</sup>·x)，组成了支持向量机(SVM)的cost function，如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="609" height="83" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207105721132-998169152.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">对于training example的数目 m 而言，它是一个常量，故在SVM的cost function中 去掉了 m</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">因此，总结一下，得到SVM的代价函数如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="547" height="275" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207115313319-6564257.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">对于SVM而言，<span style="color:rgb(255,0,0);">y==1时，要求：θ<sup>T</sup>·x&gt;=1；y==0时，要求：θ<sup>T</sup>·x&lt;=-1</span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">可以看出：相比于逻辑回归，SVM中的 label of result y 等于 1 时，要求θ<sup>T</sup>·x大于等于1，而不是0，这就相当于多了提高了限制条件，多了一层保障。</span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">另外，SVM的代价函数中的 参数 C 就相当于逻辑回归中的lambda(λ)</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="371" height="163" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207224901897-2132715207.jpg"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">因为，我们的目的是最小化 cost function，<span style="color:rgb(255,0,0);">当 C 很大时，与 C 相乘的这一项只有非常接近于0时，才能让 cost function变小啊...当 C 非常大时，代价函数就等价于：min (1/2)·Σθ<sup>2</sup><sub>j</sub></span></span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">②SVM的decision boundary</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">相比于逻辑回归，SVM能实现更复杂的非线性分类问题。先讨论下线性可分的情况下如何选择更好的 decision boundary？</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">对于样本数据而言，可能有很多种不同的 decision boundary 来对样本进行划分，比如：下图中就有三条 decision boundary，但我们觉得，黑色的那条decision boundary更好地将样本数据分开。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="324" height="231" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207120604991-1525588198.png"></span></p> 
   <p>&nbsp;<span style="font-family:'Microsoft YaHei';font-size:16px;"><strong>黑色的那条 decision boundary 的优点是：有着更大的 margin</strong>。这就是SVM分类器的特点：<span style="color:rgb(255,0,0);">总是尽可能地找出一条最大 margin 的decision boundary</span>，因此SVM有时也称为 Large Margin Classifier。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">对于下图中的数据(有一个红色的叉很“奇特”)，SVM又会怎样寻找 decision boundary呢？</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="635" height="306" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207164636569-914970321.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">当SVM的代价函数中的C不是太大的情况下，SVM还是会坚持黑色那条decision boundary，而不是转化成紫色的那条 decision boundary。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">当SVM的代价函数中的参数C很大时，它就很可能会选择紫色的那条 decision boundary了。但是，在实际应用上，C 不会是 很大很大的，因此，尽管样本中出现了“奇异点”样本，SVM还是会坚持黑色那条decision boundary，从而具有一定的“容错性”</span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">③SVM为什么是大间距分类器？(Why Large Margin?)</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">假设当C很大时，代价函数：<span style="color:rgb(255,0,0);">min (1/2)·Σθ<sup>2</sup><sub>j</sub> 可以表示成向量的乘法形式：min (1/2)θ<sup>T</sup>·θ </span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">因为：Σθ<sub>j</sub><sup>2</sup> = (θ<sub>1</sub><sup>2</sup> +θ<sub>2</sub><sup>2</sup> +.... +θ<sub>n</sub><sup>2</sup>) = (θ<sub>1</sub>，θ<sub>2</sub>，....,θ<sub>n</sub>)<sup>T</sup>• (θ<sub>1</sub>，θ<sub>2</sub>，....,θ<sub>n</sub>) = ||θ||<sup>2</sup></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">因此，我们把代价函数 转化成了：向量θ的范数，如下图 (n=2)</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="534" height="66" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207230351132-887382572.jpg"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在最小化代价函数时，服从于下面条件：</span></p> 
   <pre><span style="font-size:15px;"><span style="font-family:'Microsoft YaHei';font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> &gt;= 1 if y==1<br><span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> &lt;= -1 if y==0</span></span></span></span></pre> 
   <p>&nbsp;</p> 
   <p><span style="color:rgb(255,0,0);"><strong>向量乘法与向量投影之间的关系：假设有两个向量a，向量b；向量a、b之间的夹角为theta，由向量乘法公式：a*b=||a||*||b||*cos(theta)。其实，||b||*cos(theta)就是向量b在向量a上的投影。</strong></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">根据向量的投影，<span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup></span></span> = p<sup>(i)</sup>•||θ||，其中p<sup>(i)</sup>是向量 <span style="font-size:15px;"><span style="font-size:16px;">x<sup>(i)</sup></span></span> 在 向量<span style="font-size:15px;"><span style="font-size:16px;">θ</span></span> 方向上的投影。<span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> = p<sup>(i)</sup>•||θ||</span></span> 的示意图如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="301" height="213" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207231546210-900793809.jpg"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从而，将代价函数服从的条件转化成了“向量投影”表示，如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="487" height="170" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161207232141835-872850675.jpg"></span></p> 
   <p>&nbsp;</p> 
   <p>&nbsp;<span style="font-family:'Microsoft YaHei';font-size:16px;">要想最小化代价函数(1/2)·Σθ<sup>2</sup><sub>j</sub> ，就得<span style="color:rgb(255,0,0);">让||θ||尽可能地小</span>；但是又得满足条件：<span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> &gt;= 1 if y==1</span></span>&nbsp; and&nbsp; <span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> &lt;= -1 if y==0</span></span></span></span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">根据：<span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> = p<sup>(i)</sup>•||θ||。</span></span>因此，<span style="color:rgb(255,0,0);">要想<span style="font-size:15px;"><span style="font-size:16px;">θ<sup>T</sup>·x<sup>(i)</sup> 尽可能地大于等于 </span></span>1 ，<strong>就得让<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup></span></span> 尽可能地大</strong>，<span style="color:rgb(0,0,0);">这样<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup>•||θ||</span></span> 才有更大的可能 大于等于1</span></span>。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">（不能让<span style="font-size:15px;"><span style="font-size:16px;">||θ||</span></span>尽可能地大，因为<span style="font-size:15px;"><span style="font-size:16px;">||θ||</span></span>大了，代价函数就大了，而我们的目标是最小化代价函数）<br></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">好，既然现在的目标是让<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup></span></span>尽可能地大，<strong>那<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup></span></span>代表的意义是什么呢？就是：margins（间距），这也是SVM被称为 大间距分类器 的原因。</strong><br> 那 <span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup></span></span> 为什么代表的是间距呢？看下图：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="400" height="215" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161208092930944-1480102986.png"></span></p> 
   <p>&nbsp;<span style="font-family:'Microsoft YaHei';font-size:16px;">红色的叉叉 和 圆圈 表示的是训练的样本，我们用一条绿色的线(decision boundary)将叉叉 和 圆圈 分开。<span style="color:rgb(51,102,255);">向量θ 的方向是与decision boundary 垂直的。</span><br></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">对于“红色的叉叉”这个样本x<sup>(1)</sup>而言，它的几何间距是 <span style="font-size:15px;"><span style="font-size:16px;">p<sup>(1)</sup>；对于圆圈样本 x<sup>(2)</sup> 而言，它的几何间距是<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(2)</sup></span></span></span></span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">从上图中可以看出，<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(1)</sup></span></span> 和<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(2)</sup></span></span> 的长度 都比较短，因此，要想让<span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup>•||θ|| 大于等于1 或者 小于等于-1，只能让<span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">||θ||</span></span></span></span></span></span>大一点了，而<span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">||θ||</span></span></span></span></span></span></span></span></span></span></span></span>要是很大，代价函数就大了，而最小化SVM的代价函数的意义就是：找出一组参数(θ<sub>1</sub>，<span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">θ<sub>2</sub></span></span></span></span></span></span>......<span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">θ<sub>n</sub></span></span></span></span></span></span>)，使得代价函数尽可能地小。因此，SVM是不会选择 <span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">p<sup>(1)</sup></span></span></span></span></span></span> 长度 小的 decision boundary的。</span></span></span></span></span></span></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">再来看一个投影长度<span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">p<sup>(i)</sup></span></span></span></span></span></span> 比较长的例子：</span></span></span></span></span></span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><img alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161208094617257-636821282.png"></span></span></span></span></span></span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">红色的叉叉 和 圆圈 表示的是训练的样本，我们用一条绿色的线(decision boundary)将叉叉 和 圆圈 分开，此时的decision boundary刚好是 y 轴(竖直线)；红色的叉叉样本x<sup>(1)</sup> 在向量上的投影<span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;">p<sup>(1 )</sup></span></span></span></span></span></span>刚好是x<sup>(1) </sup>的 x 轴的坐标，它要比斜着的绿色decision boundary 上的投影 <strong>要长。</strong><br></span></span></span></span></span></span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><strong>因此，SVM 会选择这条竖直的绿色 decision boundary 作为分类边界。它的 Margin 的示意图如下：</strong></span></span></span></span></span></span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><span style="font-size:15px;"><span style="font-size:16px;"><strong><img width="349" height="238" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161208095404772-1780873211.png"></strong></span></span></span></span></span></span></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在上面的描述中，我们是先假设 SVM 的cost function 中的参数 C 很大，只留下了 θ（<span style="color:rgb(255,0,0);">min (1/2)·Σθ<sup>2</sup><sub>j</sub></span>）。然后根据 样本x<sup>(i)</sup> 在 θ向量上 的投影尽可能大 使得Margin很大，从而选择Margin大的 decision boundary，下面将从另一个角度来讨论为什么选择大的 margins（参考 cs229-notes3.pdf）</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">首先看下图中的一个线性可分的例子：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="393" height="286" alt="" src="https://images2015.cnblogs.com/blog/715283/201612/715283-20161208101912179-643415672.png"></span></p> 
   <p>因此，如果我们能找到这样一条 decision boundary，让所有的点尽可能地离该decision boundary 远，这样我们就更有理由预测 y==1 或者 y==0</p> 
   <p>比如，相比于C点，我们更有理由相信 A点属于 positive 这一类，即更相信 预测 A点的 y==1 而不是预测C点的 y==1</p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">简便起见，我们只考虑线性可分的二分类问题，y==1 或者 y==-1 来标记样本属于不同的分类。</span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:15px;">we’ll use y ∈ {−1, 1} (instead of {0, 1}) to denote the class labels</span></pre>
   </div> 
   <p>&nbsp;待完成</p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">④核函数（主要讨论高斯核函数）（待完成）</span></p> 
   <p>&nbsp;</p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:14px;">We’ll also see kernels, which give a way to <span style="color:rgb(255,0,0);">apply SVMs efficiently in very high dimensional</span> <br>
(such as infinitedimensional) feature spaces</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-size:18px;"><strong><span style="font-family:'Microsoft YaHei';">使用SVM实现垃圾邮件分类器</span></strong></span></p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">ⓐ输入数据(邮件)预处理并构造样本特征(input features)</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">假设一份样本邮件如下：</span></p> 
   <div class="cnblogs_code"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
    <pre><span style="font-size:14px;">&gt; Anyone knows how much it costs to host a web portal ?
&gt;
Well, it depends on how many visitors you're expecting.
This can be anywhere from less than 10 bucks a month to a couple of $100. 
You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 
if youre running something big..

To unsubscribe yourself from this mailing list, send an email to:
groupname-unsubscribe@egroups.com</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">这份样本邮件中有：URL、邮件地址、数字、金额(dollar)....这些特征都是与特定的Email相关的。对于不同的Email，也许也有URL、邮件地址.....但只是URL地址不一样，邮件地址不一样、出现的金额不一样.....因此，就需要“normalize”这些值，也就是说：我们关注的还是URL地址是什么，金额是多少，我们关注的是：是否出现了URL，是否出现了邮件地址....预处理策略如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">比如，所有的URL 都用字符串“httpaddr”代替；所有的邮件地址都用字符串“emailaddr”代替；邮件中的所有的大写字母都转换成小写字母....</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">处理完之后，邮件变成了如下：</span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:14px;">anyon know how much it cost to host a web portal well it depend on how mani 
visitor you re expect thi can be anywher from less than number buck a month 
to a coupl of dollarnumb you should checkout httpaddr or perhap amazon ecnumb 
if your run someth big to unsubscrib yourself from thi mail list send an 
email to emailaddr</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在本例中，我们有一个词库，这个词库有1899个单词，因此 input features 是一个1899维的向量<br></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">如果处理之后的邮件中的单词出现在了词库中，input features 对应的位置为1，否则为0</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">processEmail.m用来进行上述预处理，其代码如下：</span></p> 
   <div class="cnblogs_code"> 
    <img class="code_img_closed" alt="" src="https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif">
    <img class="code_img_opened" alt="" src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif">
    <div class="cnblogs_code_hide">
     <pre>function word_indices = processEmail(email_contents)
%PROCESSEMAIL preprocesses a the body of an email and
%returns a list of word_indices 
%   word_indices = PROCESSEMAIL(email_contents) preprocesses 
%   the body of an email and returns a list of indices of the 
%   words contained in the email. 
%

% Load Vocabulary
vocabList = getVocabList();

% Init return value
word_indices = [];

% ========================== Preprocess Email ===========================

% Find the Headers ( \n\n and remove )
% Uncomment the following lines if you are working with raw emails with the
% full headers

% hdrstart = strfind(email_contents, ([char(10) char(10)]));
% email_contents = email_contents(hdrstart(1):end);

% Lower case
email_contents = lower(email_contents);

% Strip all HTML
% Looks for any expression that starts with <span style="color:rgb(0,0,255);">&lt;</span><span style="color:rgb(128,0,0);"> and </span><span style="color:rgb(255,0,0);">ends with </span><span style="color:rgb(0,0,255);">&gt;</span> and replace
% and does not have any <span style="color:rgb(0,0,255);">&lt;</span><span style="color:rgb(128,0,0);"> or </span><span style="color:rgb(0,0,255);">&gt;</span> in the tag it with a space
email_contents = regexprep(email_contents, '<span style="color:rgb(0,0,255);">&lt;</span><span style="color:rgb(128,0,0);">[^&lt;</span><span style="color:rgb(0,0,255);">&gt;</span>]+&gt;', ' ');

% Handle Numbers
% Look for one or more characters between 0-9
email_contents = regexprep(email_contents, '[0-9]+', 'number');

% Handle URLS
% Look for strings starting with http:// or https://
email_contents = regexprep(email_contents, ...
                           '(http|https)://[^\s]*', 'httpaddr');

% Handle Email Addresses
% Look for strings with @ in the middle
email_contents = regexprep(email_contents, '[^\s]+@[^\s]+', 'emailaddr');

% Handle $ sign
email_contents = regexprep(email_contents, '[$]+', 'dollar');


% ========================== Tokenize Email ===========================

% Output the email to screen as well
fprintf('\n==== Processed Email ====\n\n');

% Process file
l = 0;

while ~isempty(email_contents)

    % Tokenize and also get rid of any punctuation
    [str, email_contents] = ...
       strtok(email_contents, ...
              [' @$/#.-:&amp;*+=[]?!(){},''"&gt;_<span style="color:rgb(0,0,255);">&lt;</span><span style="color:rgb(128,0,0);">;%' char</span><span style="color:rgb(255,0,0);">(10) char(13)]);
   
    % Remove any non alphanumeric characters
    str </span><span style="color:rgb(0,0,255);">= regexprep(str, </span><span style="color:rgb(255,0,0);">'[^a-zA-Z0-9]', '');

    % Stem the word 
    % (the porterStemmer sometimes has issues, so we use a try catch block)
    try str </span><span style="color:rgb(0,0,255);">= porterStemmer(strtrim(str)); 
    </span><span style="color:rgb(255,0,0);">catch str </span><span style="color:rgb(0,0,255);">= ''; </span><span style="color:rgb(255,0,0);">continue;
    end;

    % Skip the word if it is too short
    if length(str) &lt; 1
       continue;
    end

    % Look up the word in the dictionary and add to word_indices if
    % found
    % </span><span style="color:rgb(0,0,255);">====================== </span><span style="color:rgb(255,0,0);">YOUR CODE HERE </span><span style="color:rgb(0,0,255);">======================
    </span><span style="color:rgb(255,0,0);">% Instructions: Fill in this function to add the index of str to
    %               word_indices if it is in the vocabulary. At this point
    %               of the code, you have a stemmed word from the email in
    %               the variable str. You should look up str in the
    %               vocabulary list (vocabList). If a match exists, you
    %               should add the index of the word to the word_indices
    %               vector. Concretely, if str </span><span style="color:rgb(0,0,255);">= 'action', </span><span style="color:rgb(255,0,0);">then you should
    %               look up the vocabulary list to find where in vocabList
    %               'action' appears. For example, if vocabList{18} </span><span style="color:rgb(0,0,255);">=
    %               </span><span style="color:rgb(255,0,0);">'action', then, you should add 18 to the word_indices 
    %               vector (e.g., word_indices </span><span style="color:rgb(0,0,255);">= [word_indices </span><span style="color:rgb(255,0,0);">; 18]; ).
    % 
    % Note: vocabList{idx} returns a the word with index idx in the
    %       vocabulary list.
    % 
    % Note: You can use strcmp(str1, str2) to compare two strings (str1 and
    %       str2). It will return 1 only if the two strings are equivalent.
    %
    
    for i </span><span style="color:rgb(0,0,255);">= 1:length(vocabList)
        </span><span style="color:rgb(255,0,0);">if(strcmp(str, vocabList{i}) </span><span style="color:rgb(0,0,255);">== </span><span style="color:rgb(255,0,0);">1)
            word_indices </span><span style="color:rgb(0,0,255);">= [word_indices; </span><span style="color:rgb(255,0,0);">i];
            break;
        end
    end
    % </span><span style="color:rgb(0,0,255);">=============================================================


    </span><span style="color:rgb(255,0,0);">% Print to screen, ensuring that the output lines are not too long
    if (l + length(str) + 1) </span><span style="color:rgb(0,0,255);">&gt;</span> 78
        fprintf('\n');
        l = 0;
    end
    fprintf('%s ', str);
    l = l + length(str) + 1;

end

% Print footer
fprintf('\n\n=========================\n');

end</pre>
    </div> 
    <span class="cnblogs_code_collapse">View Code</span> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">预处理的结果如下：</span></p> 
   <div class="cnblogs_code">
    <pre>Length of feature vector: 1899
Number of non-zero entries: 45</pre>
   </div> 
   <p>表明：在上面的那封邮件中，有45个单词出现在词库中。</p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">ⓑ训练SVM</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">spamTrain.mat 中包含了4000封邮件(即有垃圾邮件，也有非垃圾邮件)，spamTest.mat中包含了1000个测试样本，相应的训练代码如下：</span></p> 
   <div class="cnblogs_code"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
    <pre><span style="font-size:14px;">%% =========== Part 3: Train Linear SVM for Spam Classification ========
%  In this section, you will train a linear classifier to determine if an
%  email is Spam or Not-Spam.

% Load the Spam Email dataset
% You will have X, y in your environment
load('spamTrain.mat');

fprintf('\nTraining Linear SVM (Spam Classification)\n')
fprintf('(this may take 1 to 2 minutes) ...\n')

C = 0.1;
<span style="color:rgb(255,0,0);"><strong>model = svmTrain(X, y, C, @linearKernel);</strong></span>

p = svmPredict(model, X);

fprintf('Training Accuracy: %f\n', mean(double(p == y)) * 100);</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">svmTrain 实现了SMO算法，svmTrain.m代码如下：</span></p> 
   <div class="cnblogs_code"> 
    <img class="code_img_closed" alt="" src="https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif">
    <img class="code_img_opened" alt="" src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif">
    <div class="cnblogs_code_hide">
     <pre>function [model] = svmTrain(X, Y, C, kernelFunction, ...
                            tol, max_passes)
%SVMTRAIN Trains an SVM classifier using a simplified version of the SMO 
%algorithm. 
%   [model] = SVMTRAIN(X, Y, C, kernelFunction, tol, max_passes) trains an
%   SVM classifier and returns trained model. X is the matrix of training 
%   examples.  Each row is a training example, and the jth column holds the 
%   jth feature.  Y is a column matrix containing 1 for positive examples 
%   and 0 for negative examples.  C is the standard SVM regularization 
%   parameter.  tol is a tolerance value used for determining equality of 
%   floating point numbers. max_passes controls the number of iterations
%   over the dataset (without changes to alpha) before the algorithm quits.
%
% Note: This is a simplified version of the SMO algorithm for training
%       SVMs. In practice, if you want to train an SVM classifier, we
%       recommend using an optimized package such as:  
%
%           LIBSVM   (http://www.csie.ntu.edu.tw/~cjlin/libsvm/)
%           SVMLight (http://svmlight.joachims.org/)
%
%

if ~exist('tol', 'var') || isempty(tol)
    tol = 1e-3;
end

if ~exist('max_passes', 'var') || isempty(max_passes)
    max_passes = 5;
end

% Data parameters
m = size(X, 1);
n = size(X, 2);

% Map 0 to -1
Y(Y==0) = -1;

% Variables
alphas = zeros(m, 1);
b = 0;
E = zeros(m, 1);
passes = 0;
eta = 0;
L = 0;
H = 0;

% Pre-compute the Kernel Matrix since our dataset is small
% (in practice, optimized SVM packages that handle large datasets
%  gracefully will _not_ do this)
% 
% We have implemented optimized vectorized version of the Kernels here so
% that the svm training will run faster.
if strcmp(func2str(kernelFunction), 'linearKernel')
    % Vectorized computation for the Linear Kernel
    % This is equivalent to computing the kernel on every pair of examples
    K = X*X';
elseif strfind(func2str(kernelFunction), 'gaussianKernel')
    % Vectorized RBF Kernel
    % This is equivalent to computing the kernel on every pair of examples
    X2 = sum(X.^2, 2);
    K = bsxfun(@plus, X2, bsxfun(@plus, X2', - 2 * (X * X')));
    K = kernelFunction(1, 0) .^ K;
else
    % Pre-compute the Kernel Matrix
    % The following can be slow due to the lack of vectorization
    K = zeros(m);
    for i = 1:m
        for j = i:m
             K(i,j) = kernelFunction(X(i,:)', X(j,:)');
             K(j,i) = K(i,j); %the matrix is symmetric
        end
    end
end

% Train
fprintf('\nTraining ...');
dots = 12;
while passes <span style="color:rgb(0,0,255);">&lt;</span><span style="color:rgb(128,0,0);"> max_passes</span><span style="color:rgb(255,0,0);">,
            
    num_changed_alphas </span><span style="color:rgb(0,0,255);">= 0;
    </span><span style="color:rgb(255,0,0);">for i </span><span style="color:rgb(0,0,255);">= 1:m,
        
        </span><span style="color:rgb(255,0,0);">% Calculate Ei </span><span style="color:rgb(0,0,255);">= f(x(i)) </span><span style="color:rgb(255,0,0);">- y(i) using (2). 
        % E(i) </span><span style="color:rgb(0,0,255);">= b </span><span style="color:rgb(255,0,0);">+ sum (X(i, :) * (repmat(alphas.*Y,1,n).*X)') - Y(i);
        E(i) </span><span style="color:rgb(0,0,255);">= b </span><span style="color:rgb(255,0,0);">+ sum (alphas.*Y.*K(:,i)) - Y(i);
        
        if ((Y(i)*E(i) &lt; -tol &amp;&amp; alphas(i) &lt; C) || (Y(i)*E(i) </span><span style="color:rgb(0,0,255);">&gt;</span> tol &amp;&amp; alphas(i) &gt; 0)),
            
            % In practice, there are many heuristics one can use to select
            % the i and j. In this simplified code, we select them randomly.
            j = ceil(m * rand());
            while j == i,  % Make sure i \neq j
                j = ceil(m * rand());
            end

            % Calculate Ej = f(x(j)) - y(j) using (2).
            E(j) = b + sum (alphas.*Y.*K(:,j)) - Y(j);

            % Save old alphas
            alpha_i_old = alphas(i);
            alpha_j_old = alphas(j);
            
            % Compute L and H by (10) or (11). 
            if (Y(i) == Y(j)),
                L = max(0, alphas(j) + alphas(i) - C);
                H = min(C, alphas(j) + alphas(i));
            else
                L = max(0, alphas(j) - alphas(i));
                H = min(C, C + alphas(j) - alphas(i));
            end
           
            if (L == H),
                % continue to next i. 
                continue;
            end

            % Compute eta by (14).
            eta = 2 * K(i,j) - K(i,i) - K(j,j);
            if (eta &gt;= 0),
                % continue to next i. 
                continue;
            end
            
            % Compute and clip new value for alpha j using (12) and (15).
            alphas(j) = alphas(j) - (Y(j) * (E(i) - E(j))) / eta;
            
            % Clip
            alphas(j) = min (H, alphas(j));
            alphas(j) = max (L, alphas(j));
            
            % Check if change in alpha is significant
            if (abs(alphas(j) - alpha_j_old) <span style="color:rgb(0,0,255);">&lt;</span><span style="color:rgb(128,0,0);"> tol</span><span style="color:rgb(255,0,0);">),
                % continue to next i. 
                % replace anyway
                alphas(j) </span><span style="color:rgb(0,0,255);">= alpha_j_old;
                </span><span style="color:rgb(255,0,0);">continue;
            end
            
            % Determine value for alpha i using (16). 
            alphas(i) </span><span style="color:rgb(0,0,255);">= alphas(i) </span><span style="color:rgb(255,0,0);">+ Y(i)*Y(j)*(alpha_j_old - alphas(j));
            
            % Compute b1 and b2 using (17) and (18) respectively. 
            b1 </span><span style="color:rgb(0,0,255);">= b </span><span style="color:rgb(255,0,0);">- E(i) ...
                 - Y(i) * (alphas(i) - alpha_i_old) *  K(i,j)' ...
                 - Y(j) * (alphas(j) - alpha_j_old) *  K(i,j)';
            b2 </span><span style="color:rgb(0,0,255);">= b </span><span style="color:rgb(255,0,0);">- E(j) ...
                 - Y(i) * (alphas(i) - alpha_i_old) *  K(i,j)' ...
                 - Y(j) * (alphas(j) - alpha_j_old) *  K(j,j)';

            % Compute b by (19). 
            if (0 &lt; alphas(i) &amp;&amp; alphas(i) &lt; C),
                b </span><span style="color:rgb(0,0,255);">= b1;
            </span><span style="color:rgb(255,0,0);">elseif (0 &lt; alphas(j) &amp;&amp; alphas(j) &lt; C),
                b </span><span style="color:rgb(0,0,255);">= b2;
            </span><span style="color:rgb(255,0,0);">else
                b </span><span style="color:rgb(0,0,255);">= (b1+b2)/2;
            </span><span style="color:rgb(255,0,0);">end

            num_changed_alphas </span><span style="color:rgb(0,0,255);">= num_changed_alphas </span><span style="color:rgb(255,0,0);">+ 1;

        end
        
    end
    
    if (num_changed_alphas </span><span style="color:rgb(0,0,255);">== </span><span style="color:rgb(255,0,0);">0),
        passes </span><span style="color:rgb(0,0,255);">= passes </span><span style="color:rgb(255,0,0);">+ 1;
    else
        passes </span><span style="color:rgb(0,0,255);">= 0;
    </span><span style="color:rgb(255,0,0);">end

    fprintf('.');
    dots </span><span style="color:rgb(0,0,255);">= dots </span><span style="color:rgb(255,0,0);">+ 1;
    if dots </span><span style="color:rgb(0,0,255);">&gt;</span> 78
        dots = 0;
        fprintf('\n');
    end
    if exist('OCTAVE_VERSION')
        fflush(stdout);
    end
end
fprintf(' Done! \n\n');

% Save the model
idx = alphas &gt; 0;
model.X= X(idx,:);
model.y= Y(idx);
model.kernelFunction = kernelFunction;
model.b= b;
model.alphas= alphas(idx);
model.w = ((alphas.*Y)'*X)';

end</pre>
    </div> 
    <span class="cnblogs_code_collapse">View Code</span> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">训练的结果如下：</span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:14px;">Training Accuracy: 99.850000

Evaluating the trained Linear SVM on a test set ...
Test Accuracy: 98.900000</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">ⓒ使用训练好的SVM分类进行邮件分类</span></p> 
   <div class="cnblogs_code"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
    <pre><span style="font-size:14px;">%% =================== Part 6: Try Your Own Emails =====================
%  Now that you've trained the spam classifier, you can use it on your own
%  emails! In the starter code, we have included spamSample1.txt,
%  spamSample2.txt, emailSample1.txt and emailSample2.txt as examples. 
% <span style="color:rgb(255,0,0);"> The following code reads in one of these emails and then uses your</span> 
%  <span style="color:rgb(255,0,0);">learned SVM classifier to determine whether the email is Spam or</span> 
%  <span style="color:rgb(255,0,0);">Not Spam</span>

% Set the file to be read in (change this to spamSample2.txt,
% emailSample1.txt or emailSample2.txt to see different predictions on
% different emails types). Try your own emails as well!
<span style="color:rgb(255,0,0);">filename = 'emailSample1.txt';</span>

% Read and predict
file_contents = readFile(filename);
word_indices  = processEmail(file_contents);
x             = emailFeatures(word_indices);
<span style="color:rgb(255,0,0);">p = svmPredict(model, x);</span>

fprintf('\nProcessed %s\n\nSpam Classification: %d\n', filename, p);
fprintf('(1 indicates spam, 0 indicates not spam)\n\n');</span></pre> 
    <pre><span style="font-size:14px;"><br></span></pre> 
    <pre><span style="font-size:14px;">本文转自hapjin博客园博客，原文链接：http://www.cnblogs.com/hapjin/，如需转载请自行联系原作者<br></span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
   </div> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
