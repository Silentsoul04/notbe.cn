<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Spark RDD/Core 编程 API入门系列之动手实战和调试Spark文件操作、动手实战操作搜狗日志文件、搜狗日志文件深入实战（二）... « NotBeCN</title>
  <meta name="description" content="             1、动手实战和调试Spark文件操作    &nbsp;    　　这里，我以指定executor-memory参数的方式，启动spark-shell。    &nbsp;    启动hadoop集群    spark@SparkSingleNode:/usr/local/hadoop/...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/21/weixin_34162695_90135496.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">Spark RDD/Core 编程 API入门系列之动手实战和调试Spark文件操作、动手实战操作搜狗日志文件、搜狗日志文件深入实战（二）...</h1>
    <p class="post-meta">Nov 21, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;"><strong>1、动手实战和调试Spark文件操作</strong></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　这里，我以指定executor-memory参数的方式，启动spark-shell。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">启动hadoop集群</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ jps<br> 8457 Jps<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$&nbsp;<span style="color:rgb(255,0,0);">sbin/start-dfs.sh</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926223307594-1191489375.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">启动spark集群</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/spark/spark-1.5.2-bin-hadoop2.6$&nbsp;<span style="color:rgb(255,0,0);">sbin/start-all.sh</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926223327875-23728940.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/spark/spark-1.5.2-bin-hadoop2.6/bin$<span style="color:rgb(255,0,0);">&nbsp;./spark-shell --master spark://SparkSingleNode:7077 --executor-memory 1g</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="color:rgb(255,0,0);">　　在命令行中，我指定了spark-shell运行时暂时用的每个机器上executor的内存大小为1GB。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="color:rgb(255,0,0);"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926223636391-1292860269.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926223743110-371019152.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926223854906-1875293742.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">从HDFS上读取该文件</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926224139641-1121753456.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt; val rdd1 = sc.textFile("/README.md")</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">或</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt; val rdd1 = sc.textFile("hdfs:SparkSingleNode:9000/README.md")</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926224612688-1112957548.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">返回，MapPartitionsRDD</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">使用，toDebugString，可以查看其lineage的关系。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">rdd1: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:21</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">rdd1.toDebugString</span><br> 16/09/26 22:47:01 INFO mapred.FileInputFormat: Total input paths to process : 1<br> res0: String =&nbsp;<br> (2)&nbsp;<strong>MapPartitionsRDD</strong>[1] at textFile at &lt;console&gt;:21 []<br> | /README.md&nbsp;<strong>HadoopRDD</strong>[0] at textFile at &lt;console&gt;:21 []</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926224759219-1019462155.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">可以看出，MapPartitionsRDD是HadoopRDD转换而来的。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">hadoopFile，这个方法，产生HadoopRDD</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">map，这个方法，产生MapPartitionsRDD</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;"><strong>从源码分析过程</strong></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926225341906-1893406753.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926225601110-1692065631.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926225643094-370165607.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926225830985-1102385516.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">val result = rdd1.flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926230509938-1698681487.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926230546188-1415616402.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">le&gt;:23, took 15.095588 s<br> result: Array[(String, Int)] = Array((package,1), (this,1), (Version"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (cluster.,1), (its,1), ([run,1), (general,2), (have,1), (pre-built,1), (locally.,1), (locally,2), (changed,1), (sc.parallelize(1,1), (only,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (YARN,,1), (graph,1), (Hive,2), (first,1), (["Specifying,1), ("yarn-client",1), (page](http://spark.apache.org/documentation.html),1), ([params]`.,1), (application,1), ([project,2), (prefer,1), (SparkPi,2), (&lt;http://spark.apache.org/&gt;,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), (distribution.,1), (are,1), (params,1), (scala&gt;,1), (DataFram...<br> scala&gt;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;"><strong><span style="color:rgb(255,0,0);">不可这样使用toDebugString</span></strong></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt; result.toDebugString<br> &lt;console&gt;:26: error: value toDebugString is not a member of Array[(String, Int)]<br> result.toDebugString</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926230824125-1840662523.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926230949969-1353316824.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">val wordcount = rdd1.flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_)</span><br> wordcount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[10] at reduceByKey at &lt;console&gt;:23</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">wordcount.toDebugString</span><br> res3: String =&nbsp;<br> (2) ShuffledRDD[10] at reduceByKey at &lt;console&gt;:23 []<br> +-(2) MapPartitionsRDD[9] at map at &lt;console&gt;:23 []<br> | MapPartitionsRDD[8] at flatMap at &lt;console&gt;:23 []<br> | MapPartitionsRDD[1] at textFile at &lt;console&gt;:21 []<br> | /README.md HadoopRDD[0] at textFile at &lt;console&gt;:21 []</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">或者</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926232200281-1230862621.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160926232208750-1665172828.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;color:rgb(255,0,0);"><strong>&nbsp;疑问：为什么没有MappedRDD？难道是版本问题？？</strong></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;"><strong>2、动手实战操作搜狗日志文件</strong></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">本节中所用到的内容是来自搜狗实验室，网址为：<a href="http://www.sogou.com/labs/dl/q.html" rel="nofollow" style="color:#000000;">http://www.sogou.com/labs/dl/q.html</a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">我们使用的是迷你版本的tar.gz格式的文件，其大小为87K，下载后如下所示：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">因为，考虑我的机器内存的自身情况。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927090122703-75434702.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927090135719-1884417739.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927090153938-1202404705.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">或者</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:~$&nbsp;<span style="color:rgb(255,0,0);">wget http://download.labs.sogou.com/dl/sogoulabdown/SogouQ/SogouQ2012.mini.tar.gz</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:~$&nbsp;<span style="color:rgb(255,0,0);">tar -zxvf SogouQ2012.mini.tar.gz</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927090856203-1862296179.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">查看它的部分内容</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:~$&nbsp;<span style="color:rgb(255,0,0);">head SogouQ.mini&nbsp;</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927090959235-822839008.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">该文件的格式如下所示：<br><br><span style="color:rgb(255,0,0);">访问时间 \t 用户ID \t 查询词 \t 该URL在返回结果中的排名 \ t用户点击的顺序号 \t 用户点击的URL</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="color:rgb(255,0,0);">&nbsp;</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="color:rgb(255,0,0);">开启hdfs和spark集群</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="color:rgb(255,0,0);"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927091549750-657731100.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">把解压后的文件上传到hdfs的/目录下</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$<span style="color:rgb(255,0,0);">&nbsp;bin/hadoop fs -copyFromLocal ~/SogouQ.mini /</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927091728688-1536562598.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927091719797-358277764.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">开启spark-shell</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/spark/spark-1.5.2-bin-hadoop2.6/bin$&nbsp;<span style="color:rgb(255,0,0);">./spark-shell --master spark://SparkSingleNode:7077</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927092036438-1318959932.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">接下来 我们使用Spark获得搜索结果排名第一同时点击结果排名也是第一的数据量，也就是第四列值为1同时第五列的值也为1的总共的记录的个数。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;读取SogouQ.mini文件</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927092258313-1914176994.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">val soGouQRdd = sc.textFile("hdfs://SparkSingleNode:9000/SogouQ.mini")</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">soGouQRdd.count</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927094237172-1261089479.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927094249391-384280344.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">took 10.753423 s<br> res0: Long = 2000</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">可以看出，count之后有2000条记录</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927094706000-684689706.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">首先过滤出有效的数据：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">val mapSoGouQRdd = soGouQRdd.map((_.split("\t"))).filter(_.length == 6)</span><br> mapSoGouQRdd: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at filter at &lt;console&gt;:23</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">mapSoGouQRdd.count</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927094613891-740045441.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927094745078-512606559.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">took 2.175379 s<br> res1: Long = 2000</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">可以发现该文件中的数据都是有效数据。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">该文件的格式如下所示：<br> 访问时间 \t 用户ID \t&nbsp;<span style="color:rgb(255,0,0);">查询词</span>&nbsp;\t&nbsp;<span style="color:rgb(255,0,0);">该URL在返回结果中的排名</span>&nbsp;\ t用户点击的顺序号 \t 用户点击的URL</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927095155610-451067969.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">下面使用spark获得搜索结果排名第一同时点击结果排名也是第一的数据量：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;<span style="color:rgb(255,0,0);">&nbsp;val filterSoGouQRdd = mapSoGouQRdd.filter(_(3).toInt == 1).filter(_(4).toInt == 1)</span><br> filterSoGouQRdd: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[5] at filter at &lt;console&gt;:25</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">filterSoGouQRdd.count</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927095104063-1745991566.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927095241406-635570535.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">可以发现搜索结果排名第一同时点击结果排名也是第一的数据量为794条；</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">使用toDebugString查看一下其lineage：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;<span style="color:rgb(255,0,0);">&nbsp;filterSoGouQRdd.toDebugString</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927095352547-495732684.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">res3: String =&nbsp;<br> (2) MapPartitionsRDD[5] at filter at &lt;console&gt;:25 []<br> | MapPartitionsRDD[4] at filter at &lt;console&gt;:25 []<br> | MapPartitionsRDD[3] at filter at &lt;console&gt;:23 []<br> | MapPartitionsRDD[2] at map at &lt;console&gt;:23 []<br> | MapPartitionsRDD[1] at textFile at &lt;console&gt;:21 []<br> | hdfs://SparkSingleNode:9000/SogouQ.mini HadoopRDD[0] at textFile at &lt;console&gt;:21 []</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">为什么没有？</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="color:rgb(255,0,0);">&nbsp;HadoopRDD-&gt;MappedRDD-&gt;MappedRDD-&gt;FilteredRDD-&gt;FilteredRDD-&gt;FilteredRDD</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;"><strong>&nbsp;3、搜狗日志文件深入实战</strong></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;下面看，用户ID查询次数排行榜：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">该文件的格式如下所示：<br> 访问时间 \t&nbsp;<span style="color:rgb(255,0,0);">用户ID</span>&nbsp;\t&nbsp;查询词&nbsp;\t&nbsp;该URL在返回结果中的排名&nbsp;\ t用户点击的顺序号 \t 用户点击的URL</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927095155610-451067969.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;<span style="color:rgb(255,0,0);">&nbsp;val sortedSoGouQRdd = mapSoGouQRdd.map(x =&gt; (x(1),1)).reduceByKey(_+_).map(x =&gt; (x._2,x._1)).sortByKey(false).map(x =&gt; (x._2,x._1))</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927100306531-424038474.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;对sortedSogouQRdd进行collect操作：（不要乱collect 会出现OOM的）</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">sortedSoGouQRdd.collect</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927100530828-589336778.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927100558703-1561194820.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">res4: Array[(String, Int)] = Array((f6492a1da9875f20e01ff8b5804dcc35,14), (e7579c6b6b9c0ea40ecfa0f425fc765a,11), (d3034ac9911c30d7cf9312591ecf990e,11), (5c853e91940c5eade7455e4a289722d6,10), (ec0363079f36254b12a5e30bdc070125,10), (828f91e6717213a65c97b694e6279201,9), (2a36742c996300d664652d9092e8a554,9), (439fa809ba818cee624cc8b6e883913a,9), (45c304b5f2dd99182451a02685252312,8), (5ea391fd07dbb616e9857a7d95f460e0,8), (596444b8c02b7b30c11273d5bbb88741,8), (a06830724b809c0db56263124b2bd142,8), (6056710d9eafa569ddc800fe24643051,7), (bc8cc0577bb80fafd6fad1ed67d3698e,7), (8897bbb7bdff69e80f7fb2041d83b17d,7), (41389fb54f9b3bec766c5006d7bce6a2,7), (b89952902d7821db37e8999776b32427,6), (29ede0f2544d28b714810965400ab912,6), (74033165c877f4082e14c1e94d1efff4,6), (833f242ff430c83d293980ec10a42484,6...<br> scala&gt;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">把结果保存在hdfs上：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;&nbsp;<span style="color:rgb(255,0,0);">sortedSoGouQRdd.saveAsTextFile("hdfs://SparkSingleNode:9000/soGouQSortedResult.txt")</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927100836422-1290717880.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927100921438-717763753.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">把这些，输出信息，看懂，深入，是大牛必经之路。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt; sortedSoGouQRdd.saveAsTextFile("hdfs://SparkSingleNode:9000/soGouQSortedResult.txt")<br> 16/09/27 10:08:34 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id<br> 16/09/27 10:08:34 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id<br> 16/09/27 10:08:34 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap<br> 16/09/27 10:08:34 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition<br> 16/09/27 10:08:34 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id<br> 16/09/27 10:08:35 INFO spark.SparkContext: Starting job: saveAsTextFile at &lt;console&gt;:28<br> 16/09/27 10:08:35 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 155 bytes<br> 16/09/27 10:08:35 INFO scheduler.DAGScheduler: Got job 5 (saveAsTextFile at &lt;console&gt;:28) with 2 output partitions<br> 16/09/27 10:08:35 INFO scheduler.DAGScheduler: Final stage: ResultStage 10(saveAsTextFile at &lt;console&gt;:28)<br> 16/09/27 10:08:35 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)<br> 16/09/27 10:08:35 INFO scheduler.DAGScheduler: Missing parents: List()<br> 16/09/27 10:08:35 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[13] at saveAsTextFile at &lt;console&gt;:28), which has no missing parents<br> 16/09/27 10:08:35 INFO storage.MemoryStore: ensureFreeSpace(128736) called with curMem=105283, maxMem=560497950<br> 16/09/27 10:08:35 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 125.7 KB, free 534.3 MB)<br> 16/09/27 10:08:36 INFO storage.MemoryStore: ensureFreeSpace(43435) called with curMem=234019, maxMem=560497950<br> 16/09/27 10:08:36 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 42.4 KB, free 534.3 MB)<br> 16/09/27 10:08:36 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.80.128:33999 (size: 42.4 KB, free: 534.5 MB)<br> 16/09/27 10:08:36 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861<br> 16/09/27 10:08:36 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[13] at saveAsTextFile at &lt;console&gt;:28)<br> 16/09/27 10:08:36 INFO scheduler.TaskSchedulerImpl: Adding task set 10.0 with 2 tasks<br> 16/09/27 10:08:36 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 14, 192.168.80.128, PROCESS_LOCAL, 1901 bytes)<br> 16/09/27 10:08:36 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.80.128:59936 (size: 42.4 KB, free: 534.5 MB)<br> 16/09/27 10:08:41 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.0 (TID 15, 192.168.80.128, PROCESS_LOCAL, 1901 bytes)<br> 16/09/27 10:08:41 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 14) in 5813 ms on 192.168.80.128 (1/2)<br> 16/09/27 10:08:43 INFO scheduler.DAGScheduler: ResultStage 10 (saveAsTextFile at &lt;console&gt;:28) finished in 7.719 s<br> 16/09/27 10:08:43 INFO scheduler.DAGScheduler: Job 5 finished: saveAsTextFile at &lt;console&gt;:28, took 8.348232 s<br> 16/09/27 10:08:43 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 10.0 (TID 15) in 2045 ms on 192.168.80.128 (2/2)<br> 16/09/27 10:08:43 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">scala&gt;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927101036656-723205017.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927101051203-575933689.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927101156235-541607247.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927101205672-80307164.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">hdfs命令行查询：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">part-0000：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$&nbsp;<span style="color:rgb(255,0,0);">bin/hadoop fs -text /soGouQSortedResult.txt/part-00000</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927101611781-1904237703.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">hdfs命令行查询：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">part-0000：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$&nbsp;<span style="color:rgb(255,0,0);">bin/hadoop fs -text /soGouQSortedResult.txt/part-00001</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927101753391-2016537046.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;我们通过hadoop命令把上述两个文件的内容合并起来：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$&nbsp;<span style="color:rgb(255,0,0);">bin/hadoop fs -getmerge hdfs://SparkSingleNode:9000/soGouQSortedResult.txt combinedSortedResult.txt &nbsp; &nbsp; &nbsp;//注意，第二个参数，是本地文件的目录</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927102447469-419710047.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ bin/hadoop fs -ls /<br> Found 6 items<br> -rw-r--r-- 1 spark supergroup 3593 2016-09-18 10:15 /README.md<br> -rw-r--r-- 1 spark supergroup 216118 2016-09-27 09:17 /SogouQ.mini<br> drwxr-xr-x - spark supergroup 0 2016-09-26 21:17 /result<br> drwxr-xr-x - spark supergroup 0 2016-09-26 21:49 /resultDescSorted<br> drwxr-xr-x - spark supergroup 0 2016-09-27 10:08 /soGouQSortedResult.txt<br> drwx-wx-wx - spark supergroup 0 2016-09-09 16:28 /tmp<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ ls<br> bin etc libexec NOTICE.txt share<br> combinedSortedResult.txt include LICENSE.txt README.txt tmp<br> dfs lib logs sbin<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927102555485-1196993419.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">或者</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$&nbsp;<span style="color:rgb(255,0,0);">bin/hdfs dfs -getmerge hdfs://SparkSingleNode:9000/soGouQSortedResult.txt combinedSortedResult.txt &nbsp; &nbsp; &nbsp; //两者是等价的</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927102829766-1356996144.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ ls<br> bin etc lib LICENSE.txt NOTICE.txt sbin tmp<br> dfs include libexec logs README.txt share<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ cd bin<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0/bin$ ls<br> container-executor hdfs mapred.cmd yarn<br> hadoop hdfs.cmd rcc yarn.cmd<br> hadoop.cmd mapred test-container-executor<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0/bin$ cd hdfs<br> bash: cd: hdfs: Not a directory<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0/bin$ cd ..<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ bin/hdfs dfs -getmerge hdfs://SparkSingleNode:9000/soGouQSortedResult.txt combinedSortedResult.txt<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$ ls<br> bin etc libexec NOTICE.txt share<br> combinedSortedResult.txt include LICENSE.txt README.txt tmp<br> dfs lib logs sbin<br> spark@SparkSingleNode:/usr/local/hadoop/hadoop-2.6.0$</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<img src="https://images2015.cnblogs.com/blog/855959/201609/855959-20160927102929656-247076419.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br></p> 
   <p><font><span style="font-size:14px;">本文转自大数据躺过的坑博客园博客，原文链接：http://www.cnblogs.com/zlslch/p/5911131.html，如需转载请自行联系原作者</span></font><br></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
