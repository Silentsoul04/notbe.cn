<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>用scikit-learn学习K-Means聚类 « NotBeCN</title>
  <meta name="description" content="             1. K-Means类概述    　　　　在scikit-learn中，包括两个K-Means的算法，一个是传统的K-Means算法，对应的类是KMeans。另一个是基于采样的Mini Batch K-Means算法，对应的类是MiniBatchKMeans。一般来说，使用K-Means...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/22/weixin_34292402_90125230.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">用scikit-learn学习K-Means聚类</h1>
    <p class="post-meta">Nov 22, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">1. K-Means类概述</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　在scikit-learn中，包括两个K-Means的算法，一个是传统的K-Means算法，对应的类是KMeans。另一个是基于采样的Mini Batch K-Means算法，对应的类是MiniBatchKMeans。一般来说，使用K-Means的算法调参是比较简单的。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　用KMeans类的话，一般要注意的仅仅就是k值的选择，即参数n_clusters；如果是用MiniBatchKMeans的话，也仅仅多了需要注意调参的参数batch_size，即我们的Mini Batch的大小。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　当然KMeans类和MiniBatchKMeans类可以选择的参数还有不少，但是大多不需要怎么去调参。下面我们就看看KMeans类和MiniBatchKMeans类的一些主要参数。</p> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">2.&nbsp;KMeans类主要参数</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　KMeans类的主要参数有：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　1)&nbsp;<strong>n_clusters</strong>: 即我们的k值，一般需要多试一些值以获得较好的聚类效果。k值好坏的评估标准在下面会讲。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　2）<strong>max_iter</strong>： 最大的迭代次数，一般如果是凸数据集的话可以不管这个值，如果数据集不是凸的，可能很难收敛，此时可以指定最大的迭代次数让算法可以及时退出循环。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　3）<strong>n_init：</strong>用不同的初始化质心运行算法的次数。由于K-Means是结果受初始值影响的局部最优的迭代算法，因此需要多跑几次以选择一个较好的聚类效果，默认是10，一般不需要改。如果你的k值较大，则可以适当增大这个值。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　4）<strong>init：&nbsp;</strong>即初始值选择的方式，可以为完全随机选择'random',优化过的'k-means++'或者自己指定初始化的k个质心。一般建议使用默认的'k-means++'。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　5）<strong>algorithm</strong>：有“auto”, “full” or “elkan”三种选择。"full"就是我们传统的K-Means算法，&nbsp;“elkan”是我们原理篇讲的elkan K-Means算法。默认的"auto"则会根据数据值是否是稀疏的，来决定如何选择"full"和“elkan”。一般数据是稠密的，那么就是&nbsp;“elkan”，否则就是"full"。一般来说建议直接用默认的"auto"</p> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">3. MiniBatchKMeans类主要参数</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　MiniBatchKMeans类的主要参数比KMeans类稍多，主要有：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　1)&nbsp;<strong>n_clusters</strong>: 即我们的k值，和KMeans类的n_clusters意义一样。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　2）<strong>max_iter：</strong>最大的迭代次数，&nbsp;和KMeans类的max_iter意义一样。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　3）<strong>n_init：</strong>用不同的初始化质心运行算法的次数。这里和KMeans类意义稍有不同，KMeans类里的n_init是用同样的训练集数据来跑不同的初始化质心从而运行算法。而MiniBatchKMeans类的n_init则是每次用不一样的采样数据集来跑不同的初始化质心运行算法。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><strong>　　　　</strong>4）<strong>batch_size</strong>：即用来跑Mini Batch KMeans算法的采样集的大小，默认是100.如果发现数据集的类别较多或者噪音点较多，需要增加这个值以达到较好的聚类效果。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　5）<strong>init：&nbsp;</strong>即初始值选择的方式，和KMeans类的init意义一样。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　6）<strong>init_size:&nbsp;</strong>用来做质心初始值候选的样本个数，默认是batch_size的3倍，一般用默认值就可以了。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　7）<strong>reassignment_ratio:&nbsp;</strong>某个类别质心被重新赋值的最大次数比例，这个和max_iter一样是为了控制算法运行时间的。这个比例是占样本总数的比例，乘以样本总数就得到了每个类别质心可以重新赋值的次数。如果取值较高的话算法收敛时间可能会增加，尤其是那些暂时拥有样本数较少的质心。默认是0.01。如果数据量不是超大的话，比如1w以下，建议使用默认值。如果数据量超过1w，类别又比较多，可能需要适当减少这个比例值。具体要根据训练集来决定。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　8）<strong>max_no_improvement：</strong>即连续多少个Mini Batch没有改善聚类效果的话，就停止算法， 和reassignment_ratio，<strong>&nbsp;</strong>max_iter一样是为了控制算法运行时间的。默认是10.一般用默认值就足够了。</p> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">4. K值的评估标准</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　不像监督学习的分类问题和回归问题，我们的无监督聚类没有样本输出，也就没有比较直接的聚类评估方法。但是我们可以从簇内的稠密程度和簇间的离散程度来评估聚类的效果。常见的方法有轮廓系数Silhouette Coefficient和Calinski-Harabasz Index。个人比较喜欢Calinski-Harabasz Index，这个计算简单直接，得到的Calinski-Harabasz分数值<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">s</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.079em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">s</span></span>越大则聚类效果越好。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　Calinski-Harabasz分数值<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">s</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.079em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">s</span></span>的数学计算公式是：</p> 
   <div class="MathJax_Display" style="text-align:center;width:669px;">
    <span class="MathJax" style="line-height:normal;font-size:12px;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">s</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">(</span><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">k</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">)</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">=</span><span class="mfrac" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">t</span><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">r</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">(</span><span class="msubsup" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">B</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-size:12px;font-family:'MathJax_Math-italic';">k</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">)</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">t</span><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">r</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">(</span><span class="msubsup" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">W<span style="border:0px;vertical-align:0px;line-height:normal;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-size:12px;font-family:'MathJax_Math-italic';">k</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">)</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border-width:1.3px 0px 0px;border-top-style:solid;vertical-align:0em;line-height:normal;"></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span><span class="mfrac" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">m</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">−</span><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">k</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">k</span><span class="mo" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">−</span><span class="mn" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Main';">1</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border-width:1.3px 0px 0px;border-top-style:solid;vertical-align:0em;line-height:normal;"></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-1.329em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" style="border:0px;width:142.891px;vertical-align:0px;line-height:normal;">s(k)=tr(Bk)tr(Wk)m−kk−1</span></span>
   </div> 
   <p></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　其中m为训练集样本数，k为类别数。<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="msubsup" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">B</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-size:12px;font-family:'MathJax_Math-italic';">k</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.246em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">Bk</span></span>为类别之间的协方差矩阵，<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="msubsup" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">W<span style="border:0px;vertical-align:0px;line-height:normal;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-size:12px;font-family:'MathJax_Math-italic';">k</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.246em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">Wk</span></span>为类别内部数据的协方差矩阵。<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">t</span><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">r</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.079em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">tr</span></span>为矩阵的迹。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　也就是说，类别内部数据的协方差越小越好，类别之间的协方差越大越好，这样的Calinski-Harabasz分数会高。在scikit-learn中，&nbsp;Calinski-Harabasz Index对应的方法是metrics.calinski_harabaz_score.</p> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">5.&nbsp;K-Means应用实例</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　下面用一个实例来讲解用KMeans类和MiniBatchKMeans类来聚类。我们观察在不同的k值下Calinski-Harabasz分数。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　首先我们随机创建一些二维数据作为训练集，选择二维特征数据，主要是方便可视化。代码如下：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> numpy as np
</span><span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> matplotlib.pyplot as plt
</span>%<span style="line-height:1.5;">matplotlib inline
</span><span style="color:rgb(0,0,255);line-height:1.5;">from</span> sklearn.datasets.samples_generator <span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> make_blobs
</span><span style="color:rgb(0,128,0);line-height:1.5;">#</span><span style="color:rgb(0,128,0);line-height:1.5;"> X为样本特征，Y为样本簇类别， 共1000个样本，每个样本4个特征，共4个簇，簇中心在[-1,-1], [0,0],[1,1], [2,2]， 簇方差分别为[0.4, 0.2, 0.2]</span>
X, y = make_blobs(n_samples=1000, n_features=2, centers=[[-1,-1], [0,0], [1,1], [2,2]], cluster_std=[0.4, 0.2, 0.2, 0.2<span style="line-height:1.5;">], 
                  random_state </span>=9<span style="line-height:1.5;">)
plt.scatter(X[:, 0], X[:, </span>1], marker=<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">o</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">)
plt.show()</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　从输出图可以我们看看我们创建的数据如下：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213143259370-1291177869.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　现在我们来用K-Means聚类方法来做聚类，首先选择k=2，代码如下：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">from</span> sklearn.cluster <span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> KMeans
y_pred </span>= KMeans(n_clusters=2, random_state=9<span style="line-height:1.5;">).fit_predict(X)
plt.scatter(X[:, 0], X[:, </span>1], c=<span style="line-height:1.5;">y_pred)
plt.show()</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　k=2聚类的效果图输出如下：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213143444854-1882584288.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在我们来看看我们用Calinski-Harabasz Index评估的聚类分数:</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">from</span> sklearn <span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> metrics
metrics.calinski_harabaz_score(X, y_pred)  </span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　输出如下：</p> 
   <pre>3116.1706763322227</pre> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在k=3来看看聚类效果，代码如下：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">from</span> sklearn.cluster <span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> KMeans
y_pred </span>= KMeans(n_clusters=3, random_state=9<span style="line-height:1.5;">).fit_predict(X)
plt.scatter(X[:, 0], X[:, </span>1], c=<span style="line-height:1.5;">y_pred)
plt.show()</span>　　</pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　k=3的聚类的效果图输出如下：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213144007542-1923430558.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在我们来看看我们用Calinski-Harabaz Index评估的k=3时候聚类分数:</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre>metrics.calinski_harabaz_score(X, y_pred)  </pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　输出如下：</p> 
   <pre>2931.625030199556</pre> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　可见此时k=3的聚类分数比k=2还差。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在我们看看k=4时候的聚类效果：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">from</span> sklearn.cluster <span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> KMeans
y_pred </span>= KMeans(n_clusters=4, random_state=9<span style="line-height:1.5;">).fit_predict(X)
plt.scatter(X[:, 0], X[:, </span>1], c=<span style="line-height:1.5;">y_pred)
plt.show()</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　k=4的聚类的效果图输出如下：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213144309354-169800692.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在我们来看看我们用Calinski-Harabasz Index评估的k=4时候聚类分数:</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre>metrics.calinski_harabaz_score(X, y_pred)  </pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　输出如下：</p> 
   <pre>5924.050613480169</pre> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　可见k=4的聚类分数比k=2和k=3都要高，这也符合我们的预期，我们的随机数据集也就是4个簇。当特征维度大于2，我们无法直接可视化聚类效果来肉眼观察时，用Calinski-Harabaz Index评估是一个很实用的方法。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在我们再看看用MiniBatchKMeans的效果，我们将batch size设置为200. 由于我们的4个簇都是凸的，所以其实batch size的值只要不是非常的小，对聚类的效果影响不大。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">for</span> index, k <span style="color:rgb(0,0,255);line-height:1.5;">in</span> enumerate((2,3,4,5<span style="line-height:1.5;">)):
    plt.subplot(</span>2,2,index+1<span style="line-height:1.5;">)
    y_pred </span>= MiniBatchKMeans(n_clusters=k, batch_size = 200, random_state=9<span style="line-height:1.5;">).fit_predict(X)
    score</span>=<span style="line-height:1.5;"> metrics.calinski_harabaz_score(X, y_pred)  
    plt.scatter(X[:, 0], X[:, </span>1], c=<span style="line-height:1.5;">y_pred)
    plt.text(.</span>99, .01, (<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">k=%d, score: %.2f</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span> %<span style="line-height:1.5;"> (k,score)),
                 transform</span>=plt.gca().transAxes, size=10<span style="line-height:1.5;">,
                 horizontalalignment</span>=<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">right</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">)
plt.show()</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　对于k=2,3,4,5对应的输出图为：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161213154105901-1056813722.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　可见使用MiniBatchKMeans的聚类效果也不错，当然由于使用Mini Batch的原因，同样是k=4最优，KMeans类的Calinski-Harabasz Index分数为5924.05,而MiniBatchKMeans的分数稍微低一些，为5921.45。这个差异损耗并不大。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><br></p> 
   <p><font><span style="font-size:12px;">本文转自刘建平Pinard博客园博客，原文链接：http://www.cnblogs.com/pinard/p/6169370.html，如需转载请自行联系原作者</span></font></p> 
   <div>
    <br>
   </div> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
