<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>用gensim学习word2vec « NotBeCN</title>
  <meta name="description" content="             在word2vec原理篇中，我们对word2vec的两种模型CBOW和Skip-Gram，以及两种解法Hierarchical Softmax和Negative Sampling做了总结。这里我们就从实践的角度，使用gensim来学习word2vec。    1. gensim安装与概述...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/22/weixin_33743661_90133521.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">用gensim学习word2vec</h1>
    <p class="post-meta">Nov 22, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">在<a href="http://www.cnblogs.com/pinard/p/7160330.html" rel="nofollow" style="color:rgb(0,0,0);">word2vec原理篇</a>中，我们对word2vec的两种模型CBOW和Skip-Gram，以及两种解法Hierarchical Softmax和Negative Sampling做了总结。这里我们就从实践的角度，使用gensim来学习word2vec。</p> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">1. gensim安装与概述</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　gensim是一个很好用的Python NLP的包，不光可以用于使用word2vec，还有很多其他的API可以用。它封装了google的C语言版的word2vec。当然我们可以可以直接使用C语言版的word2vec来学习，但是个人认为没有gensim的python版来的方便。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　安装gensim是很容易的，使用"pip install gensim"即可。但是需要注意的是gensim对numpy的版本有要求，所以安装过程中可能会偷偷的升级你的numpy版本。而windows版的numpy直接装或者升级是有问题的。此时我们需要卸载numpy，并重新下载带mkl的符合gensim版本要求的numpy，下载地址在此：http://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy。安装方法和<a id="cb_post_title_url" class="postTitle2" href="http://www.cnblogs.com/pinard/p/6013484.html" rel="nofollow" style="color:rgb(0,0,0);">scikit-learn 和pandas 基于windows单机机器学习环境的搭建</a>这一篇第4步的方法一样。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　安装成功的标志是你可以在代码里做下面的import而不出错：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">from</span> gensim.models <span style="color:rgb(0,0,255);line-height:1.5;">import</span> word2vec</pre>
   </div> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">2. gensim word2vec API概述</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　在gensim中，word2vec 相关的API都在包gensim.models.word2vec中。和算法有关的参数都在类gensim.models.word2vec.Word2Vec<code class="descname">中。算法需要注意的参数有：</code></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　1)&nbsp;sentences: 我们要分析的语料，可以是一个列表，或者从文件中遍历读出。后面我们会有从文件读出的例子。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　2)&nbsp;size: 词向量的维度，默认值是100。这个维度的取值一般与我们的语料的大小相关，如果是不大的语料，比如小于100M的文本语料，则使用默认值一般就可以了。如果是超大的语料，建议增大维度。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　3)&nbsp;window：即词向量上下文最大距离，这个参数在我们的算法原理篇中标记为<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">c</span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.079em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">c</span></span>，window越大，则和某一词较远的词也会产生上下文关系。默认值为5。在实际使用中，可以根据实际的需求来动态调整这个window的大小。如果是小语料则这个值可以设的更小。对于一般的语料这个值推荐在[5,10]之间。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　4) sg: 即我们的word2vec两个模型的选择了。如果是0， 则是CBOW模型，是1则是Skip-Gram模型，默认是0即CBOW模型。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　5) hs: 即我们的word2vec两个解法的选择了，如果是0， 则是Negative Sampling，是1的话并且负采样个数negative大于0， 则是Hierarchical Softmax。默认是0即Negative Sampling。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　6)&nbsp;negative:即使用Negative Sampling时负采样的个数，默认是5。推荐在[3,10]之间。这个参数在我们的算法原理篇中标记为neg。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　7)&nbsp;cbow_mean: 仅用于CBOW在做投影的时候，为0，则算法中的<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="msubsup" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">x</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-size:12px;font-family:'MathJax_Math-italic';">w</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.246em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">xw</span></span>为上下文的词向量之和，为1则为上下文的词向量的平均值。在我们的原理篇中，是按照词向量的平均值来描述的。个人比较喜欢用平均值来表示<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="msubsup" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">x</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-size:12px;font-family:'MathJax_Math-italic';">w</span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.246em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">xw</span></span>,默认值也是1,不推荐修改默认值。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　8) min_count:需要计算词向量的最小词频。这个值可以去掉一些很生僻的低频词，默认是5。如果是小语料，可以调低这个值。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;"><em>　　　　9)</em>&nbsp;iter: 随机梯度下降法中迭代的最大次数，默认是5。对于大语料，可以增大这个值。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　10)&nbsp;alpha: 在随机梯度下降法中迭代的初始步长。算法原理篇中标记为<span class="MathJax" style="line-height:normal;word-spacing:normal;border:0px;"><span class="math" style="border:0px;vertical-align:0px;line-height:normal;"><span style="border:0px;vertical-align:0px;line-height:normal;font-size:15.12px;"><span style="border:0px;vertical-align:0px;line-height:normal;"><span class="mrow" style="border:0px;vertical-align:0px;line-height:normal;"><span class="mi" style="border:0px;vertical-align:0px;line-height:normal;font-family:'MathJax_Math-italic';">η<span style="border:0px;vertical-align:0px;line-height:normal;"></span></span></span><span style="border:0px;vertical-align:0px;line-height:normal;width:0px;"></span></span></span><span style="border-width:0px;border-left-style:solid;vertical-align:-.329em;line-height:normal;width:0px;"></span></span><span class="MJX_Assistive_MathML" style="border:0px;vertical-align:0px;line-height:normal;width:1px;">η</span></span>，默认是0.025。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　11)&nbsp;min_alpha: 由于算法支持在迭代的过程中逐渐减小步长，min_alpha给出了最小的迭代步长值。随机梯度下降中每轮的迭代步长可以由iter，alpha，&nbsp;min_alpha一起得出。这部分由于不是word2vec算法的核心内容，因此在原理篇我们没有提到。对于大语料，需要对alpha,&nbsp;min_alpha,iter一起调参，来选择合适的三个值。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　以上就是gensim word2vec的主要的参数，下面我们用一个实际的例子来学习word2vec。</p> 
   <h1 style="font-size:28px;line-height:1.5;font-family:Verdana, Arial, Helvetica, sans-serif;">3. gensim &nbsp;word2vec实战</h1> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　我选择的《人民的名义》的小说原文作为语料，语料原文在<a href="http://files.cnblogs.com/files/pinard/in_the_name_of_people.zip" rel="nofollow" style="color:rgb(0,0,0);">这里</a>。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　拿到了原文，我们首先要进行分词，这里使用结巴分词完成。在<a class="postTitle2" href="http://www.cnblogs.com/pinard/p/6744056.html" rel="nofollow" style="color:rgb(0,0,0);">中文文本挖掘预处理流程总结</a>中，我们已经对分词的原理和实践做了总结。因此，这里直接给出分词的代码，分词的结果，我们放到另一个文件中。代码如下, 加入下面的一串人名是为了结巴分词能更准确的把人名分出来。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="color:rgb(0,128,0);line-height:1.5;">#</span><span style="color:rgb(0,128,0);line-height:1.5;"> -*- coding: utf-8 -*-</span>

<span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> jieba
</span><span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> jieba.analyse

jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">沙瑞金</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">田国富</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">高育良</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">侯亮平</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">钟小艾</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">陈岩石</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">欧阳菁</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">易学习</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">王大路</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">蔡成功</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">孙连城</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">季昌明</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">丁义珍</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">郑西坡</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">赵东来</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">高小琴</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">赵瑞龙</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">林华华</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">陆亦可</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">刘新建</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)
jieba.suggest_freq(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">刘庆祝</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">, True)

with open(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">./in_the_name_of_people.txt</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">) as f:
    document </span>=<span style="line-height:1.5;"> f.read()
    
    </span><span style="color:rgb(0,128,0);line-height:1.5;">#</span><span style="color:rgb(0,128,0);line-height:1.5;">document_decode = document.decode('GBK')</span>
<span style="line-height:1.5;">    
    document_cut </span>=<span style="line-height:1.5;"> jieba.cut(document)
    </span><span style="color:rgb(0,128,0);line-height:1.5;">#</span><span style="color:rgb(0,128,0);line-height:1.5;">print  ' '.join(jieba_cut)  //如果打印结果，则分词效果消失，后面的result无法显示</span>
    result = <span style="color:rgb(128,0,0);line-height:1.5;">'</span> <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">.join(document_cut)
    result </span>= result.encode(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">utf-8</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">)
    with open(</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">./in_the_name_of_people_segment.txt</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>, <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">w</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">) as f2:
        f2.write(result)
f.close()
f2.close()</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　拿到了分词后的文件，在一般的NLP处理中，会需要去停用词。由于word2vec的算法依赖于上下文，而上下文有可能就是停词。因此对于word2vec，我们可以不用去停词。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　现在我们可以直接读分词后的文件到内存。这里使用了word2vec提供的LineSentence类来读文件，然后套用word2vec的模型。这里只是一个示例，因此省去了调参的步骤，实际使用的时候，你可能需要对我们上面提到一些参数进行调参。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="color:rgb(0,128,0);line-height:1.5;">#</span><span style="color:rgb(0,128,0);line-height:1.5;"> import modules &amp; set up logging</span>
<span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> logging
</span><span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> os
</span><span style="color:rgb(0,0,255);line-height:1.5;">from</span> gensim.models <span style="color:rgb(0,0,255);line-height:1.5;">import</span><span style="line-height:1.5;"> word2vec

logging.basicConfig(format</span>=<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">%(asctime)s : %(levelname)s : %(message)s</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>, level=<span style="line-height:1.5;">logging.INFO)

sentences </span>= word2vec.LineSentence(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">./in_the_name_of_people_segment.txt</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">) 

model </span>= word2vec.Word2Vec(sentences, hs=1,min_count=1,window=3,size=100)  </pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　模型出来了，我们可以用来做什么呢？这里给出三个常用的应用。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　第一个是最常用的，找出某一个词向量最相近的词集合，代码如下：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>req_count = 5
<span style="color:rgb(0,0,255);line-height:1.5;">for</span> key <span style="color:rgb(0,0,255);line-height:1.5;">in</span> model.wv.similar_by_word(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">沙瑞金</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>.decode(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">utf-8</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>), topn =100<span style="line-height:1.5;">):
    </span><span style="color:rgb(0,0,255);line-height:1.5;">if</span> len(key[0])==3<span style="line-height:1.5;">:
        req_count </span>-= 1
        <span style="color:rgb(0,0,255);line-height:1.5;">print</span> key[0], key[1<span style="line-height:1.5;">]
        </span><span style="color:rgb(0,0,255);line-height:1.5;">if</span> req_count ==<span style="line-height:1.5;"> 0:
            </span><span style="color:rgb(0,0,255);line-height:1.5;">break</span>;</pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;"><a title="复制代码" style="text-decoration:underline;border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　我们看看沙书记最相近的一些3个字的词（主要是人名）如下：</p> 
   <div class="output_subarea output_text output_stream output_stdout" style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">
    <pre>高育良 0.967257142067
李达康 0.959131598473
田国富 0.953414440155
易学习 0.943500876427
祁同伟 0.942932963371</pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　第二个应用是看两个词向量的相近程度，这里给出了书中两组人的相似程度：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">print</span> model.wv.similarity(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">沙瑞金</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>.decode(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">utf-8</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>), <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">高育良</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>.decode(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">utf-8</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="line-height:1.5;">))
</span><span style="color:rgb(0,0,255);line-height:1.5;">print</span> model.wv.similarity(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">李达康</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>.decode(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">utf-8</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>), <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">王大路</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>.decode(<span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">utf-8</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span>))</pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　输出如下：</p> 
   <div class="output_subarea output_text output_stream output_stdout" style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">
    <pre>0.961137455325
0.935589365706</pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　第三个应用是找出不同类的词，这里给出了人物分类题：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:12px;font-family:'Courier New';">
    <pre><span style="color:rgb(0,0,255);line-height:1.5;">print</span> model.wv.doesnt_match(u<span style="color:rgb(128,0,0);line-height:1.5;">"</span><span style="color:rgb(128,0,0);line-height:1.5;">沙瑞金 高育良 李达康 刘庆祝</span><span style="color:rgb(128,0,0);line-height:1.5;">"</span>.split())</pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　 &nbsp; word2vec也完成的很好，输出为"刘庆祝"。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:12px;">　　　　以上就是用gensim学习word2vec实战的所有内容，希望对大家有所帮助。</p> 
   <p><font><span style="font-size:12px;">本文转自刘建平Pinard博客园博客，原文链接：http://www.cnblogs.com/pinard/p/7278324.html</span></font><span style="font-size:12px;font-family:Verdana, Arial, Helvetica, sans-serif;">，如需转载请自行联系原作者</span></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
