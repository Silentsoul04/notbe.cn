<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>理解 OpenStack + Ceph （2）：Ceph 的物理和逻辑结构 [Ceph Architecture] « NotBeCN</title>
  <meta name="description" content="             本系列文章会深入研究 Ceph 以及 Ceph 和 OpenStack 的集成：    （1）安装和部署    （2）Ceph RBD 接口和工具    （3）Ceph 物理和逻辑结构    （4）Ceph 的基础数据结构    （5）Ceph 与 OpenStack 集成的实现    ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/13/weixin_34082854_90124754.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">理解 OpenStack + Ceph （2）：Ceph 的物理和逻辑结构 [Ceph Architecture]</h1>
    <p class="post-meta">Nov 13, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">本系列文章会深入研究 Ceph 以及 Ceph 和 OpenStack 的集成：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（1）<a href="http://www.cnblogs.com/sammyliu/p/4804037.html%20" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">安装和部署</a></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（2）<a href="http://www.cnblogs.com/sammyliu/p/4838139.html%20" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph RBD 接口和工具</a></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（3）<a href="http://www.cnblogs.com/sammyliu/p/4836014.html%20" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph 物理和逻辑结构</a></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（4）<a href="http://www.cnblogs.com/sammyliu/p/4843812.html%20" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph 的基础数据结构</a></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（5）<a href="http://www.cnblogs.com/sammyliu/p/4838138.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph 与 OpenStack 集成的实现</a></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（6）<a href="http://www.cnblogs.com/sammyliu/p/5066895.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">QEMU-KVM 和 Ceph RBD 的 缓存机制总结</a></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（7）<a href="http://www.cnblogs.com/sammyliu/p/5555218.html%20" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph 的基本操作和常见故障排除方法</a></p> 
   <h2 style="font-size:21px;line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">1.&nbsp;<span style="line-height:1.5;font-size:1.17em;">Ceph 集群的物理结构</span> </h2> 
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;"><span style="line-height:1.5;font-size:1.17em;">1.1 Ceph 内部集群</span></h3> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">从<a href="http://www.cnblogs.com/sammyliu/p/4804037.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">前一篇文章</a>&nbsp;我们知道，从物理上来讲，一个 Ceph 集群内部其实有几个子集群存在：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（1）MON（Montior）集群：MON 集群有由少量的、数目为奇数个的 Monitor 守护进程（Daemon）组成，它们负责通过维护 Ceph Cluster map 的一个主拷贝（master copy of Cluster map）来维护整 Ceph 集群的全局状态。理论上来讲，一个 MON 就可以完成这个任务，之所以需要一个多个守护进程组成的集群的原因是保证高可靠性。每个 Ceph node 上最多只能有一个 Monitor Daemon。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';">
    <pre>root@ceph1:~# ps -ef | grep ceph-mon
root       964     1  0 Sep18 ?        00:36:33 /usr/bin/ceph-mon --cluster=ceph -i ceph1 -f</pre>
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">实际上，除了维护 Cluster map 以外，MON 还承担一些别的任务，比如用户校验、日志等。详细的配置可以参考&nbsp;<a href="http://docs.ceph.com/docs/master/rados/configuration/mon-config-ref/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">MON 配置</a>。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（2）OSD （Object Storage Device）集群：OSD 集群由一定数目的（从几十个到几万个） OSD Daemon 组成，负责数据存储和复制，向 Ceph client 提供存储资源。每个&nbsp;OSD 守护进程监视它自己的状态，以及别的 OSD 的状态，并且报告给 Monitor；而且，OSD 进程负责在数据盘上的文件读写操作；它还负责数据拷贝和恢复。在一个服务器上，一个数据盘有一个 OSD Daemon。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';">
    <pre>root@ceph1:~# ps -ef | grep ceph-<span style="line-height:1.5;">osd
root      </span><span style="color:rgb(128,0,128);line-height:1.5;">1204</span>     <span style="color:rgb(128,0,128);line-height:1.5;">1</span>  <span style="color:rgb(128,0,128);line-height:1.5;">0</span> Sep18 ?        <span style="color:rgb(128,0,128);line-height:1.5;">00</span>:<span style="color:rgb(128,0,128);line-height:1.5;">24</span>:<span style="color:rgb(128,0,128);line-height:1.5;">39</span> /usr/bin/ceph-osd --cluster=ceph -i <span style="color:rgb(128,0,128);line-height:1.5;">3</span> -<span style="line-height:1.5;">f
root      </span><span style="color:rgb(128,0,128);line-height:1.5;">2254</span>     <span style="color:rgb(128,0,128);line-height:1.5;">1</span>  <span style="color:rgb(128,0,128);line-height:1.5;">0</span> Sep18 ?        <span style="color:rgb(128,0,128);line-height:1.5;">00</span>:<span style="color:rgb(128,0,128);line-height:1.5;">20</span>:<span style="color:rgb(128,0,128);line-height:1.5;">52</span> /usr/bin/ceph-osd --cluster=ceph -i <span style="color:rgb(128,0,128);line-height:1.5;">6</span> -f</pre>
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（3）若干个数据盘：一个Ceph 存储节点上可以有一个或者多个数据盘，每个数据盘上部署有特定的文件系统，比如 xfs，ext4 或者 btrfs，由一个 OSD Daemon 负责照顾其状态以及向其读写数据。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';">
    <pre>Disk /dev/vda: <span style="color:rgb(128,0,128);line-height:1.5;">21.5</span> GB, <span style="color:rgb(128,0,128);line-height:1.5;">21474836480</span><span style="line-height:1.5;"> bytes
</span>/dev/vda1               <span style="color:rgb(128,0,128);line-height:1.5;">1</span>    <span style="color:rgb(128,0,128);line-height:1.5;">41943039</span>    <span style="color:rgb(128,0,128);line-height:1.5;">20971519</span>+<span style="line-height:1.5;">  ee  GPT
Disk </span>/dev/vdb: <span style="color:rgb(128,0,128);line-height:1.5;">32.2</span> GB, <span style="color:rgb(128,0,128);line-height:1.5;">32212254720</span><span style="line-height:1.5;"> bytes
</span>/dev/vdb1               <span style="color:rgb(128,0,128);line-height:1.5;">1</span>    <span style="color:rgb(128,0,128);line-height:1.5;">62914559</span>    <span style="color:rgb(128,0,128);line-height:1.5;">31457279</span>+  ee  GPT</pre>
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150925162021225-620318769.jpg" alt="" style="border:0px;">&nbsp; &nbsp;&nbsp;<img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150925162053850-1007171756.jpg" alt="" style="border:0px;">（MON 和 OSD 可以共同在一个节点上，也可以分开）</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; &nbsp; 关于Ceph 支持的数据盘上的 xfs、ext4 和 btrfs 文件系统，它们都是<a href="http://en.wikipedia.org/wiki/Journaling_file_system" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">日志文件系统</a>（其特点是文件系统将没提交的数据变化保存到日志文件，以便在系统崩溃或者掉电时恢复数据），三者各有优势和劣势：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">btrfs （B-tree 文件系统） 是个很新的文件系统（Oracel 在2014年8月发布第一个稳定版），它将会支持许多非常高大上的功能，比如 透明压缩（&nbsp;transparent compression）、可写的COW 快照（writable copy-on-write snapshots）、去重（deduplication&nbsp;）和加密（encryption&nbsp;）。因此，Ceph 建议用户在非关键应用上使用该文件系统。 更多的参考包括&nbsp;<a href="https://www.ibm.com/developerworks/cn/linux/l-cn-btrfs/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（1）</a><a href="https://zh.wikipedia.org/wiki/Btrfs" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（2）</a><a href="https://oss.oracle.com/projects/btrfs/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（3）</a>。</li> 
    <li style="list-style-type:disc;">xfs 和 btrfs 相比较ext3/4而言，在高伸缩性数据存储方面具有优势。</li> 
    <li style="list-style-type:disc;">Ceph 的<a href="http://docs.ceph.com/docs/master/rados/configuration/filesystem-recommendations/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">这篇文章</a>&nbsp;明确推荐在生产环境中使用 XFS，在开发、测试、非关键应用上使用 btrfs。</li> 
    <li style="list-style-type:disc;"> <span style="line-height:1.5;font-size:14px;">网上有很多的文章比较这几种文件系统，包括：</span> 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;"><a href="http://www.cnblogs.com/tommyli/p/3201047.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;font-size:14px;line-height:1.5;">ext3，ext4，xfs和btrfs文件系统性能对比</a></li> 
      <li style="list-style-type:disc;"><a href="http://www.oschina.net/translate/ext4-vs-xfs-on-ssd" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;line-height:1.5;">固态硬盘上 Ext4 和 xfs 性能比较</a></li> 
      <li style="list-style-type:disc;"><a href="http://imysql.com/2010/08/30/make_your_db_faster_ext4_vs_xfs.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;line-height:1.5;">哇，让你的DB再快一倍：ext4 vs xfs对比测试</a></li> 
      <li style="list-style-type:disc;"> <a href="http://arstechnica.com/civis/viewtopic.php?t=1169535" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;line-height:1.5;">XFS --if it's more robust, why are we using ext4 instead?</a><span style="line-height:1.5;">&nbsp;</span> </li> 
     </ul></li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（4）要使用 CephFS，还需要 MDS 集群，用于保存 CephFS 的元数据</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（5）要使用对象存储接口，还需要 RADOS Gateway， 它对外提供REST接口，兼容S3和Swift的API。&nbsp;</p> 
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">1.2 Ceph 网络结构</h3> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; &nbsp; Ceph 使用以太网连接内部各存储节点以及连接 client 和集群。Ceph 推荐使用两个网络：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">前端（北向）网络（&nbsp;a public (front-side) network）连接客户端和集群</li> 
    <li style="list-style-type:disc;">后端/东西向网络 （a cluster (back-side) network）来连接 Ceph 各存储节点</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">下图（<a href="http://docs.ceph.com/docs/master/rados/configuration/network-config-ref/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">来源</a>）显示了这种网络拓扑结构：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150927112658115-732178602.jpg" alt="" width="551" height="227" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">这么做，主要是从性能（OSD 节点之间会有大量的数据拷贝操作）和安全性（两网分离）考虑。你可以在 Ceph 配置文件的 [global] 部分配置两个网络：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';">
    <pre><span style="line-height:1.5;">public network = {public-network/netmask}
cluster network = {cluster-network/netmask}</span></pre>
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">具体可以参考：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;"><a href="http://www.mellanox.com/related-docs/whitepapers/WP_Deploying_Ceph_over_High_Performance_Networks.pdf" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Deploying Ceph with High Performance Networks, Architectures and benchmarks for Block Storage Solutions</a></li> 
    <li style="list-style-type:disc;"> <a href="http://www.snia.org/sites/default/files/JohnKim_CephWithHighPerformanceNetworks_V2.pdf" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Deploying Ceph with High Performance Networks</a>&nbsp;</li> 
    <li style="list-style-type:disc;"><a href="https://access.redhat.com/documentation/en/red-hat-ceph-storage/version-1.2.3/red-hat-ceph-storage-123-hardware-guide/chapter-2-networking-recommendations" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">CHAPTER 2. NETWORKING RECOMMENDATIONS</a></li> 
    <li style="list-style-type:disc;"> <a href="http://blog.widodh.nl/2014/11/ceph-with-a-cluster-and-public-network-on-ipv6/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph with a cluster and public network on IPv6</a>&nbsp;谈到了 IPV6 的支持。</li> 
   </ul>
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">1.3 RDB Cache （缓存）</h3> 
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">1.3.1 常见的 Write Cache 种类</h4> 
   <table border="0" style="border:1px solid #C0C0C0;border-collapse:collapse;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <tbody>
     <tr>
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">缓存种类</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">说明</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">优劣势</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">适合场景</td> 
     </tr>
     <tr>
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">Write-through（直写）</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">这种缓存方式在写 I/O 时把数据放入缓存，同时直接写入底层的持久存储，然后再向主机确认写入操作完成。</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">安全地保存数据，从缓存读，减少了读操作的延迟，但是写操作 的延迟没得到优化</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">适合于写较少，但是频繁度的应用</td> 
     </tr>
     <tr>
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">Write-back （回写）</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">数据直接写入缓存，然后向主机返回写入完成。</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">对频繁写应用减少了写的延迟，但是有数据丢失风险</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">对读写混合型应用有优势，但是需要考虑数据保护</td> 
     </tr>
     <tr>
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">&nbsp;</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">&nbsp;</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">&nbsp;</td> 
      <td style="font-size:12px;color:rgb(69,69,69);border:1px solid #C0C0C0;border-collapse:collapse;">&nbsp;</td> 
     </tr>
    </tbody>
   </table>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">缓存的通常位置分类：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">服务器（主机）上：RAID 卡或者 HBA 卡上做缓存。</li> 
    <li style="list-style-type:disc;">VMM 内：在 Hypervisor 上做缓存。</li> 
    <li style="list-style-type:disc;">客户机操作系统内：以 Windows 2012 为例，它提供 write-back 缓存机制。</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">更多资料，可以参考&nbsp;<a href="http://www.computerweekly.com/feature/Write-through-write-around-write-back-Cache-explained" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Cache is vital for application deployment, but which one to choose</a>。</p> 
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">1.3.2 Ceph RBD 缓存</h4> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">默认情况下，Ceph RBD 是不使用缓存的，读和写直接到 Ceph 集群中的存储，写只有在所有 replica 上写都完成后才给客户端返回写完成。Ceph 在较新的版本上陆续添加了 RBD 缓存支持：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">从 0.46 版本开始，Ceph 支持&nbsp;write-back 缓存，你可以在 ceph.conf 文件的 [client] 部分添加&nbsp;rbd cache = true 来使得 write-back 缓存生效。这时候，写几乎是立即返回，但是数据只有在被 flushed 后才写入到实际存储。</li> 
    <li style="list-style-type:disc;">从 0.47 版本开始，Ceph 支持&nbsp;write-through 缓存机制。你只需要再添加配置项&nbsp;<span class="pre" style="line-height:1.5;">rbd&nbsp;<span class="pre" style="line-height:1.5;">cache&nbsp;<span class="pre" style="line-height:1.5;">max&nbsp;<span class="pre" style="line-height:1.5;">dirty = 0 即可。</span></span></span></span> </li> 
    <li style="list-style-type:disc;"><span class="pre" style="line-height:1.5;"><span class="pre" style="line-height:1.5;"><span class="pre" style="line-height:1.5;"><span class="pre" style="line-height:1.5;">从 0.60 版本开始，Ceph 支持&nbsp;<span class="pre" style="line-height:1.5;">rbd&nbsp;<span class="pre" style="line-height:1.5;">cache&nbsp;<span class="pre" style="line-height:1.5;">writethrough&nbsp;<span class="pre" style="line-height:1.5;">until&nbsp;<span class="pre" style="line-height:1.5;">flush 配置项。设置它为 true 时，会使得 write-through 机制变得更加安全，因为老的客户机操作系统（2.6.32 内核版本之前）可能不支持 flush 操作。因此，在设置了该配置项为 true 时，即使用户设置了使用 write-through 机制，Ceph 也会自动使用 write-back 机制，直到它收到第一个 flush 指令后才真正使用 write-through。</span></span></span></span></span></span></span></span></span></li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">可见 RBD 缓存是在客户端做的，见如下图示：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150929094922043-2022546572.jpg" alt="" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">更多信息，可以参考我的另一篇文章：<a href="http://www.cnblogs.com/sammyliu/p/5066895.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">QEMU-KVM 和 Ceph RBD 的 缓存机制总结</a></p> 
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">1.3.3 Cache tiering （缓存分层）</h4> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; &nbsp; Ceph 还支持在集群段做缓存分层。其原理是，在较快的磁盘比如 SSD 上建立一个 cache pool，在建立存储池（storage pool）和它之间的 cache 关系，设置一定的缓存策略，实现类似于在客户端缓存同样的效果。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150929095617168-1458929221.jpg" alt="" width="506" height="275" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">更多的信息及详细配置，参见&nbsp;<a href="http://docs.ceph.com/docs/master/rados/operations/cache-tiering/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">CACHE TIERING</a>&nbsp; 和&nbsp;<a href="https://software.intel.com/en-us/blogs/2015/03/03/ceph-cache-tiering-introduction" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Intel 的文章</a>。</p> 
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">1.3.4 RBD Cache 和 Cache Tiering 的区别</h4> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; 从上面的分析可以看出来，两者的区别在于缓存的位置不同：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">Cache tiering 是 RADOS 层在 OSD 端进行数据缓存，也就是说不论是块存储、对象存储还是文件存储都可以使用tier来提高读写速度</li> 
    <li style="list-style-type:disc;">RBD Cache是 rbd 层在客户端的缓存，也就是只支持块存储。</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; Rbd cache是 客户端的缓存，当多个客户端使用同个块设备时，存在<strong>客户端数据不一致</strong>的问题。举个例子，用户A向块设备写入数据后，数据停留在客户自己的缓存中，没有立即刷新到磁盘，所以其它用户读取不到A写入的数据。但是tier不存在这个问题，因为所有用户的数据都直接写入到 ssd，用户读取数据也是在ssd中读取的，所以不存在客户端数据不一致问题。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; 一般地，Tier 使用 SSD 做缓存，而 Rbd cache 只能使用内存做缓存。SSD和内存有两个方面的差别，一个是读写速度、另一个是掉电保护。掉电后内存中的数据就丢失了，而ssd中的数据不会丢失。</p> 
   <h2 style="font-size:21px;line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">2. Ceph 集群的逻辑结构（以RBD为例）</h2> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp;Ceph 集群的逻辑结构由 Pool 和 PG （Placement Group）来定义。</p> 
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">2.1 Pool</h3> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">一个 Pool 是 Ceph 中的一些对象的逻辑分组，它并不表示一个连续的分区，而只是一个逻辑概念，类似于将二进制数据打了tag一样然后根据tag归类一样。它类似于 LVM 中的 Volume Group，类似于一个命名空间。RBD Image 类似于 LVM 中的 Logical Volume。RBD Image 必须且只能在一个 Pool 中。Pool 由若干个PG组成。其属性包括：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">所有性和访问权限</li> 
    <li style="list-style-type:disc;">对象副本数目</li> 
    <li style="list-style-type:disc;">PG 数目</li> 
    <li style="list-style-type:disc;">CRUSH 规则集合</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">Ceph Pool 有两种类型：</p> 
   <ol style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <li style="list-style-type:decimal;">Replicated pool：拷贝型 pool，通过生成对象的多份拷贝来确保在部分 OSD 丢失的情况下数据不丢失。这种类型的 pool 需要更多的裸存储空间，但是它支持所有的 pool 操作。</li> 
    <li style="list-style-type:decimal;">Erasure-coded pool：纠错码型 pool（类似于 Software RAID）。在这种 pool 中，每个数据对象都被存放在 K+M 个数据块中：对象被分成 K 个数据块和 M 个编码块；pool 的大小被定义成 K+M 块，每个块存储在一个 OSD 中；块的顺序号作为 object 的属性保存在对象中。可见，这种 pool&nbsp;用更少的空间实现存储，即节约空间；纠删码实现了高速的计算，但有2个缺点，一个是速度慢，一个是只支持对象的部分操作（比如：不支持局部写）。<a href="http://blog.csdn.net/niuanxins/article/details/42239431" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">这篇文章</a>&nbsp;详细介绍了其原理和细节。</li> 
   </ol>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">Pool 提供如下的能力：</p> 
   <ol style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <li style="list-style-type:decimal;">Resilience（弹力）：即在确保数据不丢失的情况允许一定的 OSD 失败，这个数目取决于对象的拷贝（copy/replica）份数。对拷贝型 pool 来说，Ceph 中默认的拷贝份数是2，这意味着除了对象自身外，它还有一个另外的备份。你可以自己决定一个 Pool 中的对象的拷贝份数。</li> 
    <li style="list-style-type:decimal;">Placement Groups（放置组）：Ceph 使用 PG 来组织对象，这是因为对象可能成千上万，因此一个一个对象来组织的成本是非常高的。PG 的值会影响 Ceph 集群的行为和数据的持久性。你可以设置 pool 的 PG 数目。推荐的配置是，每个 OSD 大概 100 个 PG。</li> 
    <li style="list-style-type:decimal;">CRUSH Rules （CRUSH 规则）：数据映射的策略。系统默认提供 “replicated_ruleset"。用户可以自定义策略来灵活地设置 object 存放的区域。比如可以指定 pool1中所有objecst放置在机架1上，所有objects的第1个副本放置在机架1上的服务器A上，第2个副本分布在机架1上的服务器B上。 pool2中所有的object分布在机架2、3、4上，所有Object的第1个副本分布在机架2的服务器上，第2个副本分布在机架3的服 器上，第3个副本分布在机架4的服务器上。详细的信息可以参考这些文档&nbsp;<a href="http://docs.openfans.org/ceph/ceph4e2d658765876863/ceph-1/ceph-storage-cluster3010ceph5b5850a896c67fa43011/operations301064cd4f5c3011/crush-maps3010crush66205c043011" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（1）</a><a href="http://dachary.org/?p=3189" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（2）</a><a href="http://docs.ceph.com/docs/master/rados/operations/crush-map/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（3）</a><a href="http://wenku.baidu.com/view/4d246317a5e9856a5612604e.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">（4）</a>。</li> 
    <li style="list-style-type:decimal;">Snapshots（快照）：你可以对 pool 做快照。</li> 
    <li style="list-style-type:decimal;">Set Ownership：设置 pool 的 owner 的用户 ID。</li> 
    <li style="list-style-type:decimal;">Ceph 集群创建后，默认创建了 data，metadata 和 rbd 三个存储池。</li> 
   </ol>
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">2.2 （Placement Group）PG</h3> 
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">2.2.1 概念</h4> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp;PG 概念非常复杂，主要有如下几点：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">PG 也是对象的逻辑集合。同一个PG 中的所有对象在相同的 OSD 上被复制。</li> 
    <li style="list-style-type:disc;">PG 聚合一部分对象成为一个组（group），这个组被放在某些OSD上（place），合起来就是 Placemeng Group （放置组）了。</li> 
    <li style="list-style-type:disc;">Epoch：PG map 的版本号，它是一个单调递增的序列。</li> 
    <li style="list-style-type:disc;">Peering：见下文的状态（8）描述。详细过程请参阅&nbsp;<a href="https://www.ustack.com/blog/ceph%EF%BC%8Dpg-peering/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph：pg peering过程分析</a>。</li> 
    <li style="list-style-type:disc;">Acting set：支持一个 PG 的所有 OSD 的有序列表，其中第一个 OSD 是主OSD，其余为次。acting set 是 CRUSH 算法分配的，但是不一定已经生效了。</li> 
    <li style="list-style-type:disc;">Up set：某一个 PG map 历史版本的 acting set。在大多数情况下，acting set 和 up set 是一致的，除非出现了&nbsp;pg_temp。</li> 
    <li style="list-style-type:disc;">Current Interval&nbsp;or&nbsp;Past Interval：若干个连续的版本号，这些版本中 acting 和 up set 保持不变。</li> 
    <li style="list-style-type:disc;">PG temp：在Ceph 正在往主 OSD 回填数据时，这个主OSD是不能提供数据服务的，这时候，它会向 MON 申请一个临时的 acting set，这就是 PG temp。举个例子，现在 acting set 是[0,1,2]，出现了一点事情后，它变为 [3,1,2]，此时 osd.3 还是空的因此它无法提供数据服务因此它还需要等待backfilling过程结束，因此，它会向 MON 申请一个临时的 set 比如 [1,2,3]，此时将由 osd.1 提供数据服务。回填过程结束后，该临时 set 会被丢弃，重新由 osd.3 提供服务。</li> 
    <li style="list-style-type:disc;">主 （primary） OSD：在 acting set 中的首个 OSD，负责接收客户端写入数据；默认情况下，提供数据读服务，但是该行为可以被修改。它还负责 peering 过程，以及在需要的时候申请 PG temp。</li> 
    <li style="list-style-type:disc;">次 （replica）OSD：在 acting set 中的除了第一个以外的其余 OSD。</li> 
    <li style="list-style-type:disc;">流浪 （stray） OSD：已经不是 acting set 中了，但是还没有被告知去删除数据 的 OSD。</li> 
    <li style="list-style-type:disc;">PG 的 acting set 是由 CRUSH 算法根据 CRUSH Rules 动态地计算得出的。</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160506141136201-1497237009.jpg" alt="" width="392" height="206" style="border:0px;">&nbsp; &nbsp;&nbsp;<img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160506140429185-571790346.jpg" alt="" width="302" height="208" style="border:0px;line-height:1.5;"></p> 
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">2.2.2 特点</h4> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">其主要特点如下：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;"> <span style="line-height:1.5;">基本特点</span> 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;"><span style="line-height:1.5;">PG 确定了 pool 中的对象和 OSD 之间的映射关系。一个 object 只会存在于一个 PG 中，但是多个 object 可以在同一个 PG 内。</span></li> 
      <li style="list-style-type:disc;">Pool 的 PG 数目是创建 pool 时候指定的，Ceph 官方有推荐的计算方法。其值与 OSD 的总数的关系密切。当Ceph 集群扩展 OSD 增多时，根据需要，可以增加 pool 的 PG 数目。</li> 
      <li style="list-style-type:disc;">对象的副本数目，也就是被拷贝的次数，是在创建 Pool 时指定的。该分数决定了每个 PG 会在几个 OSD 上保存对象。如果一个拷贝型 Pool 的size（拷贝份数）为 2，它会包含指定数目的 PG，每个 PG 使用两个 OSD，其中，第一个为主 OSD （primary），其它的为从 OSD （secondary）。<span style="line-height:1.5;">不同的 PG 可能会共享一个 OSD。</span> </li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Ceph 引入 PG 的目的主要是为了减少直接将对象映射到 OSD 的复杂度。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">PG 也是Ceph 集群做清理（scrubbing）的基本单位，也就是说数据清理是一个一个PG来做的。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">PG 和 OSD 之间的映射关系由 CRUSH 决定，而它做决定的依据是 CRUSH 规则（rules）。CRUSH 将所有的存储设备（OSD）组织成一个分层结构，该结构能区分故障域（failure domain），该结构中每个节点都是一个 CRUSH bucket。详细情况请阅读 CRUSH 相关的文档。</span></li> 
     </ul></li>
   </ul>
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;"> <span style="line-height:1.5;">PG 和 OSD 的关系是动态的：</span> 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;"><span style="line-height:1.5;">一开始在 PG 被创建的时候，MON 根据 CRUSH 算法计算出 PG 所在的 OSD。这是它们之间的初始关系。</span></li> 
      <li style="list-style-type:disc;"> <span style="line-height:1.5;">Ceph 集群中 OSD 的状态是不断变化的，它会在如下状态之间做切换：</span> 
       <ul style="list-style:none;">
        <li style="list-style-type:disc;"><span style="line-height:1.5;">up：守护进程运行中，能够提供IO服务；</span></li> 
        <li style="list-style-type:disc;"><span style="line-height:1.5;">down：守护进程不在运行，无法提供IO服务；</span></li> 
        <li style="list-style-type:disc;"><span style="line-height:1.5;">in：包含数据；</span></li> 
        <li style="list-style-type:disc;"><span style="line-height:1.5;">out：不包含数据</span></li> 
       </ul></li> 
      <li style="list-style-type:disc;"> <span style="line-height:1.5;">部分 PG 和 OSD 的关系会随着 OSD 状态的变化而发生变化。</span> 
       <ul style="list-style:none;">
        <li style="list-style-type:disc;"><span style="line-height:1.5;">当新的 OSD 被加入集群后，已有OSD上部分PG将可能被挪到新OSD上；此时PG 和 OSD 的关系会发生改变。</span></li> 
        <li style="list-style-type:disc;"><span style="line-height:1.5;">当已有的某 OSD down 了并变为 out 后，其上的 PG 会被挪到其它已有的 OSD 上。</span></li> 
        <li style="list-style-type:disc;"><span style="line-height:1.5;">但是大部分的 PG 和 OSD 的关系将会保持不变，在状态变化时，Ceph 尽可能只挪动最少的数据。</span></li> 
       </ul></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">客户端根据 Cluster map 以及 CRUSH Ruleset 使用 CRUSH 算法查找出某个 PG 所在的 OSD 列表（其实是 up set）。</span></li> 
      <li style="list-style-type:disc;"> <p style="line-height:1.5;">PG-Object-OSD 的关系如下图所示：</p> <p style="line-height:1.5;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150925162843506-1137448608.jpg" alt="" width="299" height="279" style="border:0px;"></p> </li> 
     </ul></li>
   </ul>
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;"> <span style="line-height:1.5;">PG 的创建过程（详细过程请参考&nbsp;</span><a href="http://my.oschina.net/u/2460844/blog/535007" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;line-height:1.5;">PG 的创建过程</a><span style="line-height:1.5;">）：</span> 
     <ol>
      <li style="list-style-type:disc;"><span style="line-height:1.5;">MON 节点上有PGMonitotor，它发现有 pool 被创建后，判断该 pool 是否有 PG。如果有PG，则一一判断这些 PG 是否已经存在，如果不存在，则开始下面的创建 PG 的过程。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">创建过程的开始，设置PG 状态为 Creating，并将它加入待创建PG队列&nbsp;creating_pgs，等待被处理。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">开始处理后，使用 CRUSH 算法根据当前的 OSD map 找出来 up/acting set，加入 PG map 中以这个 set 中 OSD 为索引的队列&nbsp;creating_pgs_by_osd。（看起来只会加入到主OSD的队列中）。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">队列处理函数将该 OSD 上需要创建的 PG 合并，生成消息MOSDPGCreate，通过消息通道发给 OSD。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">OSD 收到消息字为&nbsp;MSG_OSD_PG_CREATE 的消息，得到消息中待创建的 PG 信息，判断类型，并获取该PG的其它OSD，加入队列&nbsp;creating_pgs （似乎是由主 OSD 负责发起创建次 OSD 上的PG），再创建具体的 PG。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">PG 被创建出来以后，开始 Peering 过程。</span></li> 
     </ol></li>
   </ul>
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li class="_mce_act_on" style="list-style-type:disc;">PG 值的确定：创建 pool 时需要确定其 PG 的数目，在 pool 被创建后也可以调整该数字，该数目会影响到： 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;">数据的持久性：考虑pool 的 size 为 3，表明每个 PG 会将数据存放在 3 个 OSD 上。当一个 OSD down 了后，一定间隔后将开始 recovery 过程，recovery结束前，有部分 PG 的数据将只有两个副本。这时候和需要被恢复的数据的数量有关系，如果该 OSD 上的 PG 过多，则花的时间将越长，风险将越大。如果此时再有一个 OSD down 了，那么将有一部分 PG 的数据只有一个副本，recovery 过程继续。如果再出现第三个 OSD down 了，那么可能会出现部分数据丢失。可见，每个 OSD 上的PG数目不宜过大，否则，会降低数据的持久性。这也就要求在添加 OSD 后，PG 的数目在需要的时候也需要相应增加。</li> 
      <li style="list-style-type:disc;"> <p style="line-height:1.5;">数据的均匀分布性：CRUSH 算法会伪随机地保证 PG 被选中来存放客户端的数据，它还会尽可能地保证所有的 PG 均匀分布在所有的 OSD 上。比方说，有10个OSD，但是只有一个 size 为 3 的 pool，它只有一个 PG，那么10个 OSD 中将只有三个 OSD 被用到。但是 CURSH 算法在计算的时候不会考虑到OSD上已有数据的大小。比方说，100万个4K对象共4G均匀地分布在10个OSD上的1000个PG内，那么每个 OSD 上大概有400M 数据。再加进来一个400M的对象（假设它不会被分割），那么有三块 OSD 上将有 400M + 400M = 800 M 的数据，而其它七块 OSD 上只有 400M 数据。</p> </li> 
      <li style="list-style-type:disc;">资源消耗：PG 作为一个逻辑实体，它需要消耗一定的资源，包括内存，CPU 和带宽。太多 PG 的话，则占用资源会过多。</li> 
      <li style="list-style-type:disc;">清理时间：Ceph 的清理工作是以 PG 为单位进行的。如果一个 PG 内的数据太多，则其清理时间会很长。</li> 
     </ul><p style="line-height:1.5;">&nbsp; &nbsp; 那如何确定一个 Pool 中有多少 PG？Ceph 不会自己计算，而是给出了一些参考原则，让 Ceph 用户自己计算：</p> 
     <ul class="simple" style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;">少于 5 个 OSD， 建议设为 &nbsp;128</li> 
      <li style="list-style-type:disc;">5 到 10 个 OSD，建议设为 512</li> 
      <li style="list-style-type:disc;">10 到 50 个 OSD，建议设为 4096</li> 
      <li style="list-style-type:disc;">50 个 OSD 以上，就需要有更多的权衡来确定 PG 数目</li> 
      <li style="list-style-type:disc;">你可以使用&nbsp;<a class="reference external" href="http://ceph.com/pgcalc/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">pgcalc</a>&nbsp;工具</li> 
     </ul></li> 
    <li class="_mce_act_on" style="list-style-type:disc;"> <span style="line-height:1.5;">PG 的状态也是不断变化的，其主要状态包括：</span> 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Creating 创建中：PG 正在被创建。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Peering 对等互联：表示一个过程，该过程中一个 PG 的所有 OSD 都需要互相通信来就PG 的对象及其元数据的状态达成一致。处于该状态的PG不能响应IO请求。Peering的过程其实就是pg状态从初始状态然后到active+clean的变化过程。一个 OSD 启动之后，上面的pg开始工作，状态为initial，这时进行比对所有osd上的pglog和pg_info，对pg的所有信息进行同步，选举primary osd和replica osd，peering过程结束，然后把peering的结果交给recovering，由recovering过程进行数据的恢复工作。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Active 活动的：Peering 过程完成后，PG 的状态就是 active 的。此状态下，在主次OSD 上的PG 数据都是可用的。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Clean 洁净的：此状态下，主次 OSD 都已经被 peered 了，每个副本都就绪了。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Down：PG 掉线了，因为存放其某些关键数据（比如 pglog 和 pginfo，它们也是保存在OSD上）的副本 down 了。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Degraded 降级的：某个 OSD 被发现停止服务 （down）了后，Ceph MON 将该 OSD 上的所有 PG 的状态设置为 degraded，此时该 OSD 的 peer OSD 会继续提供数据服务。这时会有两种结果：一是它会重新起来（比如重启机器时），需要再经过 peering 过程再到clean 状态，而且 Ceph 会发起 recovery （恢复）过程，使该 OSD 上过期的数据被恢复到最新状态；二是 OSD 的 down 状态持续 300 秒后其状态被设置为 out，Ceph 会选择其它的 OSD 加入 acting set，并启动回填（backfilling）数据到新 OSD 的过程，使 PG 副本数恢复到规定的数目。详情可以参考&nbsp;<a href="http://my.oschina.net/u/2460844/blog/596895" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">PG 的数据恢复过程</a>。<br></span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Recovering 恢复中：一个 OSD down 后，其上面的 PG 的内容的版本会比其它OSD上的 PG 副本的版本落后。在它重启之后（比如重启机器时），Ceph 会启动 recovery 过程来使其数据得到更新。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Backfilling 回填中：一个新 OSD 加入集群后，Ceph 会尝试级将部分其它 OSD 上的 PG 挪到该新 OSD 上，此过程被称为回填。与 recovery 相比，回填（backfill）是在零数据的情况下做全量拷贝，而恢复（recovery）是在已有数据的基础上做增量恢复。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Remapped 重映射：每当 PG 的 acting set 改变后，就会发生从旧 &nbsp;acting set 到新 acting set 的数据迁移。此过程结束前，旧 acting set 中的主 OSD 将继续提供服务。一旦该过程结束，Ceph 将使用新 acting set 中的主 OSD 来提供服务。</span></li> 
      <li style="list-style-type:disc;"> <span style="line-height:1.5;">Stale 过期的：OSD 每隔 0.5 秒向 MON 报告其状态。如果因为任何原因，主 OSD 报告状态失败了，或者其它OSD已经报告其主 OSD down 了，Ceph MON 将会将它们的 PG 标记为 stale 状态。</span><span style="line-height:1.5;">&nbsp;</span> </li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">PG 的所有的状态是一个类似树形的结构，每个状态可能存在子状态，子状态还可能存在子状态，如下图所示：</span></li> 
     </ul></li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;"><img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160506144031685-1540186474.jpg" alt="" width="573" height="413" style="border:0px;">（<a href="http://my.oschina.net/u/2460844/blog/537511" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">来源</a>）</span></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">更多的状态请参考&nbsp;<a href="http://docs.ceph.com/docs/master/rados/operations/pg-states/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">http://docs.ceph.com/docs/master/rados/operations/pg-states/</a>。实际上 PG 的状态可以是以上这些状态的组合，比如：<span style="line-height:1.5;">&nbsp;</span>&nbsp;</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>[root@ceph-mon ~]# ceph -<span style="line-height:1.5;">s
cluster c5476875-2a04-41b7-a4e8-<span style="line-height:1.5;">421133c69ac8 health HEALTH_WARN 28<span style="line-height:1.5;"> pgs backfill <span style="color:rgb(0,0,255);line-height:1.5;">#回填，有新的 OSD 被加入了？</span> 79<span style="line-height:1.5;"> pgs degraded <span style="color:rgb(0,0,255);line-height:1.5;">#降级，有 OSD down 了？</span> 10<span style="line-height:1.5;"> pgs recovering <span style="color:rgb(0,0,255);line-height:1.5;">#恢复中</span> 42<span style="line-height:1.5;"> pgs recovery_wait <span style="color:rgb(0,0,255);line-height:1.5;">#等待恢复</span> 80<span style="line-height:1.5;"> pgs stuck unclean <span style="color:rgb(0,0,255);line-height:1.5;">#有 80个 PG 一直处于 unclean 状态</span> 27<span style="line-height:1.5;"> pgs undersized <span style="color:rgb(0,0,255);line-height:1.5;">#GP 的副本数小于pool size</span> recovery 4814/27835 objects degraded (17.295%<span style="line-height:1.5;">) recovery 2047/27835 objects misplaced (7.354%)</span></span></span></span></span></span></span></span></span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">注意，只有当所有的 PG 都是 active + clean 状态时，集群的状态才是 HEALTH_OK 的。</span>&nbsp;</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;"> <span style="line-height:1.5;">清理 scrubbing：Ceph 以 PG 为单位进行数据清理，以保证数据的完整性，它的作用类似于文件系统的 fsck 工具。</span> 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;"><span style="line-height:1.5;">有两种比较方式：（1）light scrubbing：比较对象的size和属性，一般每天进行 （2）deep scrubbing：读取对象的数据，比较检验码，一般每周进行。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Ceph 的 OSD 定期启动 scrub 线程来扫描部分对象，通过与其他副本比对来发现是否一致，如果存在不一致，抛出异常提示用户手动解决。管理员也可以手工发起。</span></li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">Scrub&nbsp;以 PG 为单位，对于每一个PG，Ceph 分析该 PG 下所有的对象, 产生一个类似于元数据信息摘要的数据结构，如对象大小，属性等，叫scrubmap, 比较主与副scrubmap，来保证是不是有object 丢失或者不匹配。</span></li> 
      <li style="list-style-type:disc;"> <p align="left" style="line-height:1.5;">Scrub 方式分成两种， classic vs. chunky。Scrub 流程需要提取对象的校验信息然后跟其他副本的校验信息对比，这期间被校验对象的数据是不能被修改的,所以 write 请求会被 block. 由于 PG 可能包含成千上万 objects,&nbsp;&nbsp;&nbsp;chunk 每一次的比较只取其中一部分 objects 来比较，这样只 block一小部分object的write请求。这是在ceph的Bobtail(v0.56&nbsp; Jan 1 2013)引入的feature,称为chunky scrub。Classic scrub 没有引入chunk， 会block所有的write请求。</p> </li> 
      <li style="list-style-type:disc;"><span style="line-height:1.5;">该机制对保证数据的完整性非常重要，但是也会消耗大量的集群资源，block 住一部分对象的写入操作，降低集群的性能，特别是当一个OSD服务器上多个OSD同时进行深度清理的时候。这篇文章&nbsp;<a href="http://blog.simon.leinen.ch/2015/02/ceph-deep-scrubbing-impact.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Ceph Deep-Scrubbing Impact Study</a>&nbsp;说当有三个深度清理线程发生时，性能有明显的下降。</span></li> 
     </ul></li>
   </ul>
   <h4 style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;"><span style="line-height:1.5;font-size:1.17em;">2.3 Ceph 结构和状态地图 Cluster map</span></h4> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; &nbsp; Ceph 要求 ceph 客户端和 OSD 守护进程需要知晓整个集群的拓扑结构，它们可以通过 Monitor 获取 cluster map 来达到这一点。Cluster map 包括：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（1）Monitor Map：MON 集群的状态（包括 the cluster fsid, the position, name address and port of each monitor, 创建时间，最后的更新时间等）。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>root@ceph1:/osd/<span style="line-height:1.5;">data# ceph mon dump
dumped monmap epoch </span><span style="color:rgb(128,0,128);line-height:1.5;">1</span><span style="line-height:1.5;">
epoch </span><span style="color:rgb(128,0,128);line-height:1.5;">1</span><span style="line-height:1.5;">
fsid 4387471a</span>-ae2b-47c4-b67e-<span style="line-height:1.5;">9004860d0fd0
last_changed </span><span style="color:rgb(128,0,128);line-height:1.5;">0.000000</span><span style="line-height:1.5;">
created </span><span style="color:rgb(128,0,128);line-height:1.5;">0.000000</span>
<span style="color:rgb(128,0,128);line-height:1.5;">0</span>: <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.194</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6789</span>/<span style="color:rgb(128,0,128);line-height:1.5;">0</span><span style="line-height:1.5;"> mon.ceph1
</span><span style="color:rgb(128,0,128);line-height:1.5;">1</span>: <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.195</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6789</span>/<span style="color:rgb(128,0,128);line-height:1.5;">0</span><span style="line-height:1.5;"> mon.ceph2
</span><span style="color:rgb(128,0,128);line-height:1.5;">2</span>: <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.218</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6789</span>/<span style="color:rgb(128,0,128);line-height:1.5;">0</span> mon.ceph3</pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;font-size:14px;">（2）OSD Map：</span><span style="line-height:1.5;font-size:14px;">当前所有 Pool 的状态和所有 OSD 的状态 （包括&nbsp;</span><span style="line-height:1.5;font-size:14px;">the cluster fsid, map 创建和最后修改时间, pool 列表, replica sizes, PG numbers, a list of OSDs and their status (e.g., up, in) 等）。通过运行 ceph osd dump 获取。</span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>root@ceph1:~<span style="line-height:1.5;"># ceph osd dump
epoch </span><span style="color:rgb(128,0,128);line-height:1.5;">76</span><span style="line-height:1.5;">
fsid 4387471a</span>-ae2b-47c4-b67e-<span style="line-height:1.5;">9004860d0fd0
created </span><span style="color:rgb(128,0,128);line-height:1.5;">2015</span>-<span style="color:rgb(128,0,128);line-height:1.5;">09</span>-<span style="color:rgb(128,0,128);line-height:1.5;">18</span> <span style="color:rgb(128,0,128);line-height:1.5;">02</span>:<span style="color:rgb(128,0,128);line-height:1.5;">16</span>:<span style="color:rgb(128,0,128);line-height:1.5;">19.504735</span><span style="line-height:1.5;">
modified </span><span style="color:rgb(128,0,128);line-height:1.5;">2015</span>-<span style="color:rgb(128,0,128);line-height:1.5;">09</span>-<span style="color:rgb(128,0,128);line-height:1.5;">21</span> <span style="color:rgb(128,0,128);line-height:1.5;">07</span>:<span style="color:rgb(128,0,128);line-height:1.5;">58</span>:<span style="color:rgb(128,0,128);line-height:1.5;">55.305221</span><span style="line-height:1.5;">
flags
pool </span><span style="color:rgb(128,0,128);line-height:1.5;">0</span> <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">data</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span> replicated size <span style="color:rgb(128,0,128);line-height:1.5;">3</span> min_size <span style="color:rgb(128,0,128);line-height:1.5;">2</span> crush_ruleset <span style="color:rgb(128,0,128);line-height:1.5;">0</span> object_hash rjenkins pg_num <span style="color:rgb(128,0,128);line-height:1.5;">64</span> pgp_num <span style="color:rgb(128,0,128);line-height:1.5;">64</span> last_change <span style="color:rgb(128,0,128);line-height:1.5;">1</span> flags hashpspool crash_replay_interval <span style="color:rgb(128,0,128);line-height:1.5;">45</span> stripe_width <span style="color:rgb(128,0,128);line-height:1.5;">0</span><span style="line-height:1.5;">
osd.</span><span style="color:rgb(128,0,128);line-height:1.5;">3</span> up   <span style="color:rgb(0,0,255);line-height:1.5;">in</span>  weight <span style="color:rgb(128,0,128);line-height:1.5;">1</span> up_from <span style="color:rgb(128,0,128);line-height:1.5;">26</span> up_thru <span style="color:rgb(128,0,128);line-height:1.5;">64</span> down_at <span style="color:rgb(128,0,128);line-height:1.5;">25</span> last_clean_interval [<span style="color:rgb(128,0,128);line-height:1.5;">7</span>,<span style="color:rgb(128,0,128);line-height:1.5;">23</span>) <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.194</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6801</span>/<span style="color:rgb(128,0,128);line-height:1.5;">1204</span> <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.194</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6802</span>/<span style="color:rgb(128,0,128);line-height:1.5;">1204</span> <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.194</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6803</span>/<span style="color:rgb(128,0,128);line-height:1.5;">1204</span> <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.194</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6804</span>/<span style="color:rgb(128,0,128);line-height:1.5;">1204</span> exists,up d55567da-4e2a-40ca-b7c9-5a30240c895a<br>
......</pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">（3）PG Map：包含PG 版本（version）、时间戳、最新的 OSD map epoch, full ratios, and 每个 PG 的详细信息比如 PG ID, Up Set, Acting Set, 状态 (e.g., active + clean), pool 的空间使用统计。可以使用命令&nbsp;ceph pg dump 来获取 PG Map。</span></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><a href="http://cephnotes.ksperis.com/blog/2015/02/23/get-the-number-of-placement-groups-per-osd" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">这里</a>&nbsp;有段代码可以以表格形式显示这些映射关系：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>ceph pg dump | awk '
 /^pg_stat/ { col=1; while($col!="up") {col++}; col++<span style="line-height:1.5;"> }
 /^[0-9a-f]+\.[0-9a-f]+/ { match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0<span style="line-height:1.5;">; up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+<span style="line-height:1.5;">RLENGTH) } for(i in osds) {array[osds[i],pool]++<span style="line-height:1.5;">; osdlist[osds[i]];} } END { printf("\n"<span style="line-height:1.5;">); printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n"<span style="line-height:1.5;">); for (i in poollist) printf("--------"); printf("----------------\n"<span style="line-height:1.5;">); for (i in osdlist) { printf("osd.%i\t", i); sum=0<span style="line-height:1.5;">; for (j in poollist) { printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] }; printf("| %i\n"<span style="line-height:1.5;">,sum) } for (i in poollist) printf("--------"); printf("----------------\n"<span style="line-height:1.5;">); printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n"<span style="line-height:1.5;">); }'</span></span></span></span></span></span></span></span></span></span></span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">（4）CRUSH （<a href="http://www.ssrc.ucsc.edu/Papers/weil-sc06.pdf" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">Controlled Replication under Scalable Hashing</a>）Map：包含当前磁盘、服务器、机架等层级结构 （Contains a list of storage devices, the failure domain hierarchy (e.g., device, host, rack, row, room, etc.), and rules for traversing the hierarchy when storing data）。 要查看该 map 的话，先运行 ceph osd getcrushmap -o {filename} 命令，然后运行 crushtool -d {comp-crushmap-filename} -o {decomp-crushmap-filename} 命令，在vi 或者 cat {decomp-crushmap-filename} 即可。</span></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">CRUSH map 使用分层结构来组织集群中的所有存储设备：</span></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160506161118169-947176724.jpg" alt="" width="496" height="325" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">CRUSH rules 主要有三个作用：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">指定从CRUSH Map 中的哪个节点开始查找</li> 
    <li style="list-style-type:disc;">指定使用那个节点作为故障隔离域</li> 
    <li style="list-style-type:disc;">指定定位副本的搜索模式（广度优先 or 深度优先）</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">例子：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="line-height:1.5;">rule replicated_ruleset                            #规则集的命名，创建pool时可以指定rule集
{
    ruleset </span><span style="color:rgb(128,0,128);line-height:1.5;">0</span><span style="line-height:1.5;">                                      #rules集的编号，顺序编即可
    type replicated                                #定义pool类型为replicated(还有esurecode模式)
    min_size </span><span style="color:rgb(128,0,128);line-height:1.5;">1</span><span style="line-height:1.5;">                                     #pool中最小指定的副本数量不能小1
    max_size </span><span style="color:rgb(128,0,128);line-height:1.5;">10</span><span style="line-height:1.5;">                                    #pool中最大指定的副本数量不能大于10    
    step take </span><span style="color:rgb(0,0,255);line-height:1.5;">default</span><span style="line-height:1.5;">                              #定义PG查找副本的入口点
    step chooseleaf  firstn  </span><span style="color:rgb(128,0,128);line-height:1.5;">0</span><span style="line-height:1.5;">  type  host         #选叶子节点、深度优先、隔离host
    step emit                                      #结束
}</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">PG 选择 OSD 的过程（详情可阅读&nbsp;<a href="http://my.oschina.net/u/2460844/blog/531722" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">PG选择osd的过程(crush 算法)</a>）：</span></p> 
   <ol style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <li style="list-style-type:decimal;"><span style="line-height:1.5;">首先要知道在 rules 中指明从 CRUSH map 中哪个节点开始查找，入口点默认为 default 也就是 root 节点</span></li> 
    <li style="list-style-type:decimal;"><span style="line-height:1.5;">然后隔离域为 host 节点(也就是同一个host下面不能选择两个子节点)。由 default 到3个host的选择过程，这里由default根据节点的bucket类型选择下一个子节点，由子节点再根据本身的类型继续选择，知道选择到host，然后在host下选择一个osd。</span></li> 
   </ol>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">因此，Ceph Admin 可以通过配置 CRUSH map 和 rules 来决定数据的存放方式。详细信息，可以参考 &nbsp;</span><a href="http://www.admin-magazine.com/HPC/Articles/RADOS-and-Ceph-Part-2" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;line-height:1.5;">The RADOS object store and Ceph filesystem: Part 2</a>。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（5）MDS Map：包含当前所有 MDS 的状态 （the current MDS map epoch, when the map was created, and the last time it changed. It also contains the pool for storing metadata, a list of metadata servers, and which metadata servers are up and in）。通过执行 ceph mds dump 获取。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>root@ceph1:~<span style="line-height:1.5;"># ceph mds dump
dumped mdsmap epoch </span><span style="color:rgb(128,0,128);line-height:1.5;">13</span><span style="line-height:1.5;">
epoch   </span><span style="color:rgb(128,0,128);line-height:1.5;">13</span><span style="line-height:1.5;">
flags   </span><span style="color:rgb(128,0,128);line-height:1.5;">0</span><span style="line-height:1.5;">
created </span><span style="color:rgb(128,0,128);line-height:1.5;">2015</span>-<span style="color:rgb(128,0,128);line-height:1.5;">09</span>-<span style="color:rgb(128,0,128);line-height:1.5;">18</span> <span style="color:rgb(128,0,128);line-height:1.5;">02</span>:<span style="color:rgb(128,0,128);line-height:1.5;">16</span>:<span style="color:rgb(128,0,128);line-height:1.5;">19.504427</span><span style="line-height:1.5;">
modified        </span><span style="color:rgb(128,0,128);line-height:1.5;">2015</span>-<span style="color:rgb(128,0,128);line-height:1.5;">09</span>-<span style="color:rgb(128,0,128);line-height:1.5;">18</span> <span style="color:rgb(128,0,128);line-height:1.5;">08</span>:<span style="color:rgb(128,0,128);line-height:1.5;">05</span>:<span style="color:rgb(128,0,128);line-height:1.5;">55.438558</span>
<span style="color:rgb(128,0,128);line-height:1.5;">4171</span>:   <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.194</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6800</span>/<span style="color:rgb(128,0,128);line-height:1.5;">962</span> <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">ceph1</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span> mds.<span style="color:rgb(128,0,128);line-height:1.5;">0.2</span> up:active seq <span style="color:rgb(128,0,128);line-height:1.5;">7</span>
<span style="color:rgb(128,0,128);line-height:1.5;">5673</span>:   <span style="color:rgb(128,0,128);line-height:1.5;">9.115</span>.<span style="color:rgb(128,0,128);line-height:1.5;">251.195</span>:<span style="color:rgb(128,0,128);line-height:1.5;">6800</span>/<span style="color:rgb(128,0,128);line-height:1.5;">959</span> <span style="color:rgb(128,0,0);line-height:1.5;">'</span><span style="color:rgb(128,0,0);line-height:1.5;">ceph2</span><span style="color:rgb(128,0,0);line-height:1.5;">'</span> mds.-<span style="color:rgb(128,0,128);line-height:1.5;">1.0</span> up:standby seq <span style="color:rgb(128,0,128);line-height:1.5;">1</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">MDS 只用于Ceph 文件系统该，与 RDB 和对象存储无关。</p> 
   <h2 style="font-size:21px;line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">3. CRUSH 算法（以RBD为例）</h2> 
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">3.1&nbsp;Ceph client 是如何将数据块放到 OSD 的</h3> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; Ceph 架构中，Ceph 客户端是直接读或者写存放在 OSD上的 RADOS 对象存储中的对象（data object）的，因此，Ceph 需要走完&nbsp;<strong>(Pool, Object) → (Pool, PG) → OSD set → OSD/Disk</strong>&nbsp;完整的链路，才能让 ceph client 知道目标数据 object的具体位置在哪里：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（1）创建 Pool 和它的 PG。根据上述的计算过程，PG 在 Pool 被创建后就会被 MON 在根据 CRUSH 算法计算出来的 PG 应该所在若干的 OSD 上被创建出来了。也就是说，在客户端写入对象的时候，PG 已经被创建好了，PG 和 OSD 的映射关系已经是确定了的。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（2）Ceph 客户端通过哈希算法计算出存放 object 的 PG 的 ID：</p> 
   <ol style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <li style="list-style-type:decimal;">客户端输入 pool ID 和 object ID （比如 pool = “liverpool” and object-id = “john”）</li> 
    <li style="list-style-type:decimal;">ceph 对 object ID 做哈希</li> 
    <li style="list-style-type:decimal;">ceph 对该 hash 值取 PG 总数的模，得到 PG 编号 （比如 58）（第2和第3步基本保证了一个 pool 的所有 PG 将会被均匀地使用）</li> 
    <li style="list-style-type:decimal;">ceph 对 pool ID 取 hash （比如 “liverpool” =&nbsp;4）</li> 
    <li style="list-style-type:decimal;">ceph 将 &nbsp;pool ID 和 PG ID 组合在一起（比如 4.58）得到 PG 的完整ID。</li> 
   </ol>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">也就是：PG-id = hash(pool-id). hash(objet-id) % PG-number</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160507213329078-1417185551.jpg" alt="" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（3）客户端通过 CRUSH 算法计算出（或者说查找出） object 应该会被保存到 PG 中哪个 OSD 上。（注意：这里是说”应该“，而不是”将会“，这是因为 PG 和 OSD 之间的关系是已经确定了的，那客户端需要做的就是需要知道它所选中的这个 PG 到底将会在哪些 OSD 上创建对象。）。这步骤也叫做 CRUSH 查找。&nbsp;&nbsp;&nbsp;</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; &nbsp;对 Ceph 客户端来说，只要它获得了 Cluster map，就可以使用 CRUSH 算法计算出某个 object 将要所在的 OSD 的 ID，然后直接与它通信。</p> 
   <ol style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <li style="list-style-type:decimal;">Ceph client 从 MON 获取最新的 cluster map。</li> 
    <li style="list-style-type:decimal;">Ceph client 根据上面的第（2）步计算出该 object 将要在的 PG 的 ID。</li> 
    <li style="list-style-type:decimal;">Ceph client 再根据 CRUSH 算法计算出 PG 中目标主和次 OSD 的 ID。</li> 
   </ol>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">也就是：OSD-ids = CURSH(PG-id,&nbsp;cluster-map,&nbsp;cursh-rules)。&nbsp;</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160507213353531-35087348.jpg" alt="" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（4）客户端写入数据</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">在客户端使用 rbd 时一般有两种方法：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">第一种 是 Kernel rbd。就是创建了rbd设备后，把rbd设备map到内核中，形成一个虚拟的块设备，这时这个块设备同其他通用块设备一样，一般的设备文件为/dev/rbd0，后续直接使用这个块设备文件就可以了，可以把 /dev/rbd0 格式化后 mount 到某个目录，也可以直接作为裸设备使用。这时对rbd设备的操作都通过kernel rbd操作方法进行的。&nbsp;</li> 
    <li style="list-style-type:disc;">第二种是 librbd 方式。就是创建了rbd设备后，这时可以使用librbd、librados库进行访问管理块设备。这种方式不会map到内核，直接调用librbd提供的接口，可以实现对rbd设备的访问和管理，但是不会在客户端产生块设备文件。</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">应用写入rbd块设备的过程（详细步骤请参考&nbsp;<a href="http://my.oschina.net/u/2460844/blog/532755" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">rbd client 端的数据请求处理</a>）：</p> 
   <ol style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    <li style="list-style-type:decimal;">应用调用 librbd 接口或者对linux 内核虚拟块设备写入二进制块。下面以 librbd 为例。</li> 
    <li style="list-style-type:decimal;">librbd 对二进制块进行分块，默认块大小为 4M，每一块都有名字，成为一个对象</li> 
    <li style="list-style-type:decimal;">librbd 调用 librados 将对象写入 Ceph 集群</li> 
    <li style="list-style-type:decimal;"> <span style="line-height:1.5;">librados 向主 OSD&nbsp;</span><span style="line-height:1.5;">写入分好块的二进制数据块 (先建立TCP/IP连接，然后发送消息给 OSD，OSD 接收后写入其磁盘)</span> </li> 
    <li style="list-style-type:decimal;">主 OSD 负责同时向一个或者多个次 OSD 写入副本。注意这里是写到日志（Journal）就返回，因此，使用SSD作为Journal的话，可以提高响应速度，做到服务器端对客户端的快速同步返回写结果（ack）。</li> 
    <li style="list-style-type:decimal;">当主次OSD都写入完成后，主 OSD 向客户端返回写入成功。</li> 
    <li style="list-style-type:decimal;">当一段时间（也许得几秒钟）后Journal 中的数据向磁盘写入成功后，Ceph通过事件通知客户端数据写入磁盘成功（commit），此时，客户端可以将写缓存中的数据彻底清除掉了。</li> 
    <li style="list-style-type:decimal;">默认地，Ceph 客户端会缓存写入的数据直到收到集群的commit通知。如果此阶段内（在写方法返回到收到commit通知之间）OSD 出故障导致数据写入文件系统失败，Ceph 将会允许客户端重做尚未提交的操作（replay）。因此，PG 有个状态叫 replay：“The placement group is waiting for clients to replay operations after an OSD crashed.”。</li> 
   </ol>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201605/697113-20160507205321796-1810415144.jpg" alt="" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">也就是，文件系统负责文件处理，librdb 负责块处理，librados 负责对象处理，OSD 负责将数据写入在Journal和磁盘中。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">关于 RDB 镜像在存储池中是如何被存放的，请阅读&nbsp;<a id="link_post_title" class="link-post-title" href="http://www.cnblogs.com/sammyliu/p/4843812.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">理解 OpenStack + Ceph （4）：Ceph 的基础数据结构 [Pool, Image, Snapshot, Clone]</a>。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">（5）以存放一个文件为例，下图（</span><a href="https://www.ustack.com/blog/ceph_infra/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;line-height:1.5;">来源</a><span style="line-height:1.5;">）说明了完整的计算过程：</span></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150927104027912-1261736487.jpg" alt="" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（6）一些说明</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">几个比例关系：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">文件 ：对象 = 1 ： n （由客户端实时计算）</li> 
    <li style="list-style-type:disc;">object ：PG = n ： 1 （有客户端使用哈希算法计算）</li> 
    <li style="list-style-type:disc;">PG ：OSD = m ： n （由 MON 根据 CRUSH 算法计算）</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">CRUSH 算法是相当复杂，快速看看的话可以参考&nbsp;<a href="http://docs.ceph.com/docs/master/architecture/#mapping-pgs-to-osds" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">官方文章</a>，或者直接读代码和作者的论文。几个简单的结论或原则：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">一个 RBD image（比如虚机的一个镜像文件）会分成几个 data objects 保存在 Ceph 对象存储中。</li> 
    <li style="list-style-type:disc;">一个 Ceph 集群含有多个 pool （使用 ceph osd pool create 命令创建pool）</li> 
    <li style="list-style-type:disc;">一个 Pool 包含若干个 PG (在创建 pool 时必须指定 pg_num，在需要的时候对已有的pool的&nbsp;pg_num 也可以进行修改)</li> 
    <li style="list-style-type:disc;">一个 PG 可以包含多个对象</li> 
    <li style="list-style-type:disc;">一个 object 只在一个 PG 中</li> 
    <li style="list-style-type:disc;">一个 PG 映射到一组 OSD，其中第一个 OSD 是主（primary），其余的是从（secondary）</li> 
    <li style="list-style-type:disc;">许多 PG 可以映射到某个 OSD，通常一个OSD上会有50到100个PG。</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">使用&nbsp;<a href="http://cephnotes.ksperis.com/blog/2015/02/23/get-the-number-of-placement-groups-per-osd" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">这里</a>&nbsp;的脚本，可以看出在我的测试环境（pool的副本数为1）中，一共有 6 个pool，7 个 OSD，每个 pool 中有 192 个PG，每个 OSD 大概在164个 （192 * 6*1/7）PG 中：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-size:15px;font-family:'Courier New';"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>pool :  4       5       0       1       2       3       | SUM
----------------------------------------------------------------
osd.4   20      19      21      23      21      24      | 128
osd.5   38      28      30      28      34      44      | 202
osd.6   30      33      33      32      34      36      | 198
osd.7   23      19      22      21      22      21      | 128
osd.8   26      36      34      36      30      20      | 182
osd.9   21      26      21      20      21      19      | 128
osd.3   34      31      31      32      30      28      | 186
----------------------------------------------------------------
SUM :   192     192     192     192     192     192     |&nbsp;&nbsp;</pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="line-height:1.5;font-size:12px;"><a title="复制代码" style="color:rgb(26,139,200);border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">这张图（<a href="http://karan-mj.blogspot.com/2014/01/how-data-is-stored-in-ceph-cluster.html" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">来源</a>）也有助于理清其中的关系：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150925172103694-1950919192.jpg" alt="" width="462" height="345" style="border:0px;">&nbsp;&nbsp;</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">总之，Ceph 采用的是通过计算找到对象应该被保存的 OSD 位置，这比通过常见的查询算法获取位置快得多。CRUSH 算法是的 ceph 客户端自己计算对象要被保存在哪里（哪个 OSD），也使得客户端可以从主 OSD 上保存或者读取数据。</p> 
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">3.2 RBD &nbsp;image 保存过程和形式</h3> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">如下图所示，Ceph 系统中不同层次的组件/用户所看到的数据的形式是不一样的：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150928152213918-1722034221.jpg" alt="" style="border:0px;"></p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">Ceph 客户端所见的是一个完整的连续的二进制数据块，其大小为创建 RBD image 是设置的大小或者 resize 的大小，客户端可以从头或者从某个位置开始写入二进制数据。</li> 
    <li style="list-style-type:disc;">librados 负责在 RADOS 中创建对象（object），其大小为 pool 的 order 决定，默认情况下 order = 22 此时 object 大小为 4MB；以及负责将客户端传入的二进制块条带化为若干个条带（stripe）。</li> 
    <li style="list-style-type:disc;">librados 控制哪个条带由哪个 OSD 写入（条带 ---写入哪个----&gt; object ----位于哪个 ----&gt; OSD）</li> 
    <li style="list-style-type:disc;">OSD 负责创建在文件系统中创建文件，并将 librados 传入的数据写入数据。</li> 
   </ul>
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp; Ceph client 向一个 RBD image 写入二进制数据（假设 pool 的拷贝份数为 3）：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（1）Ceph client 调用 librados 创建一个 RBD image，这时候不会做存储空间分配，而是创建若干元数据对象来保存元数据信息。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（2）Ceph client 调用 librados 开始写数据。librados 计算条带、object 等，然后开始写第一个 stripe 到特定的目标 object。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（3）librados 根据 CRUSH 算法，计算出 object 所对应的主 OSD ID，并将二进制数据发给它。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（4）主 OSD 负责调用文件系统接口将二进制数据写入磁盘上的文件（每个 object 对应一个 file，file 的内容是一个或者多个 stripe）。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><span style="line-height:1.5;">（5）主 ODS 完成数据写入后，它使用 CRUSH 算啊计算出第二个OSD（secondary OSD）和第三个OSD（tertiary OSD）的位置，然后向这两个 OSD 拷贝对象。都完成后，它向 ceph client 反馈该 object 保存完毕。</span></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150925173957756-1480951725.jpg" alt="" width="291" height="236" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">（6）然后写第二个条带，直到全部写入完成。全部完成后，librados 还应该会做元数据更新，比如写入新的 size 等。</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">完整的过程（<a href="https://www.google.com.hk/url?sa=i&amp;rct=j&amp;q=&amp;esrc=s&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=0CAUQjhxqFQoTCOfz4ZCQmcgCFcMHLAodD3sDdw&amp;url=http%3A%2F%2Fwww.slideshare.net%2FLarryCover%2Fceph-open-source-storage-software-optimizations-on-intel-architecture-for-cloud-workloads&amp;psig=AFQjCNFqMBOmR1MCHDcx4E8NrIHRdDKN8Q&amp;ust=1443508949557117" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">来源</a>）：</p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;"><img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150928144456058-1281334527.jpg" alt="" style="border:0px;"></p> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">该过程具有强一致性的特点：</p> 
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:disc;">Ceph 的读写操作采用 Primary-Replica 模型，Client 只向 Object 所对应 OSD set 的 Primary 发起读写请求，这保证了数据的强一致性。</li> 
    <li style="list-style-type:disc;">由于每个 Object 都只有一个 Primary OSD，因此对 Object 的更新都是顺序的，不存在同步问题。</li> 
    <li style="list-style-type:disc;">当 Primary 收到 Object 的写请求时，它负责把数据发送给其他 Replicas，只要这个数据被保存在所有的OSD上时，Primary 才应答Object的写请求，这保证了副本的一致性。这也带来一些副作用。相比那些只实现了最终一致性的存储系统比如 Swift，Ceph 只有三份拷贝都写入完成后才算写入完成，这在出现磁盘损坏时会出现写延迟增加。</li> 
    <li style="list-style-type:disc;"><span style="line-height:1.5;">在 OSD 上，在收到数据存放指令后，它会产生2~3个磁盘seek操作：</span></li> 
   </ul>
   <ul style="list-style:none;font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">
    <li style="list-style-type:none;"> 
     <ul style="list-style:none;font-size:12px;">
      <li style="list-style-type:disc;">把写操作记录到 OSD 的 Journal 文件上(Journal是为了保证写操作的原子性)。</li> 
      <li style="list-style-type:disc;">把写操作更新到 Object 对应的文件上。</li> 
      <li style="list-style-type:disc;">把写操作记录到 PG Log 文件上。</li> 
     </ul></li>
   </ul>
   <h3 style="font-size:16px;color:rgb(102,102,102);background-image:none;background-repeat:no-repeat;font-family:Verdana;line-height:1.5;">3.3 条带化（striping）</h3> 
   <p style="line-height:1.5;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">&nbsp;在 RADOS 层，Ceph 本身没有条带的概念，因为一个object 是作为一个 文件整体性保存的。但是，RBD 可以控制向一个 object 的写入方式，默认是将一个 object 写满再去写下一个object；还可以通过指定&nbsp;stripe_unit 和&nbsp;stripe_count，来将 object 分成若干个条带即 strip。</p> 
   <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    &nbsp; 一个 RDB image 会被分为多个 object 来保存，从而使得对一个 image 的多个读写可以分在多个 object 进行，从而可以防止某个 image 非常大或者非常忙时单个节点称为性能瓶颈。还可以将 object 进一步条带化为多个条带（stripe unit）。条带（stripe）是 librados 通过 ODS 写入数据的基本单位。这么做的好处是在保持对象数目的同时，进一步减少可以同步读写的粒度（从 object 粒度减少到 stripe 粒度），从而提高读写效率。
   </div> 
   <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
    &nbsp;
   </div> 
   <div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     Ceph 的条带化行为（如果划分条带和如何写入条带）受三个参数控制：
    </div> 
    <ul style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:12px;list-style:none;">
     <li style="list-style-type:disc;">order：RADOS Object 的大小为&nbsp;2^[<em>order</em>] bytes。默认的 oder 为 22，这时候对象大小为4MB。最小 4k，最大 32M，默认 4M.</li> 
     <li style="list-style-type:disc;">stripe_unit：条带（stripe unit）的大小。每个 [stripe_unit] 的连续字节会被连续地保存到同一个对象中，client 写满 stripe unit 大小的数据后，接着去下一个 object 中写下一个 stripe unit 大小的数据。默认为 1，此时一个 stripe 就是一个 object。</li> 
     <li style="list-style-type:disc;">stripe_count：在分别写入了&nbsp;[stripe_unit] 个字节到&nbsp;[stripe_count] 个对象后，ceph 又重新从一个新的对象开始写下一个条带，直到该对象达到了它的最大大小。这时候，ceph 转移到下&nbsp;[stripe_unit] 字节。默认为 object site。</li> 
    </ul>
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     以下图为例：
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     （1）RBD image 会被保存在总共 8 个 RADOS object （计算方式为 client data size 除以 2^[
     <em>order</em>]）中。
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     （2）stripe_unit 为 object size 的四分之一，也就是说每个 object 包含 4 个 stripe。
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     （3）stripe_count 为 4，即每个 object set 包含四个 object。这样，client 以 4 为一个循环，向一个 object set 中的每个 object 依次写入 stripe，写到第 16 个 stripe 后，按照同样的方式写第二个 object set。
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     &nbsp;
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     <img src="https://images2015.cnblogs.com/blog/697113/201509/697113-20150925180305803-50366273.jpg" alt="" style="border:0px;">
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     &nbsp;&nbsp; 默认的情况下，[stripe_unit] 等于 object size；stripe_count 为1。意味着 ceph client 在将第一个 object 写满后再去写下一个 object。要设置其他的&nbsp;[
     <em>stripe_unit</em>] 值，需要Ceph v0.53 版本及以后版本对&nbsp;STRIPINGV2&nbsp;的支持以及使用 format 2 image 格式。
    </div> 
    <div style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;">
     &nbsp;
    </div> 
    <div> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;">参考链接：</p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><a href="http://www.wzxue.com/ceph-librbd-block-library/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">http://www.wzxue.com/ceph-librbd-block-library/</a></p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><a href="http://docs.ceph.com/docs/master/architecture/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">http://docs.ceph.com/docs/master/architecture/</a></p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><a href="https://www.ustack.com/blog/ceph_infra/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">&nbsp;https://www.ustack.com/blog/ceph_infra/</a></p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><a href="https://hustcat.github.io/rbd-image-internal-in-ceph/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">https://hustcat.github.io/rbd-image-internal-in-ceph/</a></p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><a href="http://www.wzxue.com/category/ceph-2/" rel="nofollow" style="color:rgb(26,139,200);text-decoration:none;">http://www.wzxue.com/category/ceph-2/</a></p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><br></p> 
     <p style="line-height:1.5;"><font color="#4b4b4b"><span style="font-size:15px;">&nbsp; &nbsp; 本文转自SammyLiu博客园博客，原文链接：http://www.cnblogs.com/sammyliu/p/4836014.html</span></font><span style="font-size:15px;color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;">，如需转载请自行联系原作者</span></p> 
     <p style="color:rgb(75,75,75);font-family:Verdana, Geneva, Arial, Helvetica, sans-serif;font-size:15px;line-height:1.5;"><br></p> 
    </div> 
   </div> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
