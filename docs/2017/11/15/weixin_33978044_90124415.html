<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Noisy Channel模型纠正单词拼写错误 « NotBeCN</title>
  <meta name="description" content="             本文介绍 Stanford《From Languages to Information》课程中讲到的 单词拼写错误 纠正。背后的数学原理主要是贝叶斯公式。单词拼写错误纠正主要涉及到两个模型：一个是Nosiy Channel模型，它是贝叶斯公式中的似然函数；另一个模型是Language M...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/11/15/weixin_33978044_90124415.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">Noisy Channel模型纠正单词拼写错误</h1>
    <p class="post-meta">Nov 15, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">本文介绍 Stanford《From Languages to Information》课程中讲到的 单词拼写错误 纠正。背后的数学原理主要是贝叶斯公式。单词拼写错误纠正主要涉及到两个模型：一个是Nosiy Channel模型，它是贝叶斯公式中的似然函数；另一个模型是Language Model，它是贝叶斯公式中的先验概率。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">一，问题描述</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">在这句话中“. . . was called a “stellar and versatile&nbsp;<span style="color:rgb(255,0,0);"><strong>acress</strong>&nbsp;</span>whose combination of sass and glamour has defined her. . .”，有一个错误的单词：<span style="color:rgb(255,0,0);"><strong>acress&nbsp;</strong></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">这个错误单词 acress 对应的 正确单词是哪个呢？是 actress？ 还是cress？还是 caress？……</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">二，出现单词拼写错误的情形</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">一种是 Non-word spelling errors，它是指：错误的单词 不存在 于词典中。也就说，你键盘输入了一个单词，而这个单词根本没有被英文词典收录，在字典中查不到。比如你将 正确的单词graffe，多打了一个字符 i ，变成了 giraffe，而 英文字典中根本没有 giraffe这个单词。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">另一种是 real-word errors，比如：想输入&nbsp;<span style="color:rgb(0,0,255);"><em>there</em>&nbsp;</span>are，结果输入成了&nbsp;<span style="color:rgb(0,0,255);"><em>three</em>&nbsp;</span>are。而错误单词 three 是存在于字典中的，关键问题是：怎么知道将 three 改成 there 呢？</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">三，单词拼写错误的纠正步骤</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">①首先检测出 是哪个单词发生了拼写错误。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">这可以通过查字典来实现，比如依次扫描每个单词，若该单词不在词典中(未被词典收录)，则认为它是一个拼写错误的单词。显然，词典越大，词典收录的单词越多，我们就越能正确检测出错误的单词。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">②其次，是要从一组<strong>候选的</strong>&nbsp;正确单词中，选择一个“最准确”的单词，而这个“最准确”的单词，就是要找的结果（错误单词 对应的 正确单词）。&nbsp;</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">这里有个问题就是：如何找出一组候选的正确单词呢？</span><span style="font-family:'Microsoft YaHei';font-size:15px;">这就需要根据实际情况进行分析了。以上面提到的错误单词 acress 为例：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">本来想输入“across”，但是一不小心将 'o'，输入成了'e'，结果变成了 "acress"， 这是substition 操作：将 'o' 替换成了 'e'</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">本来想输入 "actress"，但是打字太快，漏打了 't'，结果变成了"acress"，这是deletion操作：删除了 't'</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">.....</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">或者说：键盘上字符'm' 和 'n' 很近，打字时，很容易将 'm'替换成了'n'；又或者说：'m' 和 'n'发音相似，也导致经常将 'm' 替换成 'n'&nbsp;</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">而寻找一组候选单词，<span style="color:rgb(255,0,0);"><strong>就可以通过“编辑距离算法”来实现</strong></span>。关于编辑距离，可参考“Damerau-Levenshtein Edit Distance”或者：<a id="cb_post_title_url" class="postTitle2" href="http://www.cnblogs.com/hapjin/p/7467035.html" rel="nofollow" style="color:#000000;">最短编辑距离算法实现</a></span></p> 
   <div class="clear" style="clear:both;font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">
    &nbsp;
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">四，贝叶斯推断 纠正 单词拼写错误</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">①Noisy Channel Model</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">Noisy Channel Model的示意图如下：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171209153432886-889000531.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">原来的一个正确的单词：经过 noisy channel ，结果变成了一个 noisy word。而这个noisy channel，其实就是前面讲的“两个词发音相近，容易拼错它们"，或者"两个字符在键盘上相邻，输入时就会错误地将一个词 输入成了(type) 另一个词。(其实niosy channel就是对现实世界存在的问题的一个建模)</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">而要想得出错误单词(noisy word) 对应的 正确单词，就需要用到贝叶斯推断。具体原理如下：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">既然 noisy word (或者说错误单词，记为 x )已经出现了，那么我们在词典中找一个单词w，在 x 已经出现的条件下，<span style="color:rgb(255,0,0);">最有可能</span>是由 哪个单词w 造成的？</span></strong></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;"> 
    <p><span style="font-size:14px;line-height:1.5;">We see an observation x (a misspelled word) and our job is to find the word w that generated this misspelled word</span><br><span style="font-size:14px;line-height:1.5;">Out of all possible words in the vocabulary V we want to find the</span><br><span style="font-size:14px;line-height:1.5;">word w such that P(w|x) is highest. We use the hat notation ˆ to mean “our estimate</span><br><span style="font-size:14px;line-height:1.5;">of the correct word”.</span></p> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">用公式（1）表示如下：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171209154617620-764718368.png" alt="" style="border:0px;">（公式1）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><span style="text-decoration:underline;">V是词典(Vocabulary)</span>，p(w|x)表示：从V中选出一个w，计算概率 P(w|x)，概率最大的那个 w，就是 错误单词x 对应的正确单词，将该正确单词记为: wˆ</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">&nbsp;根据<a href="https://baike.baidu.com/item/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F" rel="nofollow" style="color:#000000;">贝叶斯公式法则</a>（公式2）：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171209155009527-51857531.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">将公式（1）变成如下形式：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171209155039011-816768696.png" alt="" style="border:0px;">（公式3）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">从公式3 可以看出：就是对于 词典V 中的每个单词w，计算 [p(x|w)*p(w)]/p(x)，找出&nbsp;<strong>计算结果最大(概率最大)&nbsp;</strong>的那个 w，该 w 就是最优解 wˆ&nbsp;</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">而在这个计算过程中，可以不需要计算分母p(x)，因为这不影响我们 找出 概率最大的那个 w 。因此将 p(x) 视为一个常量值。<em>（这里关于贝叶斯的理解，可参考后面给出的参考文献）</em></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">于是我们的公式就变成了：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2017.cnblogs.com/blog/715283/201712/715283-20171209155935417-1350330184.png" alt="" style="border:0px;">（公式4）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">可以看出，公式4 由两部分组成，一部分是 p(x|w)，我们称之为 channel model 或者 称为 error model，它就是似然函数</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">另一部分是 p(w) 我们称之为先验概率(prior)。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">另外，值得一提的是这个Vocabulary V，由于Vocabulary中单词个数是很多的，只有在发生某种”条件“的情况下，一个单词才会被误拼写成了另一个单词。换句话说，Vocabulary中的某些词与错误单词 x 之间是”八杆子打不着“的关系，因此我们只在某些Candidate words 中 寻找 [p(x|w)*p(w)] 的那个 w</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">而这些Candidate words 就是由前面提到的”编辑距离算法“生成。因此，公式可继续变成(注意 argmax 的下标的变化。V变成了C，而C就是 Candidate words的集合)</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209161718058-61616931.png" alt="" style="border:0px;"></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">因此，现在的问题变成了：如何求出channel model 和 prior呢？</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">首先介绍下先验概率p(w)的求解(Prior)</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">我们使用 unigram language model 来作为 p(w)。这里解释一下 unigram language model：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">选择一个语料库（词库），这个语料库里面总共有 404253213个单词，然后”编辑距离“算法 根据 错误的单词 acress 生成了一系列的候选词（Candidate words），每一个候选词在语料库中出现的次数count(candidate word) 除以&nbsp;404253213 就是每个Candidate word的先验概率。如下图所示，第一列是错误单词acress的 候选词，第二列是这些候选词在语料库中出现的次数，第三列是这些候选词在语料库中出现的概率（频率）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209162510558-2033259661.png" alt="" style="border:0px;"></span></p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="font-size:14px;line-height:1.5;">For this example let’s start in the following table by assuming a unigram language model. We computed the language model from the
404,253,213 words in the Corpus of Contemporary English (COCA).</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">接下来是求解 channel model</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">个人理解就是：求解channel model需要用到日常生活中用到的知识经验，或者行业应用中累积下来的数据（经验）。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">从公式：p(x|w)理解上来看，给定一个正确的候选单词 w 的条件下，导致错误单词x 的概率有多大？</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">如果我们收集了足够多的数据，比如观察了很多用户一共输入了（打字）1万次 w，其中有10次 输入成了x（打字打成了 x），那么 p(x|w)=0.0001</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">我们考虑四种出错情况：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209163813714-1200674234.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">del[x,y] 表示，输入 xy 时，少打了字符 'y'，结果变成了 x，那么最终得到的单词是一个错误的单词，记录下这种情况下出错的总次数 count(xy typed as x)</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">trans[x,y]表示，输入 xy 时，输入反了，变成了 yx，那么最终得到的单词是一个错误的单词，记录下这种情况下出错的总次数 count(xy typed as yx)</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">把这些数据统计起来，放在一个表里面，这个表称为：confusion matrix</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">比如<a href="http://www.dcs.bbk.ac.uk/~ROGER/corpora.html" rel="nofollow" style="color:#000000;">这个网站（Corpora of misspellings for download）</a>就有一系列的”错误单词的统计数据“。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209164709464-2038229435.png" alt="" style="border:0px;">（"错误单词" 示意图）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">那么根据 confusion matrix，就能计算 似然函数的概率了（也即能求解 channel model 了）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209165142245-1796726669.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">解释一下 if transposition情况：</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">count[w<sub>i</sub>&nbsp;w<sub>i+1</sub>]表示：含有 w<sub>i</sub>&nbsp;w<sub>i+1</sub>&nbsp;字符的所有单词w 的个数；trans[w<sub>i</sub>&nbsp;,w<sub>i+1</sub>&nbsp;] 表示，将 w<sub>i</sub>&nbsp;与 w<sub>i+1</sub>&nbsp;交换的次数。（将w<sub>i</sub>&nbsp;与 w<sub>i+1</sub>&nbsp; 交换后，就变成了一个错误的单词了）</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">另一种计算 confusion matrix 的方法是 EM算法，这个我也没学，不懂，就不说了。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">对于错误的单词 acress，根据下面的7个候选单词计算出来的似然概率如下图：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209165837652-820294249.png" alt="" style="border:0px;"></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">上图中，第一行表示，其中一个正确的候选单词是 actress，正确的单词是 t，由于<span style="color:rgb(0,0,255);"><em>某种原因</em></span>（键盘输入太快了，漏打了t，本来是输入ct 的，结果输入成了c ），统计到的这种情形出现的概率是0.000117 。</span><span style="font-family:'Microsoft YaHei';font-size:15px;"><em><span style="color:rgb(0,0,255);">这种原因</span></em>，其实就是一个deleteion操作而导致的错误。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">现在计算出了 似然概率，也计算出了先验概率，二者相乘：p(x|w)*p(w)，就得出了正确的候选单词 actress 由于deletion 操作导致 得到错误单词 acress 的概率是&nbsp;0.000117</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">同理，计算其它的候选单词 cress、caress、access……的 p(x|w)*p(w)概率，比较一下，哪个概率最大，<span style="color:rgb(0,0,255);">从上图中看出：across 对应的概率最大，也就是说：应该将 acress 纠正为：across&nbsp;</span><br></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">但是，事实上，从句子”“的意思来看，acress 应该纠正为 actress 更为合理。那上而的channel model 为什么没有给出正确的纠正结果呢？</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">主要原因是：先验概率是由 unigram language model 得出的，如果采用 bigram language model，那么就能够正确地找出”actress“，从而将acress纠正为actress</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;">下面是使用Contemporary American English语料库训练得到的二元Language Model。对于单词w：actress 和 across，它给出的先验概率p(w)如下：</span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';"><span style="font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209171350589-2097926896.png" alt="" style="border:0px;"></span></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><img src="https://images2018.cnblogs.com/blog/715283/201712/715283-20171209171710480-1629571116.png" alt="" style="border:0px;"></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">actress对应的先验概率：p(actress)=p("versatile actress whose")=0.000021*0.0010</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">across对应的先验概率：p(across)=1*10<sup>-10</sup></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">这样，再将先验概率和似然概率相乘，就能得到正确的单词应该是”actress“，而不是”across“了。</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><strong><span style="font-family:'Microsoft YaHei';font-size:15px;">参考文章：</span></strong></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a href="http://norvig.com/ngrams/" rel="nofollow" style="color:#000000;"><span style="font-family:'Microsoft YaHei';font-size:15px;">Natural Language Corpus Data: Beautiful Data</span></a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a href="http://www.dcs.bbk.ac.uk/~ROGER/corpora.html" rel="nofollow" style="color:#000000;">Corpora of misspellings for download</a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;">理解贝叶斯公式的一系列文章 或者 推荐《A first course in machine learning 》这本书</span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-family:'Microsoft YaHei';font-size:15px;"><a id="post_title_link_6653920" href="http://www.cnblogs.com/hapjin/p/6653920.html" rel="nofollow" style="color:#000000;">机器学习中的贝叶斯方法---先验概率、似然函数、后验概率的理解及如何使用贝叶斯进行模型预测（1）</a></span></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a id="post_title_link_6656642" href="http://www.cnblogs.com/hapjin/p/6656642.html" rel="nofollow" style="color:#000000;">机器学习中的贝叶斯方法---先验概率、似然函数、后验概率的理解及如何使用贝叶斯进行模型预测（2）</a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a id="post_title_link_6623431" href="http://www.cnblogs.com/hapjin/p/6623431.html" rel="nofollow" style="color:#000000;">使用最大似然法来求解线性模型（2）-为什么是最大化似然函数？</a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a id="post_title_link_6623795" href="http://www.cnblogs.com/hapjin/p/6623795.html" rel="nofollow" style="color:#000000;">使用最大似然法来求解线性模型（3）-求解似然函数</a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><a id="post_title_link_6633471" href="http://www.cnblogs.com/hapjin/p/6633471.html" rel="nofollow" style="color:#000000;">使用最大似然法来求解线性模型（4）-最大化似然函数背后的数学原理</a></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;<a id="post_title_link_7581335" href="http://www.cnblogs.com/hapjin/p/7581335.html" rel="nofollow" style="color:#000000;">NLP里面的一些基本概念</a></p> 
   <p><font><span style="font-size:14px;">本文转自hapjin博客园博客，原文链接：http://www.cnblogs.com/hapjin/p/8012069.html</span></font><span style="font-size:14px;font-family:Verdana, Arial, Helvetica, sans-serif;">，如需转载请自行联系原作者</span></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
