<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>MLlib 中的聚类和分类 « NotBeCN</title>
  <meta name="description" content="             1. 聚类和分类 （1）什么是聚类 聚类（ Clustering）指将数据对象分组成为多个类或者簇（ Cluster），它的目标是：在同一个簇中的对象之间具有较高的相似度，而不同簇中的对象差别较大。其实，聚类在 人们日常生活中是一种常见行为，即所谓的“物以类聚，人以群分”，其核心思想在于...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/10/09/weixin_34268310_90132439.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">MLlib 中的聚类和分类</h1>
    <p class="post-meta">Oct 9, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><span style="font-size:18pt;"><strong>1. 聚类和分类</strong></span><br> （1）什么是聚类<br> 聚类（ Clustering）指将数据对象分组成为多个类或者簇（ Cluster），它的目标是：在同一个簇中的对象之间具有较高的相似度，而不同簇中的对象差别较大。其实，聚类在<br> 人们日常生活中是一种常见行为，即所谓的“物以类聚，人以群分”，其核心思想在于分组，人们不断地改进聚类模式来学习如何区分各个事物和人。<br> （2）什么是分类<br> 数据仓库、数据库或者其他信息库中有许多可以为商业、科研等活动的决策提供所需要的知识。分类与预测即是其中的两种数据分析形式，可以用来抽取能够描述重要数据集合或预测未来数据趋势。分类方法（Classif ication）用于预测数据对象的离散类别（ Categorical Label）；预测方法（ Prediction）用于预测数据对象的连续取值。<br> 分类流程：新样本→特征选取→分类→评价<br> 训练流程：训练集→特征选取→训练→分类器<br> 最初，机器学习的分类应用大多都是在这些方法及基于内存基础上所构造的算法。目前，数据挖掘方法都要求具有基于外存以处理大规模数据集合能力，同时具有可扩展能力。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br><br><strong><span style="font-size:18pt;">2. MLlib 中的聚类和分类</span></strong><br> MLlib 目前已经实现了 K-Means 聚类算法、朴素贝叶斯和决策树分类算法。这里主要介绍被广泛使用的 K-Means 聚类算法和朴素贝叶斯分类算法。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　<span style="font-size:18px;"><strong>（1） K-Means 算法</strong></span><br> 1）&nbsp;<strong><span style="color:rgb(0,0,255);">K-Means 算法简介</span></strong><br> K-Means 聚类算法能轻松地对聚类问题建模。 K-Means 聚类算法容易理解，并且能在分布式的环境下并行运行。学习 K-Means 聚类算法，能更容易地理解聚类算法的优缺点，以及其他算法对于特定数据的高效性。<br> K-Means 聚类算法中的 K 是聚类的数目，在算法中会强制要求用户输入。如果将新闻聚类成诸如政治、经济、文化等大类，可以选择 10 ～ 20 的数字作为 K。因为这种顶级类别的数量是很小的。如果要对这些新闻详细分类，选择 50 ～ 100 的数字也是没有问题的。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　K-Means 聚类算法主要可以分为三步：</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　第一步是为待聚类的点寻找聚类中心；<br> 第二步是计算每个点聚类中心的距离，将每个点聚类到离该点最近的聚类中去；</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　第三步是计算聚类中所有点的坐标平均值，并将这个平均值作为新的聚类中心点。反复执行第二步，直到聚类中心不再进行大范围的移动，或者聚类次数达到要求为止。<br><br> 2）&nbsp;<strong><span style="color:rgb(0,0,255);">k-Means 示例</span></strong><br> 下面的例子中有 7 名选手，每名选手有两个类别的比分， A 类比分和 B 类比分如表 1 所示。<br> 表1 &nbsp;A 类和 B 类比分<br><img src="http://images2015.cnblogs.com/blog/855959/201608/855959-20160801170416715-218661624.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　这些数据将会聚为两个簇。随机选取 1 号和 4 号选手作为簇的中心，如表2所示。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　　　　　　　　　　　　　　　　　　　　　　　表 2 &nbsp; &nbsp; 1 号和 4 号选手信息</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;　　<img src="http://images2015.cnblogs.com/blog/855959/201608/855959-20160801170457122-2132134735.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　将 1 号和 4 号选手分别作为两个簇的中心点，下面每一步将选取的点计算和两个簇中心的欧几里德距离，哪个中心距离小就放到哪个簇中，如表 3所示。<br> 表 3 &nbsp; &nbsp;　第一步聚类</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　<img src="http://images2015.cnblogs.com/blog/855959/201608/855959-20160801170537106-1225061383.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　第一轮聚类的结果产生了，如表 4 所示。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;　　　　　　　　　　　　　　　　　　　　　　　　表 4 &nbsp;　第一轮结果</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　<img src="http://images2015.cnblogs.com/blog/855959/201608/855959-20160801170542481-141651968.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　第二轮将使用 (1.8,2.3) 和 (4.1,5.4) 作为新的簇中心，重复以上的过程。直到迭代次数达到用户设定的次数终止。最后一轮的迭代分出的两个簇就是最后的聚类结果。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br> 3）&nbsp;<strong><span style="color:rgb(0,0,255);">MLlib 之 K-Means 源码解析</span></strong><br> MLlib 中的 K-Means 的原理是：在同一个数据集上，跑多个 K-Means 算法（每个称为一个 run），然后返回效果最好的那个聚类的类簇中心。初始的类簇中心点的选取有两种方法，一种是随机，另一种是采用 KMeans||（KMeans++ 的一个变种）。算法的停止条件是迭代次数达到设置的次数，或者在某一次迭代后所有 run 的 K-Means 算法都收敛。<br> ① 类簇中心初始化。<br> 本节介绍的初始化方法是对于每个运行的 K-Means 都随机选择 K 个点作为初始类簇：</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;">
    <pre><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">private</span> def initRandom(data: RDD[Array[Double]]): Array[ClusterCenters] =<span style="font-size:12px;line-height:1.5;"> {
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> Sample all the cluster centers in one pass to avoid repeated scans</span>
val sample = data.takeSample(<span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">true</span>, runs * k, <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">new</span><span style="font-size:12px;line-height:1.5;"> Random().nextInt()).toSeq
Array.tabulate(runs)(r </span>=&gt; sample.slice(r * k, (r + <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">1</span>) *<span style="font-size:12px;line-height:1.5;"> k).toArray)
}</span></pre>
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br> ② 计算属于某个类簇的点。<br> 在每一次迭代中，首先会计算属于各个类簇的点，然后更新各个类簇的中心。<br> // K-Means 算法的并行实现通过 Spark 的 mapPartitions 函数 , 通过该函数获取到分区的迭代器。<br> 可以在每个分区内计算该分区内的点属于哪个类簇<br> // 之后对于每个运行算法中的每个类簇计算属于该类簇的点的个数以及累加和。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="font-size:12px;line-height:1.5;"><a title="复制代码" style="border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre>val totalContribs = data.mapPartitions { points =&gt;<span style="font-size:12px;line-height:1.5;">
val runs </span>=<span style="font-size:12px;line-height:1.5;"> activeCenters.length
val k </span>= activeCenters(<span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span><span style="font-size:12px;line-height:1.5;">).length
val dims </span>= activeCenters(<span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span>)(<span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span><span style="font-size:12px;line-height:1.5;">).length
val sums </span>= Array.fill(runs, k)(<span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">new</span><span style="font-size:12px;line-height:1.5;"> DoubleMatrix(dims))
val counts </span>= Array.fill(runs, k)(<span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0L</span><span style="font-size:12px;line-height:1.5;">)
</span><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">for</span> (point &lt;- points; (centers, runIndex) &lt;-<span style="font-size:12px;line-height:1.5;"> activeCenters.zipWithIndex) {
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 找到距离该点最近的类簇中心点</span>
val (bestCenter, cost) =<span style="font-size:12px;line-height:1.5;"> KMeans.findClosest(centers, point)
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 统计该运行算法开销 , 用于在之后选取开销最小的那个运行的算法</span>
costAccums(runIndex) +=<span style="font-size:12px;line-height:1.5;"> cost
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 将该点加到最近的类簇的统计总和中去 , 方便之后计算该类簇的新中心点</span>
sums(runIndex)(bestCenter).addi(<span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">new</span><span style="font-size:12px;line-height:1.5;"> DoubleMatrix(point))
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 将距离该点最近的类簇的点数量加 1,sum.divi(count) 就是类簇的新中心</span>
counts(runIndex)(bestCenter) += <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">1</span><span style="font-size:12px;line-height:1.5;">
}
val contribs </span>= <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">for</span> (i &lt;- <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span> until runs; j &lt;- <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span> until k) <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">yield</span><span style="font-size:12px;line-height:1.5;"> {
((i, j), (sums(i)(j), counts(i)(j)))
}
contribs.iterator
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 对于每个运行算法的每个类簇计算属于该类簇的点的个数和加和</span>
<span style="font-size:12px;line-height:1.5;">}.reduceByKey(mergeContribs).collectAsMap()
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> mergeContribs 是一个负责合并的函数 :</span>
def mergeContribs(p1: WeightedPoint, p2: WeightedPoint): WeightedPoint =<span style="font-size:12px;line-height:1.5;"> {
(p1._1.addi(p2._1), p1._2 </span>+<span style="font-size:12px;line-height:1.5;"> p2._2)
}</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="font-size:12px;line-height:1.5;"><a title="复制代码" style="border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　③更新类簇的中心点。</p> 
   <div class="cnblogs_code" style="border:1px solid rgb(204,204,204);font-family:'Courier New';font-size:12px;"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="font-size:12px;line-height:1.5;"><a title="复制代码" style="border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
    <pre><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">for</span> ((run, i) &lt;-<span style="font-size:12px;line-height:1.5;"> activeRuns.zipWithIndex) {
</span><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">var</span> changed = <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">false</span>
<span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">for</span> (j &lt;- <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span><span style="font-size:12px;line-height:1.5;"> until k) {
val (sum, count) </span>=<span style="font-size:12px;line-height:1.5;"> totalContribs((i, j))
</span><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">if</span> (count != <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">0</span><span style="font-size:12px;line-height:1.5;">) {
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 计算类簇的新的中心点</span>
val newCenter =<span style="font-size:12px;line-height:1.5;"> sum.divi(count).data
</span><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">if</span> (MLUtils.squaredDistance(newCenter, centers(run)(j)) &gt; epsilon *<span style="font-size:12px;line-height:1.5;">
epsilon) {
</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 此处与代码和算法的停止条件有关</span>
changed = <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">true</span><span style="font-size:12px;line-height:1.5;">
}
centers(run)(j) </span>=<span style="font-size:12px;line-height:1.5;"> newCenter
}

</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;">//</span><span style="color:rgb(0,128,0);font-size:12px;line-height:1.5;"> 如果某个 run 的 KMeans 算法的某轮次迭代中 K 个类簇的中心点变化都不超过指定阈值 ,</span>
<span style="font-size:12px;line-height:1.5;">　　　　　 则认为该 KMeans 算法收敛。
</span><span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">if</span> (!<span style="font-size:12px;line-height:1.5;">changed) {
active(run) </span>= <span style="color:rgb(0,0,255);font-size:12px;line-height:1.5;">false</span><span style="font-size:12px;line-height:1.5;">
logInfo(</span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">"</span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">Run </span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">"</span> + run + <span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">"</span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;"> finished in </span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">"</span> + (iteration + <span style="color:rgb(128,0,128);font-size:12px;line-height:1.5;">1</span>) + <span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">"</span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;"> iterations</span><span style="color:rgb(128,0,0);font-size:12px;line-height:1.5;">"</span><span style="font-size:12px;line-height:1.5;">)
}
costs(run) </span>=<span style="font-size:12px;line-height:1.5;"> costAccums(i).value
}</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy" style="font-size:12px;line-height:1.5;"><a title="复制代码" style="border:none;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码" style="border:none;"></a></span>
    </div> 
   </div> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　④ 算法停止条件。<br> 算法的停止条件是迭代次数达到设置的次数，或者所有运行的 K-Means 算法都收敛：<br> while (iteration &lt; maxIterations &amp;&amp; !activeRuns.isEmpty)<br> 上文对典型聚类算法 K-Means 原理进行介绍，下面将对典型的分类算法朴素贝叶斯算法进行介绍。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br><br><span style="font-size:18px;"><strong>（2）朴素贝叶斯分类算法</strong></span><br> 朴素贝叶斯分类算法是贝叶斯分类算法多个变种之一。朴素指假设各属性之间是相互独立的。研究发现，在大多数情况下，朴素贝叶斯分类算法（naive bayes classif ier）在性能上与决策树（decision tree）、神经网络（netural network）相当。贝叶斯分类算法<br> 在大数据集的应用中具有方法简便、准确率高和速度快的优点。但事实上，贝叶斯分类也有其缺点。由于贝叶斯定理假设一个属性值对给定类的影响独立于其他的属性值，而此假设在实际情况中经常是不成立的，则其分类准确率可能会下降。朴素贝叶斯分类算法是一种监督学习算法，使用朴素贝叶斯分类算法对文本进行分类，主要有两种模型，即多项式模型（multinomial model）和伯努利模型（bernoullimodel）。 MLlib 使用的是被广泛使用的多项式模型。本书将以一个实际的例子来简略介绍使用多项式模型的朴素贝叶斯分类算法。在多项式模型中，设某文档 d=(t1,t2,…,tk)， tk 是该文档中出现过的单词，允许重复。<br> 先验概率 P(c) = 类 c 下单词总数 / 整个训练样本的单词总数类条件概率 P(tk|c) = ( 类 c 下单词 tk 在各个文档中出现过的次数之和 +1)/( 类 c 下单词总数 +|V|)， V 是训练样本的单词表（即抽取单词，单词出现多次，只算一个）， |V| 则表示训练样本包含多少种单词。P(tk|c) 可以看作是单词 tk 在证明 d 属于类 c 上提供了多大的证据，而 P(c) 则可以认为是类别 c 在整体上占多大比例（有多大可能性）。给定一组分好类的文本训练数据，如表 3-10 所示。<br> 给定一个新样本（河北河北河北吉林香港），对其进行分类。该文本用属性向量表示为 d=( 河北 , 河北 , 河北 , 吉林 , 香港 )，类别集合为 Y={yes, no}。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　　　　　　　　　　　　　　　　　　　　　　　表 5 &nbsp;　文本训练数据</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;　　<img src="http://images2015.cnblogs.com/blog/855959/201608/855959-20160801170733434-767588338.png" alt="" style="border:0px;"></p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">　　类 yes 下总共有 8 个单词，类 no 下总共有 3 个单词，训练样本单词总数为 11，因此 P(yes)=8/11, P(no)=3/11。类条件概率计算如下：<br><br> P( 河北 | yes)=(5+1)/(8+6)=6/14=3/7<br> P( 河北 | yes)=P( 吉林 | yes)= (0+1)/(8+6)=1/14<br> P( 河北 |no)=(1+1)/(3+6)=2/9<br> P(Japan|no)=P( 吉林 | no) =(1+1)/(3+6)=2/9<br> 分母中的 8，是指 yes 类别下 textc 的长度，也即训练样本的单词总数， 6 是指训练样本有河北、北京、上海、广东、吉林、香港，共 6 个单词， 3 是指 no 类下共有 3 个单词。<br> 有了以上类条件概率，开始计算后验概率：<br> P(yes | d)=(3/7)3×1/14×1/14×8/11=108/184877≈0.00058417<br> P(no | d)= (2/9)3×2/9×2/9×3/11=32/216513≈0.00014780<br> 比较大小，即可知道这个文档属于类别河北。</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;">&nbsp;</p> 
   <p style="font-family:Verdana, Arial, Helvetica, sans-serif;font-size:14px;"><br></p> 
   <p><font><span style="font-size:14px;">本文转自大数据躺过的坑博客园博客，原文链接：http://www.cnblogs.com/zlslch/p/5726501.html，如需转载请自行联系原作者</span></font><br></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
