<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>stanford coursera 机器学习编程作业 exercise 5（正则化线性回归及偏差和方差） « NotBeCN</title>
  <meta name="description" content="             本文根据水库中蓄水标线(water level) 使用正则化的线性回归模型预 水流量(water flowing out of dam)，然后 debug 学习算法 以及 讨论偏差和方差对 该线性回归模型的影响。    &nbsp;    ①可视化数据集    本作业的数据集分成三部分：...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2017/10/05/weixin_33873846_90122222.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">stanford coursera 机器学习编程作业 exercise 5（正则化线性回归及偏差和方差）</h1>
    <p class="post-meta">Oct 5, 2017</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="content-detail markdown-body"> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">本文根据水库中蓄水标线(water level) 使用正则化的线性回归模型预 水流量(water flowing out of dam)，然后 debug 学习算法 以及 讨论偏差和方差对 该线性回归模型的影响。</span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">①可视化数据集</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">本作业的数据集分成三部分：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">ⓐ训练集(training set)，样本矩阵(训练集)：X，结果标签(label of result)向量 y</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">ⓑ交叉验证集(cross validation set)，确定正则化参数 Xval 和 yval</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">ⓒ测试集(test set) for evaluating performance，测试集中的数据 是从未出现在 训练集中的</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">将数据加载到Matlab中如下：训练集中一共有12个训练实例，每个训练实例只有一个特征。故假设函数h<sub>θ</sub>(x) = θ<sub>0</sub>·x<sub>0</sub> + θ<sub>1</sub>·x<sub>1</sub> ，用向量表示成：<span style="color:rgb(255,0,0);">h<sub>θ</sub>(x) = θ<sup>T</sup>·x</span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">一般地，x<sub>0</sub> 为 bais unit，默认 x<sub>0</sub>==1</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="425" height="231" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129162718896-1768763307.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">训练数据集中的数据图形表示如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="471" height="408" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129153344646-1798977896.png"></span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">②正则化线性回归模型的代价函数</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">代价函数公式如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="549" height="92" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129153528365-1201373640.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">Matlab代码实现如下：这里的代价函数是用<strong>向量(矩阵)乘法</strong>来实现的。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">具体证明可参考：<a href="http://www.cnblogs.com/hapjin/p/6079012.html" rel="nofollow">Linear Regression---实现一个线性回归</a> </span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:15px;">reg = (lambda / (2*m)) * ( ( theta( <span style="color:rgb(255,0,0);">2:length(theta)</span> ) )' * theta(<span style="color:rgb(255,0,0);">2:length(theta)</span>) );
J = sum((X*theta-y).^2)/(2*m) + reg;</span></pre>
   </div> 
   <p>&nbsp;注意：由于θ<sub>0</sub>不参与正则化项的，故上面Matlab数组下标是从2开始的(Matlab数组下标是从1开始的，θ<sub>0</sub>是Matlab数组中的第一个元素)。</p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">③正则化的线性回归梯度</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">梯度的计算公式如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="477" height="137" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129161640427-1366890157.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">其中，下面公式的向量表示就是：[X<sup>T</sup>&nbsp;· (X·θ - y)]/m，用Matlab表示就是：<span style="font-size:14px;">X'*(X*theta-y) / m</span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="258" height="72" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129165621896-978552011.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">梯度的Matlab代码实现如下：</span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:14px;">grad_tmp = X'*(X*theta-y) / m;
grad = [ grad_tmp(1:1); grad_tmp(2:end) + (lambda/m)*theta(2:end) ];</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">④使用Matlab的函数 fmincg 函数训练线性回归模型，得到模型的参数，trainLinearReg.m如下：</span></strong></p> 
   <div class="cnblogs_code"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
    <pre><span style="font-size:14px;">function [theta] = trainLinearReg(X, y, lambda)
%TRAINLINEARREG Trains linear regression given a dataset (X, y) and a
%regularization parameter lambda
%   [theta] = TRAINLINEARREG (X, y, lambda) trains linear regression using
%   the dataset (X, y) and regularization parameter lambda. Returns the
%   trained parameters theta.
%

% Initialize Theta
initial_theta = zeros(size(X, 2), 1); 

% Create "short hand" for the cost function to be minimized
<span style="color:rgb(255,0,0);">costFunction = @(t) linearRegCostFunction(X, y, t, lambda);</span>

% Now, costFunction is a function that takes in only one argument
options = optimset('MaxIter', 200, 'GradObj', 'on');

% Minimize using fmincg
theta = <span style="color:rgb(255,0,0);">fmincg</span>(costFunction, initial_theta, options);

end</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">但是，在<a href="http://www.cnblogs.com/hapjin/p/6079012.html" rel="nofollow">作业一</a>中，我们并不是通过Matlab的 fmincg 函数来求得模型参数的，而是通过下面的公式 在for循环中 求得 模型参数θ</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129170630974-202439921.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">其Matlab实现如下：</span></p> 
   <div class="cnblogs_code">
    <pre>for iter = 1:num_iters
   <span style="color:rgb(255,0,0);"> theta = theta - (alpha/m)*X'*(X*theta-y)</span>; % theta 就是用上面的向量表示法的 matlab 语言实现
....
end</pre>
   </div> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">⑤线性回归模型的图形化表示</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">上面已经通过 fmincg 求得了模型参数了，那么我们求得的模型 与 数据的拟合程度 怎样呢？看下图：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="476" height="438" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161129170914302-2036121145.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从上图中可以看出，由于我们的数据是二维的，但是却用一个线性模型去拟合，故很明显出现了 underfiting problem</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">在这里，我们很容易将模型以图形化方式表现出来，因为，我们的训练数据的特征很少(一维)。当训练数据的特征很多(feature variables)时，就很难画图了(三维以上很难直接用图形表示了...)。<span style="color:rgb(255,0,0);">这时，就需要用 “学习曲线”来检查 训练出来的模型与数据是否很好地拟合了。</span></span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:14px;">The best fit line tells us that the model is not a good fit to the data because the data has a non-linear pattern.
While visualizing the best fit as shown is one possible way to debug your learning algorithm,<br><span style="color:rgb(255,0,0);">it is not always easy to visualize the data and model(比如，当特征超过3维时...)</span></span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">⑥偏差与方差之间的权衡</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">高偏差---欠拟合，underfit</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">高方差---过拟合，overfit</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">可以用学习曲线(learning curve)来诊断偏差--方差 问题。学习曲线的 x 轴是训练集大小(training set size)，y 轴则是交叉验证误差和训练误差。<br></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">训练误差的定义如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="350" height="87" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130085308302-799613904.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">注意：训练误差J<sub>train</sub>(θ)是没有正则化项的，因此在调用linearRegCostFunction时，lambda==0。Matlab实现如下(learningCurve.m)</span></p> 
   <p>&nbsp;</p> 
   <div class="cnblogs_code"> 
    <img class="code_img_closed" alt="" src="https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif">
    <img class="code_img_opened" alt="" src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif">
    <div class="cnblogs_code_hide">
     <pre>function [error_train, error_val] = ...
    learningCurve(X, y, Xval, yval, lambda)
%LEARNINGCURVE Generates the train and cross validation set errors needed 
%to plot a learning curve
%   [error_train, error_val] = ...
%       LEARNINGCURVE(X, y, Xval, yval, lambda) returns the train and
%       cross validation set errors for a learning curve. In particular, 
%       it returns two vectors of the same length - error_train and 
%       error_val. Then, error_train(i) contains the training error for
%       i examples (and similarly for error_val(i)).
%因为 m 是一样的，所以 error_val 和 error_train 向量有着相同的元素个数
%   In this function, you will compute the train and test errors for
%   dataset sizes from 1 up to m. In practice, when working with larger
%   datasets, you might want to do this in larger intervals.
%

% Number of training examples
m = size(X, 1);

% You need to return these values correctly
error_train = zeros(m, 1);
error_val   = zeros(m, 1);

% ====================== YOUR CODE HERE ======================
% Instructions: Fill in this function to return training errors in 
%               error_train and the cross validation errors in error_val. 
%               i.e., error_train(i) and 
%               error_val(i) should give you the errors
%               obtained after training on i examples.
%
% Note: You should evaluate the training error on the first i training
%       examples (i.e., X(1:i, :) and y(1:i)).
%
%       For the cross-validation error, you should instead evaluate on
%       the _entire_ cross validation set (Xval and yval).
%
% Note: If you are using your cost function (linearRegCostFunction)
%       to compute the training and cross validation error, you should 
%       call the function with the lambda argument set to 0. 
%       Do note that you will still need to use lambda when running
%       the training to obtain the theta parameters.
%
% Hint: You can loop over the examples with the following:
%
%       for i = 1:m
%           % Compute train/cross validation errors using training examples 
%           % X(1:i, :) and y(1:i), storing the result in 
%           % error_train(i) and error_val(i)
%           ....
%           
%       end
%

% ---------------------- Sample Solution ----------------------

for i = 1:m
        theta = trainLinearReg(X(1:i, :), y(1:i), lambda);
        error_train(i) = linearRegCostFunction(X(1:i, :), y(1:i), theta, 0);
        error_val(i) = linearRegCostFunction(Xval, yval, theta, 0);
    
% -------------------------------------------------------------
% =========================================================================

end</pre>
    </div> 
    <span class="cnblogs_code_collapse">View Code</span> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">学习曲线的图形如下：可以看出欠拟合时，在 training examples 数目很少时，训练出来的模型还能拟合"一点点数据"，故训练误差相对较小；但对于交叉验证误差而言，它是使用未知的数据得算出来到的，而现在模型欠拟合，故几乎不能 拟合未知的数据，因此交叉验证误差非常大。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">随着 training examples 数目的增多，由于欠拟合，训练出来的模型越来越来能拟合一些数据了，故训练误差增大了。而对于交叉验证误差而言，最终慢慢地与训练误差一致并变得越来越平坦，此时，再增加训练样本(training examples)已经对模型的训练效果没有太大影响了---在欠拟合情况下，再增加训练集的个数也不能再降低训练误差了。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="563" height="519" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130160653068-763509850.png"></span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">⑦多项式回归</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从上面的学习曲线图形可以看出：出现了underfit problem，通过添加更多的特征(features)，使用更高幂次的多项式来作为假设函数拟合数据，以解决欠拟合问题。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">多项式回归模型的假设函数如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="790" height="181" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130102550756-1447304740.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">通过对特征“扩充”，以添加更多的features，代码实现如下：polyFeatures.m</span></p> 
   <div class="cnblogs_code"> 
    <img class="code_img_closed" alt="" src="https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif">
    <img class="code_img_opened" alt="" src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif">
    <div class="cnblogs_code_hide">
     <pre>function [X_poly] = polyFeatures(X, p)
%POLYFEATURES Maps X (1D vector) into the p-th power
%   [X_poly] = POLYFEATURES(X, p) takes a data matrix X (size m x 1) and
%   maps each example into its polynomial features where
%   X_poly(i, :) = [X(i) X(i).^2 X(i).^3 ...  X(i).^p];
%


% You need to return the following variables correctly.
X_poly = zeros(numel(X), p);

% ====================== YOUR CODE HERE ======================
% Instructions: Given a vector X, return a matrix X_poly where the p-th 
%               column of X contains the values of X to the p-th power.
%
% 
%X_ploy(:, 1) = X;
for i = 1:p
    X_poly(:,i) = X.^i;
end
% =========================================================================

end</pre>
    </div> 
    <span class="cnblogs_code_collapse">View Code</span> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">“扩充”了特征之后，就变成了多项式回归了，但由于多项式回归的特征取值范围差距太大（比如有些特征的取值很小，而有些特征的取值非常大），故需要用到Normalization(归一化)，归一化的代码如下：</span></p> 
   <div class="cnblogs_code"> 
    <img class="code_img_closed" alt="" src="https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif">
    <img class="code_img_opened" alt="" src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif">
    <div class="cnblogs_code_hide">
     <pre>function [X_norm, mu, sigma] = featureNormalize(X)
%FEATURENORMALIZE Normalizes the features in X 
%   FEATURENORMALIZE(X) returns a normalized version of X where
%   the mean value of each feature is 0 and the standard deviation
%   is 1. This is often a good preprocessing step to do when
%   working with learning algorithms.

mu = mean(X);
X_norm = bsxfun(@minus, X, mu);

sigma = std(X_norm);
X_norm = bsxfun(@rdivide, X_norm, sigma);

% ============================================================
end</pre>
    </div> 
    <span class="cnblogs_code_collapse">View Code</span> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">继续再用原来的linearRegCostFunction.m计算多项式回归的代价函数和梯度，得到的多项式回归模型的假设函数的图形如下：（注意：lambda==0，没有使用正则化）：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="454" height="398" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130163849427-1005635672.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从多项式回归模型的 图形看出：它几乎很好地拟合了所有的训练样本数据。因此，可认为出现了：过拟合问题(overfit problem)---高方差</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">多项式回归模型的学习曲线 图形如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="424" height="389" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130164216787-226011919.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从多项式回归的学习曲线图形看出：训练误差几乎为0(非常贴近 x 轴了)，这正是因为过拟合---模型几乎完美地穿过了训练数据集中的每个数据点，从而训练误差非常小。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">交叉验证误差先是很大(训练样本数目为2时)，然后随着训练样本数目的增多，cross validation error 变得越来越小了(训练样本数目2 增加到 5 过程中)；然后，当训练样本数目再增多时（11个以上的训练样本时...），<span style="color:rgb(255,0,0);">交叉验证误差又变得大了(过拟合导致泛化能力下降)</span>。</span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">⑧使用正则化来解决多项化回归模型的过拟合问题</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">设置正则化项 <span style="color:rgb(255,0,0);">lambda == 1(λ==1)</span>时，得到的模型假设函数图形如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="463" height="412" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130165635677-2079430253.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">可以看出：这里的拟合曲线不再是 lambda == 0 时 那样弯弯曲曲的了，也不是非常精准地穿过每一个点，而是变得相对比较平滑。这正是 正则化 的效果。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">lambda==1 <span style="color:rgb(255,0,0);">(λ==1) </span>时的学习曲线如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="485" height="428" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130170055896-1949912296.png"></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">lambda==1时的学习曲线表明：该模型有较好的泛化能力，能够对未知的数据进行较好的预测。因为，它的交叉验证误差和训练误差非常接近，且非常小。（训练误差小，表明模型能很好地拟合数据，但有可能出现过拟合的问题，过拟合时，是不能很好地对未知数据进行预测的；而此处交叉验证误差也小，表明模型也能够很好地对未知数据进行预测）</span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">最后来看下，多项式回归模型的正则化参数 lambda == 100(λ==100)时的情况：<span style="color:rgb(255,0,0);">（出现了underfit problem--欠拟合--高偏差）</span></span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">模型“假设函数”曲线如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="454" height="403" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130170651599-388801523.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">学习曲线图形如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="420" height="386" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130170720584-1184677556.png"></span></p> 
   <p>&nbsp;</p> 
   <p><strong><span style="font-family:'Microsoft YaHei';font-size:16px;">⑨如何自动选择合适的 正则化参数 lambda(λ) ？</span></strong></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从第⑧点中看出：正则化参数 lambda(λ) 等于0时，出现了过拟合， lambda(λ) 等于100时，又出现了欠拟合， lambda(λ) 等于1时，模型刚刚好。</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">那在训练过程中如何自动选择合适的lambda参数呢？</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">可以<span style="color:rgb(255,0,0);">使用交叉验证集</span>(根据交叉验证误差来选择合适的 lambda 参数)</span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:15px;">Concretely, you will <span style="color:rgb(255,0,0);">use a cross validation set to evaluate how good each lambda value is.</span><br>
After selecting the best lambda value using the cross validation set, <br>
we can then evaluate the model on the test set to estimate how well the model will perform on actual unseen data.</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">&nbsp;具体的选择方法如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">首先有一系列的待选择的 lambda(λ) 值，在本λ作业中用一个lambda_vec向量保存这些 lambda 值（一共有10个）：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">lambda_vec = [0 0.001 0.003 0.01 0.03 0.1 0.3 1 3 10]'</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">然后，使用训练数据集 针对这10个 lambda 分别训练 10个正则化的模型。然后对每个训练出来的模型，计算它的交叉验证误差，<span style="color:rgb(255,0,0);">选择交叉验证误差最小的那个模型所对应的lambda(λ)值，作为最适合的 </span><span style="color:rgb(255,0,0);">λ</span> 。（注意：在计算训练误差和交叉验证误差时，是没有正则化项的，相当于 lambda==0） </span></p> 
   <div class="cnblogs_code">
    <pre><span style="font-size:15px;">for i = 1:length(lambda_vec)
   theta = trainLinearReg(X,y,lambda_vec(i));%对于每个lambda,训练出模型参数theta
   %compute jcv and jval without regularization,causse last arguments(lambda) is zero 
   error_train(i) = linearRegCostFunction(X, y, theta, 0);%计算训练误差
  <span style="color:rgb(255,0,0);"> error_val(i) = linearRegCostFunction(Xval, yval, theta, 0)</span>;%计算交叉验证误差
end</span></pre>
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">对于这10个不同的 lambda，计算出来的训练误差和交叉验证误差如下：</span></p> 
   <div class="cnblogs_code"> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
    <pre><span style="font-size:15px;">lambda     Train Error   Validation Error
 0.000000    0.173616    22.066602
 0.001000    0.156653    18.597638
 0.003000    0.190298    19.981503
 0.010000    0.221975    16.969087
 0.030000    0.281852    12.829003
 0.100000    0.459318    7.587013
 0.300000    0.921760    4.636833
 <span style="color:rgb(255,0,0);">1.000000 2.076188 4.260625</span>
<span style="color:rgb(255,0,0);"> 3.000000 4.901351 3.822907</span>
 10.000000   16.092213   9.945508</span></pre> 
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></span>
    </div> 
   </div> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">训练误差、交叉验证误差以及 lambda 之间的关系 图形表示如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">当 lambda &gt;= 3 的时候，交叉验证误差开始上升，如果再增大 lambda 就可能出现欠拟合了...</span></p> 
   <p><img width="447" height="416" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130171638131-456785755.png"></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">从上面看出：lambda == 3 时，交叉验证误差最小。lambda==3时的拟合曲线如下：（可与 lambda==1时的拟合曲线及学习曲线对比一下，看有啥不同）</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="448" height="398" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130224122271-684319935.png"></span></p> 
   <p>&nbsp;</p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;">学习曲线如下：</span></p> 
   <p><span style="font-family:'Microsoft YaHei';font-size:16px;"><img width="477" height="444" alt="" src="https://images2015.cnblogs.com/blog/715283/201611/715283-20161130224311349-446401082.png"></span></p> 
   <p><br> 完整地理一遍这个东西，真的好累啊。还是有很多不懂。。。。</p> 
   <p><br></p> 
   <p>本文转自hapjin博客园博客，原文链接：http://www.cnblogs.com/hapjin/，如需转载请自行联系原作者<br></p> 
  </div> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
