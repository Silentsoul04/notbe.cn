<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>车主之家-汽车销量与汽车配置-python爬虫实现 « NotBeCN</title>
  <meta name="description" content="                       车主之家-汽车销量与汽车配置-python爬虫实现    作为一名数据分析师，在分析问题时，获取数据是最重要的环节之一，没有数据就如巧妇难为无米之炊，就不能对问题进行定性与定量的描述，自然也无法获得针对性的策略。目前，数据分析师主要的获取数据的渠道有：企业内部运行数据...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/11/weixin_37729220_90116179.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">车主之家-汽车销量与汽车配置-python爬虫实现</h1>
    <p class="post-meta">May 11, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p></p>
  <div class="toc">
   <h3>车主之家-汽车销量与汽车配置-python爬虫实现</h3>
   <br> 作为一名数据分析师，在分析问题时，获取数据是最重要的环节之一，没有数据就如巧妇难为无米之炊，就不能对问题进行定性与定量的描述，自然也无法获得针对性的策略。目前，数据分析师主要的获取数据的渠道有：企业内部运行数据，社会统计数据，咨询公司，市场调研，网络数据等。网络数据是目前获取大量数据成本较低，数据质量较高的一个渠道。大家在获取网络数据时，会不会遇到这样的痛点：自己所需要的数据网络上都能查询的到，但是数据量却很大，人工摘取几乎是不可能完成的事情。今天就要介绍一个工具来帮大家解决这一痛点–利用Python进行网络爬虫。
  </div>
  <p></p> 
  <p><strong>什么是爬虫？</strong><br> 首先需要介绍的就是什么是网络爬虫，网络爬虫是一种设定一定的规则大批量的自动的从网络上获取数据的手段，目前网络上的爬虫工具都非常多，例如：集搜客，八爪鱼等等，这些工具是不需要的任何的编程基础的，只需要初步的了解网页结构知识就可以掌握，这一类不需要编程的工具功能相对单一，对个性化的爬虫需求不能很好的满足，与数据处理与分析的衔接相对较弱。而今天，我们要介绍的利用python进行爬虫，是需要有一定的编程基础，能实现个性化的爬虫需求，以及可以突破网站的各种爬虫限制。</p> 
  <p><strong>数据分析师需要将爬虫掌握到什么程度？</strong><br> 在具体的介绍爬虫案例之前，再讨论一下数据分析师需要将爬虫掌握到什么程度，爬虫并不是每一个数据分析必须掌握的技能，所以对于一个数据分析师的要求就是，能够获取自己想要的数据即可。</p> 
  <p><strong>车主之家-汽车销量与汽车配置-python爬虫实现：</strong><br> 建议大家如果想要更好的代码体验，请在pc端CSDN网站中搜索‘车主之家-汽车销量与汽车配置-python爬虫实现’即可查看源代码。在此强烈的向大家推荐CSDN这个网站，对于想要通过python学习数据分析的同学，如果在实际操作中遇到了什么问题，就可以在此网站中搜索答案，同样，本篇文章并不能面面俱到，如遇到不懂的问题，随时可在CSDN中搜索答案一定会找到你想要的答案的。</p> 
  <p><strong>话不多说，撸代码：</strong><br> 本文使用selenium进行网络爬虫，使用selenium的优点就是，可以模拟浏览器对数据进行渲染，不会出现原始网页代码与展示的信息不一致的情况，即所见即所得，同时selenium还能实现用户登录，网页模拟浏览等功能，在后边都会提到</p> 
  <pre><code>from selenium import webdriver  
from bs4 import BeautifulSoup
import pandas as pd
driver=webdriver.PhantomJS()    #加载无头浏览器，具体查看selenium文档，可换成火狐或者谷歌浏览器
</code></pre> 
  <p>下面我们将进行第一步，爬取车主之家的车型历史销量，2019年3月的销量页面与连接如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511222604906.png" alt="在这里插入图片描述"><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511222627688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzcyOTIyMA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 对于这一级页面，我们想要爬取的内容是：时间，车型，销量与‘参数’对应的连接（为下一步爬取车辆参数内容做准备），下面就开始 设计爬取该页面内容的爬虫</p> 
  <pre><code>#此函数用于加载网页，并返回无头浏览器全部渲染过的数据，即所见即所得
def get_url(url):
    driver.get(url)             #加载网页
    driver.implicitly_wait(10)   #隐式等待10秒钟，智能等待网页加载
    source=driver.page_source          #获取网页信息
    return source
</code></pre> 
  <p>下面我们就将会对以上函数所返回的数据进行解析，获得我们想要的数据。如下图，我们可以看到对于一个车型，我们想要爬取的所有的信息，下面就开始获取我们想要获取的数据</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511222801938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzcyOTIyMA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <pre><code>def get_info(source):
    soup=BeautifulSoup(source,"lxml")   #对渲染后的网页代码使用BS4进行解析
    car_info=soup.select('table &gt; tbody &gt; tr &gt; td')        #对车辆基本信息定位，获取网页代码
    car_info_=[i.get_text() for i in car_info]          #对代码进行解析，获得内容
    car_info_=[car_info_[i:i+5] for i in range(0,len(car_info_),6)]       
    option_link=soup.select('table &gt; tbody &gt; tr &gt; td &gt; div &gt; a')
    option_link=[i.get('href') for i in option_link]
    option_link=[option_link[i] for i in range(2,len(option_link),6)]
    all_info=np.c_[np.array(car_info_),np.array(option_link)]
    return all_info        #最终返回爬取的内容
</code></pre> 
  <p>该函数返回的内容如下图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511222852373.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzcyOTIyMA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 以上爬虫的核心内容就已经完成了，剩下需要做的就是翻页爬虫和分日期爬虫了。通过观察，翻页和日期都可以通过构造网页链接的形式来解决，那接下来就构造网页链接</p> 
  <pre><code>def links(month):
    #https://xl.16888.com/style-201903-201903-1.html
    links=[]
    month_=[i+j
                for i in ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']
                for j in ['01','02','03','04','05','06','07','08','09','10','11','12']
                if i+j&lt;=month]
    for i in month_:
        page_num=get_url('https://xl.16888.com/style-%s-%s-1.html'%(i,i))
        soup=BeautifulSoup(page_num,"lxml")
        page_num_=soup.select('div.xl-data-page-r &gt; div &gt; span')[0].get_text()
        if int(page_num_[1:4])%50==0:
            page_number=int(int(page_num_[1:4])/50)
        else:
            page_number=int(int(page_num_[1:4])/50)+1
        for j in range(page_number):
            links.append('https://xl.16888.com/style-%s-%s-%s.html'%(i,i,j+1))
    return links
</code></pre> 
  <p>得到的结果如下图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511222944810.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzcyOTIyMA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 所有的准备工作都完成了，现在就要开始爬虫了：</p> 
  <pre><code>url=links(month)
all_info_=pd.DataFrame()
for i in url:
    print(i)
    source=get_url(i)
    all_info=get_info(source)
    date_month=i[27:33]
    date=np.array([date_month for i in range(len(all_info))])
    all_info=np.c_[all_info,date]
    all_info=pd.DataFrame(all_info)
    all_info_=pd.concat([all_info_,all_info])
print(all_info_)
</code></pre> 
  <p>最终的数据如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511223555131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzcyOTIyMA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 大家如果对数据有需求，私信我</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
