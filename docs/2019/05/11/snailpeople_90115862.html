<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>NLP实践一----数据探索 « NotBeCN</title>
  <meta name="description" content="                  nlp实践（一）----数据探索   对IMDB数据集 ： 首先就是对序列进行补全，然后利用embedding（随机初始化词向量） 喂入网络，平均池化，16维的全连接和1维的输出层   import kerasimdb = keras.datasets.imdbimport t...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/11/snailpeople_90115862.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">NLP实践一----数据探索</h1>
    <p class="post-meta">May 11, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h3><a id="nlp_1"></a>nlp实践（一）----数据探索</h3> 
  <p>对IMDB数据集 ：<br> 首先就是对序列进行补全，然后利用embedding（随机初始化词向量） 喂入网络，平均池化，16维的全连接和1维的输出层</p> 
  <pre><code class="prism language-py"><span class="token keyword">import</span> keras
imdb <span class="token operator">=</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>imdb
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span> <span class="token operator">=</span> imdb<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span>num_words<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">)</span>



<span class="token comment">#序列预处理,post是在末尾填充0，长的截断，短的补0,截取前面的</span>
train_data <span class="token operator">=</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>
                                                        value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                                                        padding<span class="token operator">=</span><span class="token string">'post'</span><span class="token punctuation">,</span>
                                                        maxlen<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
                                                        truncating<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">)</span>

test_data <span class="token operator">=</span> keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>
                                                       value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                                                       padding<span class="token operator">=</span><span class="token string">'post'</span><span class="token punctuation">,</span>
                                                       maxlen<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
                                                      truncating<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">)</span>
<span class="token comment"># (25000, 256)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#词汇表大小</span>
vocab_size<span class="token operator">=</span><span class="token number">10000</span>
model<span class="token operator">=</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#embedding层，词向量大小16</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#平均池化</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>GlobalAveragePooling1D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#全连接层</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span>activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment">#优化器，损失函数</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">#feed data</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>
                    train_labels<span class="token punctuation">,</span>
                    epochs<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span>
                    batch_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
                    validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>
                    verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">#评估</span>
result<span class="token operator">=</span>model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>test_labels<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>

<span class="token comment">#创建准确率和损失随时间变化的图</span>
history_dict <span class="token operator">=</span> history<span class="token punctuation">.</span>history
<span class="token keyword">print</span><span class="token punctuation">(</span>history_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
acc<span class="token operator">=</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span>
val_acc<span class="token operator">=</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span>
loss<span class="token operator">=</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>
val_loss<span class="token operator">=</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span>

epochs<span class="token operator">=</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>acc<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">#loss</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span>loss<span class="token punctuation">,</span><span class="token string">'bo'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'Train loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span>val_loss<span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'validate loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Train and validate loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epochs'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#acc</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span>acc<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'train acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span>val_acc<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'train acc'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



</code></pre> 
  <p>对cnews：<br> 处理过程，首先通过content构建词汇表（前5000），然后把content转成词汇表的id，并且对content进行序列标准化，长度为600，最后喂如text_cnn,对字进行embedding，训练得到结果。<br> 参考：<a href="https://blog.csdn.net/u011439796/article/details/77692621" rel="nofollow">https://blog.csdn.net/u011439796/article/details/77692621</a></p> 
  <p>Roc曲线：参考：<a href="https://www.cnblogs.com/dlml/p/4403482.html" rel="nofollow">https://www.cnblogs.com/dlml/p/4403482.html</a><br> 横轴：负正类率(false postive rate FPR)特异度，划分实例中所有负例占所有负例的比例<br> y轴：真正类率(true postive rate TPR)灵敏度，Sensitivity(正类覆盖率)<br> 绘制ROC曲线就是通过划分不同的阀值，得出x,y的值，这样的曲线与右半部分围成的面积就是AUC，不会随着类别分布的改变而改变，但负例N增加了很多，而曲线却没变，这等于产生了大量FP。像信息检索中如果主要关心正例的预测准确性的话，这就不可接受了。<br> 使用场景<br> ROC曲线由于兼顾正例与负例，所以适用于评估分类器的整体性能，相比而言PR曲线完全聚焦于正例。</p> 
  <p>使用场景：参考 <a href="https://www.imooc.com/article/48072" rel="nofollow">https://www.imooc.com/article/48072</a><br> 如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为类别分布改变可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合。<br> 如果想要评估在相同的类别分布下正例的预测情况，则宜选PR曲线。<br> 类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。<br> 最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
