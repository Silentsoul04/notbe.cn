<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>爬虫入门整理 « NotBeCN</title>
  <meta name="description" content="                  爬虫的基本流程   1.发起请求：   通过HTTP库向目标站点发起请求，即发送一个Request，请求可以包含额外的headers等信息，然后等待服务器响应。这个请求的过程就像我们打开浏览器，在浏览器地址栏输入网址：www.baidu.com，然后点击回车。这个过程其实就相当...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/11/weiwei_Allison_90116364.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">爬虫入门整理</h1>
    <p class="post-meta">May 11, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h1><a id="_0"></a>爬虫的基本流程</h1> 
  <p><strong>1.发起请求：</strong></p> 
  <p>通过HTTP库向目标站点发起请求，即发送一个Request，请求可以包含额外的headers等信息，然后等待服务器响应。这个请求的过程就像我们打开浏览器，在浏览器地址栏输入网址：<a href="http://www.baidu.com" rel="nofollow">www.baidu.com</a>，然后点击回车。这个过程其实就相当于浏览器作为一个浏览的客户端，向服务器端发送了 一次请求。</p> 
  <p><strong>2.获取响应内容：</strong></p> 
  <p>如果服务器能正常响应，我们会得到一个Response，Response的内容便是所要获取的内容，类型可能有HTML、Json字符串，二进制数据(图片，视频等）等类型。这个过程就是服务器接收客户端的请求，进过解析发送给浏览器的网页HTML文件。</p> 
  <p><strong>3.解析内容：</strong></p> 
  <p>得到的内容可能是HTML，可以使用正则表达式，网页解析库进行解析。也可能是Json，可以直接转为Json对象解析。可能是二进制数据，可以做保存或者进一步处理。这一步相当于浏览器把服务器端的文件获取到本地，再进行解释并且展现出来。</p> 
  <p><strong>4.保存数据：</strong></p> 
  <p>保存的方式可以是把数据存为文本，也可以把数据保存到数据库，或者保存为特定的jpg，mp4 等格式的文件。这就相当于我们在浏览网页时，下载了网页上的图片或者视频。</p> 
  <h1><a id="_19"></a>相关的库：</h1> 
  <ul> 
   <li>requests库</li> 
   <li>lxml类库</li> 
  </ul> 
  <h2><a id="Requests_24"></a><strong>Requests库介绍</strong></h2> 
  <p>Requests库是Python中的一个HTTP网络请求库，浏览器会发送信息给该网址所在的服务器</p> 
  <p><strong><strong>爬取第一个网页</strong></strong><br> 这里以 “<a href="http://www.baidu.com" rel="nofollow">http://www.baidu.com</a>“为例。<br> 第一步：导入requests库</p> 
  <pre><code>import requests
</code></pre> 
  <p>第二步：创建一个url，这里是”<a href="http://www.baidu.com" rel="nofollow">http://www.baidu.com</a>”</p> 
  <pre><code>url = "http://www.baidu.com"
</code></pre> 
  <p>第三步：对”<a href="http://www.baidu.com" rel="nofollow">http://www.baidu.com</a>“发起一个get请求</p> 
  <pre><code>response = requests.get(url)
</code></pre> 
  <p>这里的response是一个对象，response 对象是服务器发送到客户端的数据</p> 
  <p>第四步：可以调用response对象的方法将服务器端的数据打印一下</p> 
  <pre><code>print(response.text)
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511125315270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXdlaV9BbGxpc29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 可以看到这里的数据是乱码，出现这种情况的原因是：response.text 的解码是根据HTTP头部对响应的编码做出有根据的推测，推测的<strong><strong>文本编码</strong></strong>。也就是说它的解码方式只是一种推测，并不一定正确。<br> 那如何修改编码方式呢？<br> 可以在打印之前增加一行：</p> 
  <pre><code>response.enconding("utf-8")
</code></pre> 
  <p>这行的作用就是将编码格式改为 utf-8 编码，这对大多数网页来说都是可行的。<br> 结果如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511133721783.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXdlaV9BbGxpc29u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 响应状态：有多种响应状态，比如200代表成功，301 跳转页面，404 表示找不到页面，502 表示服务器错误；</p> 
  <pre><code>print(response.status_code) # 打印出状态码
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511133757437.png" alt="在这里插入图片描述"></p> 
  <h2><a id="lxml_75"></a>lxml类库介绍</h2> 
  <p>lxml类库是一个Html/XML的解析器，主要功能是如何解析和提取HTML/XML数据。</p> 
  <p>etree将文本转成html：</p> 
  <pre><code># 将文本转成html对象
html = etree.HTML(text) 

# 将html对象转成html的文本信息
etree.tostring(html)
</code></pre> 
  <p>lxml.etree中提供了几种方法用于解析文本:</p> 
  <pre><code>etree.fromstring()  # 用于解析字符串
etree.HTML()        # 用于解析HTML对象
etree.XML()         # 用于解析XML对象
etree.parse()       # 用于解析文件类型的对象
</code></pre> 
  <h2><a id="XPath_97"></a>XPath介绍</h2> 
  <p>XPath（XML Path Language）是一门在XML文档中查找信息的语言，可用来在XML文档中对元素和属性进行遍历。Xpath为XML路径语言，用来确定XML文档中某个位置，类似于地理中经纬网的作用。</p> 
  <p>XPath的节点有7种类型：文档节点，元素节点，属性节点，文本节点，命名空间节点，处理指令节点，注释节点。对于我们需要关注的是前面4个节点。</p> 
  <p>用 Xpath 获取静态文本：</p> 
  <pre><code>import requests
from lxml import etree

# 用Requests库抓取整个页面
url = 'http://data.eastmoney.com/cjsj/cpi.html'
content = requests.get(url).content

# 用etree.HTML()解析对象
html = etree.HTML(content)

# 右键copy.Xpath复制后，通过etree.xpath()函数调用
html.xpath('//*[@id="tb"]/tr[3]/td[2]/text()')
# 部分浏览器会在table标签下添加tbody标签，因此将Xpath中的tbody删去，否则将无法获取数据。
</code></pre> 
  <p>以Chrome为例，按f12检查网页，用箭头点击自己想要的地方，比如我想提取出“故宫博物院”的xpath地址，右击，点击copy，然后选择copy xpath。这样我们就获得“故宫博物院”的xpath。</p> 
  <pre><code>import requests
from lxml import etree
import lxml
url="http://www.meituan.com/xiuxianyule/271772/"
#你需要爬取的网页
html=requests.get(url)
html.encoding="utf-8"
selecter=etree.HTML(html.text)
#将你的xpath复制到三引号里面，因为xpath里可能有双引号，所以我们加上三引号比较靠谱
s=selecter.xpath("""//*[@id="lego-widget-play-mt-poi-001-000"]/div/div[2]/div[1]/h1/text()""")
print (s)

</code></pre> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
