<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>吴恩达机器学习第五周测验及编程作业 « NotBeCN</title>
  <meta name="description" content="                   测验：Neural Networks: Learning   第一题    答案 B   第二题    答案 A   第三题    答案 D   第四题    答案 AD 分析： A：使用梯度检验来检查反向传播是否正确，正确。 B：梯度检验要比反向传播计算损失函数的梯度慢的多...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/SpicyCoder_90137863.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">吴恩达机器学习第五周测验及编程作业</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="Neural_Networks_Learning_0"></a>测验：Neural Networks: Learning</h2> 
  <h3><a id="_1"></a>第一题</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019051110572964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NwaWN5Q29kZXI=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>答案</strong><br> B</p> 
  <h3><a id="_6"></a>第二题</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511110049445.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NwaWN5Q29kZXI=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>答案</strong><br> A</p> 
  <h3><a id="_11"></a>第三题</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511110216414.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NwaWN5Q29kZXI=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>答案</strong><br> D</p> 
  <h3><a id="_17"></a>第四题</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511110654587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NwaWN5Q29kZXI=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>答案</strong><br> AD<br> 分析：<br> A：使用梯度检验来检查反向传播是否正确，正确。<br> B：梯度检验要比反向传播计算损失函数的梯度慢的多，错误。<br> C：梯度检验对梯度下降算法来说非常有用，错误。<br> D：为了保证效率，在使用反向传播算法前关闭梯度检验，正确。</p> 
  <h3><a id="_27"></a>第五题</h3> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190511111124863.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NwaWN5Q29kZXI=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>答案</strong><br> BC<br> 分析：<br> A：权重为1不能打破堆成，错误。<br> B：正确。<br> C：训练结果可能是到达局部最小值，而不是全局的，正确。<br> D：一层的权重都是一样的数字不能打破对称，错误。</p> 
  <hr> 
  <h2><a id="Neural_Network_Learning_39"></a>编程练习：Neural Network Learning</h2> 
  <h3><a id="Feedforward_and_Cost_Function_41"></a>作业一：Feedforward and Cost Function</h3> 
  <p>Hint：根据文档一步一步来做，注意对y向量的转换</p> 
  <p>nnCostFunction.m</p> 
  <pre><code class="prism language-Matlab">% part1
% 计算假设函数
a1 = [ones(m,1) X];
z2 = a1 * Theta1';
a2 = sigmoid(z2);
a2 = [ones(size(a2,1),1) a2];
z3 = a2 * Theta2';
a3 = sigmoid(z3);
h = a3;     % 5000 x 10


% y是m x 1向量,需要变成m x 10矩阵
u = eye(num_labels);

% 这条语句有点难理解，大概意思是选出每一行的y值作为u的行标，将这行u替换对应行的y
y = u(y,:);         

J = 1/m * sum(sum(-y .* log(h) - (1 - y) .* log(1 - h)));

% 对X添加一列
X = [ones(m,1) X];
</code></pre> 
  <h3><a id="Regularized_Cost_Function_71"></a>作业二：Regularized Cost Function</h3> 
  <p>Hint:注意双重求和的向量化,注意Theta求和时的下标，不正则化0号！<br> nnCostFunction.m</p> 
  <p>下面采用 非向量化和向量化两种方式实现<br> 先看一下效率比较</p> 
  <p>非向量化用时：<code>ans = 0.0012472</code><br> 向量化代码用时：<code>ans = 0.00015712</code></p> 
  <p>可以看出非向量化代码用时是向量化代码用时的近十倍。</p> 
  <p>非向量形式的代码，<strong>不推荐</strong></p> 
  <pre><code class="prism language-Matlab">sum1 = 0;
sum2 = 0;
for i = 1 : size(Theta1,1)
    sum1 += Theta1(i,:) * Theta1'(:,i) - Theta1(i,1)^2;
end;

for i = 1 : size(Theta2,1)
    sum2 += Theta2(i,:) * Theta2'(:,i) - Theta2(i,1)^2;
end;

J += lambda/(2*m) * (sum1 + sum2);

</code></pre> 
  <p>正则化形式的代码,<strong>推荐</strong></p> 
  <pre><code class="prism language-Matlab">% 正则化 （向量化形式）
regularization = lambda / (2*m) * (sum(sum(Theta1(:, 2:end).^2))+ sum(sum(Theta2(: , 2:end).^2 )));
J += regularization;
</code></pre> 
  <h3><a id="Sigmoid_Gradient_110"></a>作业三:Sigmoid Gradient</h3> 
  <p>sigmoidGradient.m</p> 
  <pre><code class="prism language-Matlab">g = sigmoid(z) .* (1 - sigmoid(z));
</code></pre> 
  <h3><a id="Neural_Network_Gradient_Backpropagation_118"></a>作业四：Neural Network Gradient (Backpropagation)</h3> 
  <p>nnCostFunction.m<br> 我是按照步骤一步一步来做的，老师上课说推荐第一次使用for循环，我实在没有get到这个意思，大概可能就是说一步一步来做吧！</p> 
  <pre><code class="prism language-Matlab">% part2
delta3 = a3 - y;           % 5000 x 10
delta2 = delta3 * Theta2;  % 5000 x 26
delta2 = delta2(:,2:end);  % 5000 x 25
delta2 = delta2 .* sigmoidGradient(z2);    % 5000 x 25

Delta1 = zeros(size(Theta1));
Delta2 = zeros(size(Theta2));

Delta1 = Delta1 + delta2' * a1;    % 26 x 400
Delta2 = Delta2 + delta3' * a2;    % 10 x 25

</code></pre> 
  <h3><a id="Regularized_Gradient_137"></a>作业五:Regularized Gradient</h3> 
  <p>nnCostFunction.m</p> 
  <pre><code class="prism language-Matlab">Theta1_grad = 1 / m * Delta1 + lambda / m * Theta1 ;
Theta2_grad = 1 / m * Delta2 + lambda /m  * Theta2 ;

% 0号元素不用正则化
Theta1_grad(:,1) -=  lambda / m * Theta1(:,1); 
Theta2_grad(:,1) -=  lambda / m * Theta2(:,1);
</code></pre> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
