<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>人工神经网络（ANN）及BP算法 « NotBeCN</title>
  <meta name="description" content="                     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;       ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/qq_44993621_90139698.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">人工神经网络（ANN）及BP算法</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-light"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <div class="markdown_views prism-tomorrow-night" id="content_views">
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   <!-- flowchart &#31661;&#22836;&#22270;&#26631; &#21247;&#21024; -->&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    <!-- flowchart &amp;#31661;&amp;#22836;&amp;#22270;&amp;#26631; &amp;#21247;&amp;#21024; --> 
    <h1 id="1-什么是神经网络"><a></a><a target="_blank"></a>1&nbsp; 什么是神经网络</h1>
    <h2 id="11-基本结构"><a></a><a target="_blank"></a>1.1 基本结构</h2>
    <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305094101920?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>说明：</p>
    <ol>
     <li>通常一个神经网络由一个input layer，多个hidden layer和一个output layer构成。</li>
     <li>图中圆圈可以视为一个神经元（又可以称为感知器）</li>
     <li>设计神经网络的重要工作是设计hidden layer，及神经元之间的权重</li>
     <li>添加少量隐层获得浅层神经网络SNN；隐层很多时就是深层神经网络DNN</li>
    </ol>
   </div>
   <h2 id="12-从逻辑回归到神经元"><a></a><a target="_blank"></a>1.2 从逻辑回归到神经元</h2>
   <p>LinearRegression模型： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305102316463?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>sigmoid函数： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305101627090?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>LR可以理解为如下结构： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305101850816?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>所以逻辑回归是一个单层感知器（没有隐层）结构。</p>
   <p>如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击<a href="http://www.captainbed.net/csdn" rel="nofollow" target="_blank">这里</a>可以查看教程。</p>
   <h1 id="2-为什么需要神经网络"><a></a><a target="_blank"></a>2 为什么需要神经网络</h1>
   <p>首先，神经网络应用在分类问题中效果很好。&nbsp; 工业界中分类问题居多。 <br>LR或者linear SVM更适用线性分割。如果数据非线性可分（现实生活中多是非线性的），LR通常需要靠特征工程做特征映射，增加高斯项或者组合项；SVM需要选择核。 而增加高斯项、组合项会产生很多没有用的维度，增加计算量。GBDT可以使用弱的线性分类器组合成强分类器，但维度很高时效果可能并不好。</p>
   <h2 id="21-非线性可分怎么办"><a></a><a target="_blank"></a>2.1 非线性可分怎么办</h2>
   <p>如下图非线性可分 <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305110555815?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>从逻辑回归看，单层感知器只能解决线性问题。要解决非线性问题，需要引入多层感知器（加入隐层）。</p>
   <p>这时使用两个线性分类器，再求逻辑与就可以达到分类的效果。&nbsp; 注意，最开始的两个线性分类器都是部分正确的分类器</p>
   <h2 id="22-神经元完成逻辑与"><a></a><a target="_blank"></a>2.2 神经元完成逻辑与</h2>
   <p>前面说可以使用两个线性分类器的逻辑与可以完成上例的非线性分割。暂时不管两个线性分类器，现在先使用神经元（感知器）达到逻辑与的效果</p>
   <p>假设 <br> <img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305112335169?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305112357402?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305112542481?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305112946406?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>这样，g(z)完成逻辑与： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305113135916?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>调整z的参数，可以实现逻辑或等操作</p>
   <h2 id="23-流程图"><a></a><a target="_blank"></a>2.3 流程图</h2>
   <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305113426764?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>可以看到，先有imput layer生产两个线性分类器，在通过两个线性分类器的权重组合构成逻辑与，完成非线性分类。&nbsp; <br>注意，训练两个线性分类器需要imput的权重，逻辑与又需要两个线性分类器的权重。</p>
   <h2 id="24-效果"><a></a><a target="_blank"></a>2.4 效果</h2>
   <p>对线性分类器的逻辑与和逻辑或的组合可以完美的对平面样本进行分类 <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305113738159?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>隐层决定了最终的分类效果 <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305113920456?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>由上图可以看出，随着隐层层数的增多，凸域将可以形成任意的形状，因此可以解决任何复杂的分类问题。实际上，Kolmogorov理论指出：双隐层感知器就足以解决任何复杂的分类问题。</p>
   <h1 id="3-神经网络表达力与过拟合"><a></a><a target="_blank"></a>3 神经网络表达力与过拟合</h1>
   <ol>
    <li>理论上，单隐层神经网络可以逼近任何连续函数（只要隐层的神经元个数足够）</li>
    <li>虽然从数学上看多隐层和单隐层表达能力一致，但多隐层的神经网络比单隐层神经网络工程效果好很多</li>
    <li>对于一些分类数据（比如CTR预估），3层神经网络效果优于2层神经网络，但如果把层数不断增加（4，5，6层），对最后的结果的帮助没有那么大的跳变</li>
    <li>图像数据比较特殊，是一种深层的结构化数据，深层次的卷积神经网络能更充分和准确的把这些层级信息表达出来</li>
    <li>提升隐层数量或者隐层神经元个数，神经网络的“容量”会变大，空间表达能力会变强</li>
    <li>过多的隐层和神经元结点会带来过拟合问题</li>
    <li>不要试图降低神经网络参数量来减缓过拟合，用正则化或者dropout <br>￼</li>
   </ol>
   <h1 id="4-神经网络结构"><a></a><a target="_blank"></a>4 神经网络结构</h1>
   <h2 id="41-网络结构"><a></a><a target="_blank"></a>4.1 网络结构</h2>
   <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305174207037?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n个输入；输出m个概率</p>
   <h2 id="42-传递函数激活函数"><a></a><a target="_blank"></a>4.2 传递函数/激活函数</h2>
   <pre class="prettyprint"><code class="has-numbering">&nbsp;&nbsp; 前面每一层输入经过线性变换wx+b后还用到了sigmoid函数，在神经网络的结构中被称为传递函数或者激活函数。&nbsp;&nbsp; 除了sigmoid，还有tanh、relu等别的激活函数。激活函数使线性的结果非线性化。</code>
    <div class="hljs-button signin"></div>
    <ul class="pre-numbering">
     <li>1</li>
     <li>2</li>
    </ul>
    <ul class="pre-numbering"></ul></pre>
   <h3 id="421-为什么需要传递函数"><a></a><a target="_blank"></a>4.2.1 为什么需要传递函数</h3>
   <pre class="prettyprint"><code class="has-numbering">简单理解上，如果不加激活函数，无论多少层隐层，最终的结果还是原始输入的线性变化，这样一层隐层就可以达到结果，就没有多层感知器的意义了。所以每个隐层都会配一个激活函数，提供非线性变化。</code>
    <div class="hljs-button signin"></div>
    <ul class="pre-numbering">
     <li>1</li>
     <li>2</li>
    </ul>
    <ul class="pre-numbering"></ul></pre>
   <h3 id="422-介绍两种激活函数"><a></a><a target="_blank"></a>4.2.2 介绍两种激活函数</h3>
   <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305175240551?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">&nbsp; </p>
   <p>双S函数又被称为tanh函数</p>
   <h1 id="5-bp算法"><a></a><a target="_blank"></a>5 BP算法</h1>
   <h2 id="51-网络结构"><a></a><a target="_blank"></a>5.1 网络结构</h2>
   <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305180419543?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1. 正向传播求损失，反向传播回传误差 <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2. 根据误差信号修正每层的权重 <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3. f是激活函数；f(netj)是隐层的输出； f(netk）是输出层的输出O; d是target</p>
   <h2 id="52-如何反向传播"><a></a><a target="_blank"></a>5.2 如何反向传播</h2>
   <p>以三层感知器为例： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305180841201?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>结合BP网络结构，误差由输出展开至输入的过程如下： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305181347079?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>有了误差E，通过求偏导就可以求得最优的权重。（不要忘记学习率） <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305181918948?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>BP算法属于δ学习规则类，这类算法常被称为误差的梯度下降算法。 这类算法要求变换函数可导（sigmoid是满足的)</p>
   <h2 id="53-举例"><a></a><a target="_blank"></a>5.3 举例</h2>
   <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305182331552?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>图中元素： <br>&nbsp;&nbsp;&nbsp; 两个输入； <br>&nbsp;&nbsp;&nbsp; 隐层: b1, w1, w2, w3, w4 (都有初始值） <br>&nbsp;&nbsp;&nbsp; 输出层：b2, w5, w6, w7, w8（赋了初始值）</p>
   <h3 id="531-前向运算-计算误差"><a></a><a target="_blank"></a>5.3.1 前向运算&nbsp; 计算误差</h3>
   <p><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305182910946?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"> <br>则误差： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305183004945?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <h3 id="532-反向传播"><a></a><a target="_blank"></a>5.3.2 反向传播</h3>
   <p>求误差对w5的偏导过程 <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305183223309?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>参数更新： <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305183324681?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>求误差对w1的偏导 <br><img title="" alt="这里写图片描述" src="https://uzshare.com/_p?https://img-blog.csdn.net/20170305183622425?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpdGluZ19pbWVjYXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"></p>
   <p>注意，w1对两个输出的误差都有影响 <br>通过以上过程可以更新所有权重，就可以再次迭代更新了，直到满足条件。</p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  </div> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
