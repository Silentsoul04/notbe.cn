<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Flume环境搭建及主要的对接示例（超详细） « NotBeCN</title>
  <meta name="description" content="                  1.Flume简介       Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。    支持在日志系统中定制各类数据发送方，用于收集数据；    同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力。  ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/zht245648124_90137807.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">Flume环境搭建及主要的对接示例（超详细）</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="1Flume_0"></a>1.Flume简介</h2> 
  <ol> 
   <li>Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。</li> 
   <li>支持在日志系统中定制各类数据发送方，用于收集数据；</li> 
   <li>同时，Flume提供对数据进行简单处理，并写到各种数据接受方(比如文本、HDFS、Hbase等)的能力。</li> 
   <li>名词介绍：<br> Flume OG：Flume original generation,即Flume0.9x版本<br> Flume NG：Flume next generation，即Flume1.x版本<br> 官网：<a href="http://flume.apache.org" rel="nofollow">http://flume.apache.org</a></li> 
  </ol> 
  <h2><a id="2Flume_9"></a>2.Flume体系结构</h2> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512102222229.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3podDI0NTY0ODEyNA==,size_16,color_FFFFFF,t_70" alt="flume"><br> 1.Flume有一个简单、灵活的基于流的数据流结构<br> 2.Flume具有故障转移机制和负载均衡机制<br> 3.Flume使用一个简单可扩展的数据模型(source、channel、sink)<br> 4.目前，flume-ng处理数据有两种方式：avro-client、agent</p> 
  <table> 
   <thead> 
    <tr> 
     <th>avro-client</th> 
     <th>一次性将数据传输到指定的avro服务的客户端</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td><strong>agent</strong></td> 
     <td><strong>一个持续传输数据的服务</strong></td> 
    </tr> 
   </tbody> 
  </table>
  <p>5.Agent主要的组件包括：Source、Channel、Sink</p> 
  <pre><code>Source：完成对日志数据的手机，分成transtion和event打入到channel之中。
Channel：主要提供一个队列的功能，对source提供的数据进行简单的缓存。
Sink：取出Channel中的数据，进行相应的存储文件系统，数据库或是提交到远程服务器。
</code></pre> 
  <p>6.数据在组件传输的单位是Event。</p> 
  <h2><a id="3Flume_27"></a>3.Flume基本组件</h2> 
  <p><em><strong><font color="#000000" size="5">1.source</font></strong></em><br> 意为来源、源头。<br> 主要作用：从外界采集各种类型的数据，将数据传递给Channel。<br> 比如:监控某个文件只要增加数据就立即采集新增的数据、监控某个目录一旦有新文件产生就采集新文件的内容、监控某个端口等等。<br> 常见采集的数据类型：</p> 
  <pre><code> Exec Source、Avro Source、NetCat Source、Spooling Directory Source等
</code></pre> 
  <p>详细查看：<br> <a href="http://flume.apache.org/FlumeUserGuide.html#flume-sources" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#flume-sources</a><br> 或者自带的文档查看。</p> 
  <pre><code>各种Source具体作用：
1. AvroSource：监听一个avro服务端口，采集Avro数据序列化后的数据；
2. Thrift Source：监听一个Thrift 服务端口，采集Thrift数据序列化后的数据；
3. Exec Source：基于Unix的command在标准输出上采集数据；
   tail -F 和tail -f 区别。基于log4j切割文件时的能否读取问题。
4. JMS Source：Java消息服务数据源，Java消息服务是一个与具体平台无关的API，这是支持jms规范的数据源采集；
5. Spooling Directory Source：通过文件夹里的新增的文件作为数据源的采集；
6. Kafka Source：从kafka服务中采集数据。
7. NetCat Source： 绑定的端口（tcp、udp），将流经端口的每一个文本行数据作为Event输入
8. HTTP Source：监听HTTP POST和 GET产生的数据的采集
</code></pre> 
  <p><em><strong><font color="#000000" size="5">2.Channel</font></strong></em><br> 一个数据的存储池，中间通道。<br> 主要作用<br> &nbsp;&nbsp; &nbsp;&nbsp; 接受source传出的数据，向sink指定的目的地传输。Channel中的数据直到进入到下一个channel中或者进入终端才会被删除。当sink写入失败后，可以自动重写，不会造成数据丢失，因此很可靠。<br> &nbsp;&nbsp; &nbsp;&nbsp; channel的类型很多比如:内存中、jdbc数据源中、文件形式存储等。<br> <strong>常见采集的数据类型：</strong><br> <em><font color="#FF7F50" size="3">&nbsp;&nbsp; Memory Channel<br> &nbsp;&nbsp; File Channel<br> &nbsp;&nbsp; Spillable Memory Channel<br> &nbsp;&nbsp; kafka Channel等</font></em><br> 详细查看：<br> <a href="http://flume.apache.org/FlumeUserGuide.html#flume-channels" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#flume-channels</a></p> 
  <p><strong>Channel具体作用：</strong><br> <font color="#4169E1" size="3" face="宋体">&nbsp;&nbsp; 1. Memory Channel：使用内存作为数据的存储。速度快<br> &nbsp;&nbsp; 2. File Channel：使用文件来作为数据的存储。安全可靠<br> &nbsp;&nbsp; 3. Spillable Memory Channel：使用内存和文件作为数据的存储，<br> &nbsp;&nbsp; &nbsp;&nbsp; 即：先存在内存中，如果内存中数据达到阀值则flush到文件中。<br> &nbsp;&nbsp; 4. JDBC Channel：使用jdbc数据源来作为数据的存储。<br> &nbsp;&nbsp; 5. Kafka Channel：使用kafka服务来作为数据的存储。 </font></p> 
  <p><font color="#000000" size="5"><em><strong>3.Sink</strong></em></font><br> <font color="#000000" size="3" face="宋体">具体作用：<br> 数据的最终的目的地。<br> 主要作用：接受channel写入的数据以指定的形式表现出来（或存储或展示）。</font><br> <font color="#A52A2A" size="3">sink的表现形式很多比如:打印到控制台、hdfs上、avro服务中、文件中等。</font><br> 常见采集的数据类型：<br> &nbsp;&nbsp; &nbsp;&nbsp; HDFS Sink<br> &nbsp;&nbsp; &nbsp;&nbsp; Hive Sink<br> &nbsp;&nbsp; &nbsp;&nbsp; Logger Sink<br> &nbsp;&nbsp; &nbsp;&nbsp; Avro Sink<br> &nbsp;&nbsp; &nbsp;&nbsp; Thrift Sink<br> &nbsp;&nbsp; &nbsp;&nbsp; File Roll Sink<br> &nbsp;&nbsp; &nbsp;&nbsp; HBaseSink<br> &nbsp;&nbsp; &nbsp;&nbsp; Kafka Sink等<br> 详细查看：<br> &nbsp;&nbsp; &nbsp;&nbsp; <a href="http://flume.apache.org/FlumeUserGuide.html#flume-sinks" rel="nofollow">http://flume.apache.org/FlumeUserGuide.html#flume-sinks</a><br> 具体的sink如下：<br> &nbsp;&nbsp; &nbsp;&nbsp;Logger Sink：将数据作为日志处理（根据flume中的设置的日志的级别显示）。<br> &nbsp;&nbsp; &nbsp;&nbsp;HDFS Sink：将数据传输到hdfs集群中。<br> &nbsp;&nbsp; &nbsp;&nbsp;Avro Sink：数据被转换成Avro Event，然后发送到指定的服务端口上。<br> &nbsp;&nbsp; &nbsp;&nbsp;Thrift Sink：数据被转换成Thrift Event，然后发送到指定的的服务端口上。<br> &nbsp;&nbsp; &nbsp;&nbsp;File Roll Sink：数据传输到本地文件中。<br> &nbsp;&nbsp; &nbsp;&nbsp;Hive Sink：将数据传输到hive的表中。<br> &nbsp;&nbsp; &nbsp;&nbsp;IRC Sink：数据向指定的IRC服务和端口中发送。<br> &nbsp;&nbsp; &nbsp;&nbsp;Null Sink：取消数据的传输，即不发送到任何目的地。<br> &nbsp;&nbsp; &nbsp;&nbsp;HBaseSink：将数据发往hbase数据库中。<br> &nbsp;&nbsp; &nbsp;&nbsp;MorphlineSolrSink：数据发送到Solr搜索服务器（集群）。<br> &nbsp;&nbsp; &nbsp;&nbsp;ElasticSearchSink：数据发送到Elastic Search搜索服务器（集群）。<br> &nbsp;&nbsp; &nbsp;&nbsp;Kafka Sink：将数据发送到kafka服务中。（注意依赖类库）<br> <font color="#000000" size="2">注意：HDFSSink需要有hdfs的配置文件和类库。一般采取多个sink汇聚到一台采集机器负责推送到hdfs。</font></p> 
  <p><font color="#000000" size="5"><em><strong>4.Event</strong></em></font><br> <font color="#000000" size="3" face="宋体">具体作用：<br> &nbsp;&nbsp;Flume NG传输的数据的基本单位，也是事务的基本单位。</font><br> <font color="#4169E1" size="3" face="宋体">&nbsp;&nbsp; &nbsp;&nbsp;在文本文件，通常是一行记录就是一个event。<br> &nbsp;&nbsp; &nbsp;&nbsp;网络消息传输系统中，一条消息就是一个event。</font><br> &nbsp;&nbsp; &nbsp;&nbsp;event里有header、body<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;Event里面的header类型：Map&lt;String, String&gt;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;我们可以在source中自定义header的key：value，在某些channel和sink中使用header。</p> 
  <p>练习1：<br> 一个需求：怎么实时监听一个文件的数据增加呢？打印到控制台上。<br> 如果这个文件增加的量特别大呢？</p> 
  <p><font color="#000000" size="5"><em><strong>5.Avro client</strong></em></font><br> avro客户端：<br> &nbsp;&nbsp;&nbsp;&nbsp; 往指定接收方相应的主机名:端口 发送本机要监听发送的源文件或者文件夹。</p> 
  <pre><code>bin/flume-ng avro-client --conf conf/ -H master -p 41414 -F /opt/logs/access.log
</code></pre> 
  <p>需要提供 avro-source<br> &nbsp;&nbsp;&nbsp;&nbsp; 注意：–headerFile选项：追加header信息，文件以空格隔开。</p> 
  <pre><code>bin/flume-ng avro-client  --conf conf/ --host slave01 --port 41414  --filename /opt/logs/access.log --headerFile /opt/logs/kv.log 
</code></pre> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp; 如果指定了–dirname。则传输后此文件夹里的文件会加上fileSuffix后缀。<br> 练习02：<br> 监控文件的新增内容向另一台机器的source发送数据。怎么处理？<br> <font color="#000000" size="5"><em><strong>6.Flume安装</strong></em></font></p> 
  <pre><code>系统要求：
    1、JRE：JDK1.6+(推荐使用1.7)
    2、内存：没有上限和下限，能够配置满足source、channel以及sink即可
    3、磁盘空间：同2
    4、目录权限：一般的agent操作的目录必须要有读写权限
    这里采用的Flume版本为1.9.0，也是目前最新的版本，下载地址为：
    http://archive.apache.org/dist/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz
 
安装步骤：
    解压缩：$ tar -zxvf soft/apache-flume-1.9.0-bin.tar.gz -C app/
    重命名：$ mv app/apache-flume-1.9.0-bin/ /xxxx/flume
    添加到环境变量中
        vim ~/.bash_profile
        export FLUME_HOME=/home/xxxx/app/flume
        export PATH=$PATH:$FLUME_HOME/bin
    修改配置文件
        conf]# cp flume-env.sh.template flume-env.sh
    flume-env.sh中添加你的JAVA_HOME
        export JAVA_HOME=/xxxx/jdk
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512112318188.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3podDI0NTY0ODEyNA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <font color="#000000" size="5"><em><strong>6.Flume Agent案例</strong></em></font><br> <strong>1.侦听网络端口数据</strong><br> 在conf目录下复制文件：</p> 
  <pre><code> cp flume-conf.properties.template flume-nc.conf
</code></pre> 
  <p>编辑文件</p> 
  <pre><code>gedit  flume-nc.conf
</code></pre> 
  <p>添加内容【注意：使用时，请把每行后注释去掉】</p> 
  <pre><code class="prism language-java">#定义了当前agent的名字叫做a1<span class="token punctuation">,</span>
#该agent中的sources组件叫做r1<span class="token punctuation">,</span>
#该agent中的sinks组件叫做k1<span class="token punctuation">,</span>该agent中的channels组件叫做c1
a1<span class="token punctuation">.</span>sources <span class="token operator">=</span> r1
a1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
a1<span class="token punctuation">.</span>sinks <span class="token operator">=</span> k1

# 监听数据源的方式，这里采用监听网络端口
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>type <span class="token operator">=</span> netcat      #source的类型为网络字节流
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>bind <span class="token operator">=</span> localhost   #source监听的网络的hostname
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>port <span class="token operator">=</span> <span class="token number">8888</span>        #source监听的网络的port

# 采集的数据的下沉<span class="token punctuation">(</span>落地<span class="token punctuation">)</span>方式 通过日志
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>type <span class="token operator">=</span> logger    #sink的类型为logger日志方式，log4j的级别有INFO、Console、file。。。

# 描述channel的部分，使用内存做数据的临时存储
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>type <span class="token operator">=</span> memory
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>capacity <span class="token operator">=</span> <span class="token number">1000</span>              #定义了channel对的容量
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>    #定义channel的最大的事务容量

# 使用channel将source和sink连接起来
# 需要将source和sink使用channel连接起来，组成一个类似流水管道
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>channel <span class="token operator">=</span> c1

</code></pre> 
  <p>进入bin目录，启动flume agent：</p> 
  <pre><code>./flume-ng agent -c conf -n a1 -f ../conf/flume-nc.conf -Dflume.root.logger=INFO,console
 
-c conf：使用配置文件的方式
-n a1：指定agent的名称为a1
-f：指定配置文件
 
因为数据落地是通过日志，所以后面需要指定日志的相关配置选项。

</code></pre> 
  <p>通过telnet或者nc向端口发送数据</p> 
  <pre><code># 使用nc
$ nc localhost 8888
hello
OK
nihao
OK
</code></pre> 
  <p>此时可以查看flume agent启动终端的输出：</p> 
  <pre><code class="prism language-java"><span class="token number">2018</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">24</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">09</span><span class="token operator">:</span><span class="token number">34</span><span class="token punctuation">,</span><span class="token number">390</span> <span class="token punctuation">(</span>lifecycleSupervisor<span class="token operator">-</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO <span class="token operator">-</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>source<span class="token punctuation">.</span>NetcatSource<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span>NetcatSource<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">166</span><span class="token punctuation">)</span><span class="token punctuation">]</span> Created serverSocket<span class="token operator">:</span>sun<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>ch<span class="token punctuation">.</span>ServerSocketChannelImpl<span class="token punctuation">[</span><span class="token operator">/</span><span class="token number">192.168</span><span class="token number">.43</span><span class="token number">.101</span><span class="token operator">:</span><span class="token number">52019</span><span class="token punctuation">]</span>
<span class="token number">2018</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">24</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">10</span><span class="token operator">:</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">022</span> <span class="token punctuation">(</span>SinkRunner<span class="token operator">-</span>PollingRunner<span class="token operator">-</span>DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO <span class="token operator">-</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>LoggerSink<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span>LoggerSink<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">]</span> Event<span class="token operator">:</span> <span class="token punctuation">{</span> headers<span class="token operator">:</span><span class="token punctuation">{</span><span class="token punctuation">}</span> body<span class="token operator">:</span> <span class="token number">77</span> <span class="token number">6F</span> <span class="token number">20</span> <span class="token number">61</span> <span class="token number">69</span> <span class="token number">20</span> <span class="token number">6</span>E <span class="token number">69</span> <span class="token number">0D</span>                      wo ai ni<span class="token punctuation">.</span> <span class="token punctuation">}</span>
<span class="token number">2018</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">24</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">10</span><span class="token operator">:</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">139</span> <span class="token punctuation">(</span>SinkRunner<span class="token operator">-</span>PollingRunner<span class="token operator">-</span>DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO <span class="token operator">-</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>LoggerSink<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span>LoggerSink<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">]</span> Event<span class="token operator">:</span> <span class="token punctuation">{</span> headers<span class="token operator">:</span><span class="token punctuation">{</span><span class="token punctuation">}</span> body<span class="token operator">:</span> <span class="token number">73</span> <span class="token number">61</span> <span class="token number">69</span> <span class="token number">20</span> <span class="token number">62</span> <span class="token number">65</span> <span class="token number">69</span> <span class="token number">20</span> <span class="token number">64</span> <span class="token number">65</span> <span class="token number">20</span> <span class="token number">78</span> <span class="token number">75</span> <span class="token number">65</span> <span class="token number">0D</span>    sai bei de xue<span class="token punctuation">.</span> <span class="token punctuation">}</span>
<span class="token number">2018</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">24</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">13</span><span class="token operator">:</span><span class="token number">26</span><span class="token punctuation">,</span><span class="token number">190</span> <span class="token punctuation">(</span>SinkRunner<span class="token operator">-</span>PollingRunner<span class="token operator">-</span>DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO <span class="token operator">-</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>LoggerSink<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span>LoggerSink<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">]</span> Event<span class="token operator">:</span> <span class="token punctuation">{</span> headers<span class="token operator">:</span><span class="token punctuation">{</span><span class="token punctuation">}</span> body<span class="token operator">:</span> <span class="token number">68</span> <span class="token number">65</span> <span class="token number">69</span> <span class="token number">68</span> <span class="token number">65</span> <span class="token number">69</span>                               nihao <span class="token punctuation">}</span>
<span class="token number">2018</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">24</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">13</span><span class="token operator">:</span><span class="token number">26</span><span class="token punctuation">,</span><span class="token number">463</span> <span class="token punctuation">(</span>SinkRunner<span class="token operator">-</span>PollingRunner<span class="token operator">-</span>DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO <span class="token operator">-</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>LoggerSink<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span>LoggerSink<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">]</span> Event<span class="token operator">:</span> <span class="token punctuation">{</span> headers<span class="token operator">:</span><span class="token punctuation">{</span><span class="token punctuation">}</span> body<span class="token operator">:</span> <span class="token number">78</span> <span class="token number">70</span> <span class="token number">6</span>C <span class="token number">65</span> <span class="token number">61</span> <span class="token number">66</span>                               nihao <span class="token punctuation">}</span>
<span class="token number">2018</span><span class="token operator">-</span><span class="token number">03</span><span class="token operator">-</span><span class="token number">24</span> <span class="token number">20</span><span class="token operator">:</span><span class="token number">17</span><span class="token operator">:</span><span class="token number">01</span><span class="token punctuation">,</span><span class="token number">694</span> <span class="token punctuation">(</span>SinkRunner<span class="token operator">-</span>PollingRunner<span class="token operator">-</span>DefaultSinkProcessor<span class="token punctuation">)</span> <span class="token punctuation">[</span>INFO <span class="token operator">-</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>LoggerSink<span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span>LoggerSink<span class="token punctuation">.</span>java<span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">]</span> Event<span class="token operator">:</span> <span class="token punctuation">{</span> headers<span class="token operator">:</span><span class="token punctuation">{</span><span class="token punctuation">}</span> body<span class="token operator">:</span> <span class="token number">68</span> <span class="token number">65</span> <span class="token number">6</span>C <span class="token number">6</span>C <span class="token number">6F</span>                                  hello <span class="token punctuation">}</span>

</code></pre> 
  <p><strong>2.侦听目录中的新增文件</strong></p> 
  <pre><code class="prism language-java">#####################################################################
## 监听目录中的新增文件
## <span class="token keyword">this</span> agent is consists of source which is r1 <span class="token punctuation">,</span> sinks which is k1<span class="token punctuation">,</span>
## channel which is c1
## 
## 这里面的a1 是flume一个实例agent的名字
#####################################################################

a1<span class="token punctuation">.</span>sources <span class="token operator">=</span> r1
a1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
a1<span class="token punctuation">.</span>sinks <span class="token operator">=</span> k1

# 监听数据源的方式，这里采用监听目录中的新增文件

a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>type <span class="token operator">=</span> spooldir
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>spoolDir <span class="token operator">=</span> <span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>testFile<span class="token operator">/</span>flume
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>fileSuffix <span class="token operator">=</span> <span class="token punctuation">.</span>ok
# a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>deletePolicy <span class="token operator">=</span> immediate
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>deletePolicy <span class="token operator">=</span> never
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>fileHeader <span class="token operator">=</span> <span class="token boolean">true</span>

# 采集的数据的下沉<span class="token punctuation">(</span>落地<span class="token punctuation">)</span>方式 通过日志
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>type <span class="token operator">=</span> logger

# 描述channel的部分，使用内存做数据的临时存储
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>type <span class="token operator">=</span> memory
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>capacity <span class="token operator">=</span> <span class="token number">1000</span>
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>

# 使用channel将source和sink连接起来
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>channel <span class="token operator">=</span> c1

</code></pre> 
  <p>启动flume agent：</p> 
  <pre><code>./flume-ng agent -c conf -n a1 -f ../conf/flume-spool.conf -Dflume.root.logger=INFO,console
</code></pre> 
  <p>在配置文件的本地目录中增加文件，输入</p> 
  <pre><code>hello you
hello he
hello me
</code></pre> 
  <p>可以看到flume agent终端输出：</p> 
  <pre><code>2018-03-24 21:23:59,182 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{file=/home/uplooking/data/flume/hello.txt} body: 68 65 6C 6C 6F 20 79 6F 75                      hello you }
2018-03-24 21:23:59,182 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{file=/home/uplooking/data/flume/hello.txt} body: 68 65 6C 6C 6F 20 68 65                         hello he }
2018-03-24 21:23:59,182 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{file=/home/uplooking/data/flume/hello.txt} body: 68 65 6C 6C 6F 20 6D 65                         hello me }
2018-03-24 21:23:59,184 (pool-3-thread-1) [INFO - org.apache.flume.client.avro.ReliableSpoolingFileEventReader.readEvents(ReliableSpoolingFileEventReader.java:324)] Last read took us just up to a file boundary. Rolling to the next file, if there is one.
2018-03-24 21:23:59,184 (pool-3-thread-1) [INFO - org.apache.flume.client.avro.ReliableSpoolingFileEventReader.rollCurrentFile(ReliableSpoolingFileEventReader.java:433)] Preparing to move file /home/uplooking/data/flume/hello.txt to /home/uplooking/data/flume/hello.txt.ok

</code></pre> 
  <p>可以看到提示说，原来的文本文件已经被重命名为.ok，查看数据目录中的文件：</p> 
  <pre><code>$ ls
hello.txt.ok

</code></pre> 
  <p><strong>3.侦听目录中的新增文件</strong></p> 
  <pre><code>tail -f与tail -F的说明：
在生产环境中，为了防止日志文件过大，通常会每天生成一个新的日志文件，
这是通过重命名原来的日志文件，然后touch一个原来的日志文件的方式来实现的。
    http-xxx.log
    http-xxx.log.2017-03-15
    http-xxx.log.2017-03-16
    -f不会监听分割之后的文件，而-F则会继续监听。

</code></pre> 
  <pre><code>a1.sources = r1
a1.channels = c1
a1.sinks = k1

# 监听数据源的方式，这里监听文件中的新增数据
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /usr/local/testFile/flume/http-flume.log

a1.sinks.k1.type = logger

a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 100
a1.channels.c1.transactionCapacity = 100
</code></pre> 
  <p>启动flume agent：</p> 
  <pre><code>./flume-ng agent -c conf -n a1 -f ../conf/flume-data.conf -Dflume.root.logger=INFO,console
</code></pre> 
  <p>向监听文件中添加数据：</p> 
  <pre><code>cat hello.txt.ok &gt; http-flume.log 
</code></pre> 
  <p>查看flume agent终端的输出：</p> 
  <pre><code>2018-03-25 01:28:39,359 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 68 65 6C 6C 6F 20 79 6F 75                      hello you }
2018-03-25 01:28:40,465 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 68 65 6C 6C 6F 20 68 65                         hello he }
2018-03-25 01:28:40,465 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 68 65 6C 6C 6F 20 6D 65                         hello me }

</code></pre> 
  <p>数据过大导致的内存溢出问题与解决方案</p> 
  <pre><code>通过调整
# 描述channel的部分，使用内存做数据的临时存储
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000000
a1.channels.c1.transactionCapacity = 1000000
执行案例监听日志文件中的新增记录，操作一下异常
java.lang.OutOfMemoryError: GC overhead limit exceeded，简称OOM/OOME
两种方案解决：
    第一种方案：给该flume程序加大内存存储容量
        默认值为-Xmx20m(最大堆内存大小)，---&gt;-Xmx 2000m
        -Xms10m(初始堆内存大小)
        flume-ng agent -Xms1000m -Xmx1000m -c conf -n a1 -f conf/flume-data.conf -Dflume.root.logger=INFO,console
    第二种方案：第一种搞不定的时候，比如机器可用内存不够的话的，使用其它channel解决
        比如磁盘文件，比如jdbc

</code></pre> 
  <p>如果文本数据不是特别大，那么用第一种方案也是可以解决的，但是一旦文本数据过大，第一种方案需要分配很大的内存空间，所以下面演示使用第二种方案。</p> 
  <p>配置文件如下：</p> 
  <pre><code>#####################################################################
## 监听文件中的新增数据
## 使用文件做为channel
## 
## this agent is consists of source which is r1 , sinks which is k1,
## channel which is c1
## 
## 这里面的a1 是flume一个实例agent的名字
#####################################################################
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# 监听数据源的方式，这里监听文件中的新增数据
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/uplooking/data/flume/http-flume.log
# 采集的数据的下沉(落地)方式 通过日志
a1.sinks.k1.type = logger
# 描述channel的部分，使用内存做数据的临时存储
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /home/uplooking/data/flume/checkpoint
a1.channels.c1.transactionCapacity = 1000000
a1.channels.c1.dataDirs = /home/uplooking/data/flume/data
# 使用channel将source和sink连接起来
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

</code></pre> 
  <p>注意需要创建下面两个目录：</p> 
  <pre><code>/home/uplooking/data/flume/checkpoint # 存放检查点数据
/home/uplooking/data/flume/data       # 存放channel的数据

</code></pre> 
  <p>这样再向监听文件中打数据，会在终端中看到不停地刷数据。</p> 
  <p><strong>注：flume集成hdfs、hbase、kafka，请查看文章：</strong><br> <a href="https://blog.csdn.net/zht245648124/article/details/90140470" rel="nofollow">https://blog.csdn.net/zht245648124/article/details/90140470</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
