<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DatawhaleChina -任务一 IMDB数据集+THUCNews数据集 « NotBeCN</title>
  <meta name="description" content="                   预备任务   tensorflow 早已安装好，都有跑模型，莫烦先生的视频也都看了，基础知识有了解，都很OK。   IMDB数据集下载和探索   整体思路：       特征 特征就是 one-hot 形式，选取10000个频率在前的单词，然后对每一个文档处理成这10000维...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/randompeople_90130119.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">DatawhaleChina -任务一 IMDB数据集+THUCNews数据集</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h3><a id="_0"></a>预备任务</h3> 
  <p>tensorflow 早已安装好，都有跑模型，莫烦先生的视频也都看了，基础知识有了解，都很OK。</p> 
  <h3><a id="IMDB_3"></a>IMDB数据集下载和探索</h3> 
  <p>整体思路：</p> 
  <ul> 
   <li>特征<br> 特征就是 one-hot 形式，选取10000个频率在前的单词，然后对每一个文档处理成这10000维度的向量。<br> 文档里包含这个单词，向量中这个单词的索引位置就是1，否则就是0，总的样本空间就是 10000 * docNum。</li> 
   <li>网络</li> 
  </ul> 
  <p>代码部分：</p> 
  <pre><code>import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.datasets import imdb
import numpy as np
import matplotlib.pyplot as plt


### 将数据处理，利用one - hot 模型，把数据转换成数字

(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=10000)


def vectorize_sequences(sequences, dimension=10000):
   
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.  # 索引results矩阵中的位置，赋值为1，全部都是从第0行0列开始的
    return results

# Our vectorized training data
x_train = vectorize_sequences(train_data)
# Our vectorized test data
x_test = vectorize_sequences(test_data)

y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')
print(x_train.shape())

# 拆分数据
x_val = x_train[:10000]
partial_x_train = x_train[10000:]

y_val = y_train[:10000]
partial_y_train = y_train[10000:]

model = keras.Sequential()
# model = keras.models.Sequential()

model.add(keras.layers.Dense(16, activation='relu', input_shape=(10000,))) 
model.add(keras.layers.Dense(16, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid')) # 一个输出层

## 定义误差
model.compile(optimizer=optimizers.RMSprop(lr=0.001),
              loss=keras.losses.binary_crossentropy,
              metrics=[keras.metrics.binary_accuracy])

# 开始训练
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_val, y_val))


# 获取训练过程中的一些数据指标
history_dict = history.history
history_dict.keys()

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

## 误差绘图

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')  # bo表示蓝色圆点，训练的误差
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')  # b表示蓝色实线，实际误差
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()  #如果不加这一句就不会显示图例

plt.show()

##  准确率绘图

plt.clf()   # clear figure
acc_values = history_dict['acc']
val_acc_values = history_dict['val_acc']

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# 将概率装换成 具体的分类结果，分类结果为1，或者 0 
results = model.evaluate(x_test, y_test)
y_pre = model.predict(x_test)

result = []
for i in y_pre:
    if i &gt; 0.5:
        result.append[1]  # 概率大于 0.5 就是 分类1
    else :
        result.append(0)  # 否则概率就是 0 

</code></pre> 
  <p>最后需要选择损失函数和优化器，由于面对的是一个二分类问题，网络输出是一个概率值，那么最好使用binary_crossentropy（二元交叉熵）。对于输出概率值的模型，交叉熵（crossentropy）往往是最好的选择</p> 
  <p>主要是分析数据，对数据进行代码了解，可以自己使用其他模型来尝试。</p> 
  <h3><a id="THUCNews_125"></a>THUCNews</h3> 
  <p>这是一个中文多分类数据集，数据集还是蛮大的，75万篇新闻，2.19G左右，分类结果主要分为：<code>体育,娱乐,家居,彩票,房产,教育,时尚,时政,星座,游戏,社会,科技,股票,财经</code>。数据集比较大，这里就不展示元数据信息了，大家可以查看官方网站：<a href="http://thuctc.thunlp.org/#%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86THUCNews" rel="nofollow">THUCTC: 一个高效的中文文本分类工具包<br> </a></p> 
  <p>网上有很多关于该数据集的CNN代码，大部分人的思路都是统计高频词汇，10000个高频词汇，然后把文章装换为词频向量，作为神经网络的输入。也有思路是利用TF-IDF来提取关键词，取关键词的前10000个用来文档向量化，当然也可以通过其他特征来做模型。这个数据集太大了，普通机器跑很容易系统崩溃，所以最好是有GPU的机器来做这件事。</p> 
  <h3><a id="_134"></a>参考资料</h3> 
  <p><a href="https://blog.csdn.net/Einstellung/article/details/82683652" rel="nofollow">电影评论分类：二分类问题（IMDB数据集）</a><br> <a href="https://github.com/gaussic/text-classification-cnn-rnn" rel="nofollow">Text Classification with CNN and RNN</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
