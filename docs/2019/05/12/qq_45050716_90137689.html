<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>深度学习 Keras入门 一 之基础篇 « NotBeCN</title>
  <meta name="description" content="                     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;       ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/qq_45050716_90137689.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">深度学习 Keras入门 一 之基础篇</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <div class="markdown_views prism-tomorrow-night" id="content_views">
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   <!-- flowchart &#31661;&#22836;&#22270;&#26631; &#21247;&#21024; -->&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   <div class="htmledit_views" id="content_views">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    <div class="clear"></div>
    <div class="postBody">
     <div id="cnblogs_post_body">
      <p><span><span>1.关于Keras</span></span></p>
      <p>1）简介 </p>
      <p>Keras是由纯python编写的基于theano/tensorflow的深度学习框架。</p>
      <p>Keras是一个高层神经网络API，支持快速实验，能够把你的idea迅速转换为结果，如果有如下需求，可以优先选择Keras：</p>
      <p> a）简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）</p>
      <p>b）支持CNN和RNN，或二者的结合</p>
      <p><span id="__mceDel"></span>c）无缝CPU和GPU切换</p>
      <p>2）设计原则</p>
      <p>a）用户友好：Keras是为人类而不是天顶星人设计的API。用户的使用体验始终是我们考虑的首要和中心内容。Keras遵循减少认知困难的最佳实践：Keras提供一致而简洁的API， 能够极大减少一般应用下用户的工作量，同时，Keras提供清晰和具有实践意义的bug反馈。</p>
      <p>b）模块性：模型可理解为一个层的序列或数据的运算图，完全可配置的模块可以用最少的代价自由组合在一起。具体而言，网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，你可以使用它们来构建自己的模型。</p>
      <p> c）易扩展性：添加新模块超级容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。</p>
      <p>d）与Python协作：Keras没有单独的模型配置文件类型（作为对比，caffe有），模型由python代码描述，使其更紧凑和更易debug，并提供了扩展的便利性。</p>
     </div>
    </div>
   </div>
   <p>如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击<a href="http://www.captainbed.net/csdn" rel="nofollow" target="_blank">这里</a>可以查看教程。</p>
   <p><span><span>2.Keras的模块结构</span></span></p>
   <p>&nbsp; &nbsp;<img alt="" src="http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707133635659-888158147.png"></p>
   <p>&nbsp;</p>
   <p>3.<span><span>使用Keras搭建一个神经网络</span></span></p>
   <p><img alt="" src="http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707133932722-715494711.png"></p>
   <p>&nbsp;</p>
   <p><span><span>4.主要概念</span></span></p>
   <p>&nbsp; &nbsp;1）符号计算</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。符号计算首先定义各种变量，然后建立一个“计算图”,计算图规定了各个变量之间的计算关系。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp;符号计算也叫数据流图，其过程如下(gif图不好打开，所以用了静态图，数据是按图中黑色带箭头的线流动的)：</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<img alt="" src="http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707135253581-1586562235.png"></p>
   <p>&nbsp; &nbsp; &nbsp;2）张量</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 张量(tensor)，可以看作是向量、矩阵的自然推广，用来表示广泛的数据类型。张量的阶数也叫维度。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0阶张量,即标量,是一个数。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1阶张量,即向量,一组有序排列的数</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2阶张量,即矩阵,一组向量有序的排列起来</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3阶张量，即立方体，一组矩阵上下排列起来</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4阶张量......<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 依次类推</p>
   <p>&nbsp;&nbsp;<span>&nbsp; &nbsp; &nbsp; &nbsp; 重点：关于维度的理解</span></p>
   <p><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 假如有一个10长度的列表，那么我们横向看有10个数字，也可以叫做10维度，纵向看只能看到1个数字，那么就叫1维度。注意这个区别有助于理解Keras或者神经网络中计算时出现的维度问题。</span></p>
   <p>&nbsp; &nbsp; 3）数据格式(data_format)</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; 目前主要有两种方式来表示张量：<br>&nbsp; &nbsp; &nbsp; &nbsp; a) th模式或channels_first模式，Theano和caffe使用此模式。<br>&nbsp; &nbsp; &nbsp; &nbsp; b）tf模式或channels_last模式，TensorFlow使用此模式。</p>
   <p>&nbsp;<br>&nbsp; &nbsp; &nbsp; &nbsp; 下面举例说明两种模式的区别：<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;对于100张RGB3通道的16×32（高为16宽为32）彩色图，<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;th表示方式：（100,3,16,32）<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;tf表示方式：（100,16,32,3）<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;唯一的区别就是表示通道个数3的位置不一样。</p>
   <p>&nbsp; &nbsp; &nbsp;4）模型</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）序贯模型（Sequential):单输入单输出，一条路通到底，层与层之间只有相邻关系，没有跨层连接。这种模型编译速度快，操作也比较简单<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）函数式模型（Model）：多输入多输出，层与层之间任意连接。这种模型编译速度慢。</p>
   <p>&nbsp;</p>
   <p><span><span>5.第一个示例</span></span></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 这里也采用介绍神经网络时常用的一个例子：手写数字的识别。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 在写代码之前，基于这个例子介绍一些概念，方便大家理解。</p>
   <p>&nbsp; &nbsp;<span>&nbsp;&nbsp; &nbsp; &nbsp; PS：可能是版本差异的问题，官网中的参数和示例中的参数是不一样的，官网中给出的参数少，并且有些参数支持，有些不支持。所以此例子去掉了不支持的参数，并且只介绍本例中用到的参数。</span></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1）Dense(500,input_shape=(784,))</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a）Dense层属于网络层--&gt;常用层中的一个层</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;b） 500表示输出的维度，完整的输出表示：(*,500)：即输出任意个500维的数据流。但是在参数中只写维度就可以了，比较具体输出多少个是有输入确定的。换个说法，Dense的输出其实是个N×500的矩阵。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c）input_shape(784,) 表示输入维度是784(28×28，后面具体介绍为什么)，完整的输入表示：(*,784)：即输入N个784维度的数据</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2）Activation('tanh')</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）Activation：激活层</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）'tanh' ：激活函数</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3）Dropout(0.5)</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;在训练过程中每次更新参数时随机断开一定百分比（rate）的输入神经元，防止过拟合。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4）数据集</p>
   <p>&nbsp;&nbsp;<span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;数据集包括60000张28×28的训练集和10000张28×28的测试集及其对应的目标数字。如果完全按照上述数据格式表述，以tensorflow作为后端应该是（60000,28,28,3），因为示例中采用了mnist.load_data()获取数据集，所以已经判断使用了tensorflow作为后端，因此数据集就变成了(60000,28,28),那么input_shape(784,)应该是input_shape(28,28，)才对，但是在这个示例中这么写是不对的，需要转换成(60000,784),才可以。为什么需要转换呢？</span></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<img alt="" src="http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707145150519-637435869.png"></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 如上图，训练集(60000,28,28)作为输入，就相当于一个立方体，而输入层从当前角度看就是一个平面，立方体的数据流怎么进入平面的输入层进行计算呢？所以需要进行黄色箭头所示的变换，然后才进入输入层进行后续计算。至于从28*28变换成784之后输入层如何处理，就不需要我们关心了。(喜欢钻研的同学可以去研究下源代码)。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;并且，Keras中输入多为(nb_samples, input_dim)的形式：即(样本数量，输入维度)。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; 5）示例代码</p>
   <div class="cnblogs_code">
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><a title="复制代码" target="_blank"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></a></span>
    </div>
    <pre class="prettyprint"><span>from</span> keras.models <span>import</span><span> Sequential&nbsp; </span><span>from</span> keras.layers.core <span>import</span><span> Dense, Dropout, Activation&nbsp; </span><span>from</span> keras.optimizers <span>import</span><span> SGD&nbsp; </span><span>from</span> keras.datasets <span>import</span><span> mnist&nbsp; </span><span>import</span><span> numpy </span><span>'''</span><span>&nbsp;&nbsp;&nbsp; 第一步：选择模型</span><span>'''</span><span>model </span>=<span> Sequential()</span><span>'''</span><span>&nbsp;&nbsp; 第二步：构建网络层</span><span>'''</span><span>model.add(Dense(</span>500,input_shape=(784,))) <span>#</span><span> 输入层，28*28=784&nbsp; </span>model.add(Activation(<span>'</span><span>tanh</span><span>'</span>)) <span>#</span><span> 激活函数是tanh&nbsp; </span>model.add(Dropout(0.5)) <span>#</span><span> 采用50%的dropout</span><span>model.add(Dense(</span>500)) <span>#</span><span> 隐藏层节点500个&nbsp; </span>model.add(Activation(<span>'</span><span>tanh</span><span>'</span><span>))&nbsp; model.add(Dropout(</span>0.5<span>))model.add(Dense(</span>10)) <span>#</span><span> 输出结果是10个类别，所以维度是10&nbsp; </span>model.add(Activation(<span>'</span><span>softmax</span><span>'</span>)) <span>#</span><span> 最后一层用softmax作为激活函数</span><span>'''</span><span>&nbsp;&nbsp; 第三步：编译</span><span>'''</span><span>sgd </span>= SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) <span>#</span><span> 优化函数，设定学习率（lr）等参数&nbsp; </span>model.compile(loss=<span>'</span><span>categorical_crossentropy</span><span>'</span>, optimizer=sgd, class_mode=<span>'</span><span>categorical</span><span>'</span>) <span>#</span><span> 使用交叉熵作为loss函数</span><span>'''</span><span>&nbsp;&nbsp; 第四步：训练&nbsp;&nbsp; .fit的一些参数&nbsp;&nbsp; batch_size：对总的样本数进行分组，每组包含的样本数量&nbsp;&nbsp; epochs ：训练次数&nbsp;&nbsp; shuffle：是否把数据随机打乱之后再进行训练&nbsp;&nbsp; validation_split：拿出百分之多少用来做交叉验证&nbsp;&nbsp; verbose：屏显模式 0：不输出&nbsp; 1：输出进度&nbsp; 2：输出每次的训练结果</span><span>'''</span><span>(X_train, y_train), (X_test, y_test) </span>= mnist.load_data() <span>#</span><span> 使用Keras自带的mnist工具读取数据（第一次需要联网）</span><span>#</span><span> 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维&nbsp; </span>X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2<span>]) X_test </span>= X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2<span>])&nbsp; Y_train </span>= (numpy.arange(10) ==<span> y_train[:, None]).astype(int) Y_test </span>= (numpy.arange(10) ==<span> y_test[:, None]).astype(int)model.fit(X_train,Y_train,batch_size</span>=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3<span>)model.evaluate(X_test, Y_test, batch_size</span>=200, verbose=<span>0)</span><span>'''</span><span>&nbsp;&nbsp;&nbsp; 第五步：输出</span><span>'''</span><span>print</span>(<span>"</span><span>test set</span><span>"</span><span>)scores </span>= model.evaluate(X_test,Y_test,batch_size=200,verbose=<span>0)</span><span>print</span>(<span>""</span><span>)</span><span>print</span>(<span>"</span><span>The test loss is %f</span><span>"</span> %<span> scores)result </span>= model.predict(X_test,batch_size=200,verbose=<span>0)result_max </span>= numpy.argmax(result, axis = 1<span>)test_max </span>= numpy.argmax(Y_test, axis = 1<span>)result_bool </span>=<span> numpy.equal(result_max, test_max)true_num </span>=<span> numpy.sum(result_bool)</span><span>print</span>(<span>""</span><span>)</span><span>print</span>(<span>"</span><span>The accuracy of the model is %f</span><span>"</span> % (true_num/len(result_bool)))</pre>
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><a title="复制代码" target="_blank"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></a></span>
    </div>
   </div>
   <p>&nbsp;</p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  </div> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
