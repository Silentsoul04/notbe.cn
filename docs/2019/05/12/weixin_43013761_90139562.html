<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>人工智能学习（22 机器学习：02-特征工程和文本特征提取） « NotBeCN</title>
  <meta name="description" content="                  03_数据集的组成   从历史中获得规律，这些数据大部分存储在文件（CSV）中，一般不存在数据库中，因为数据库有性能瓶颈。期读取数据数据率慢，并且数据的格式不太符合机器学习的要求。我们前面学习过pandas，其是基于numpy的，速率非常的快。在python中存在GPL锁，但是...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/weixin_43013761_90139562.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">人工智能学习（22 机器学习：02-特征工程和文本特征提取）</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="03__0"></a>03_数据集的组成</h2> 
  <p>从历史中获得规律，这些数据大部分存储在文件（CSV）中，一般不存在数据库中，因为数据库有性能瓶颈。期读取数据数据率慢，并且数据的格式不太符合机器学习的要求。我们前面学习过pandas，其是基于numpy的，速率非常的快。在python中存在GPL锁，但是numpy中已经把他释放了。<br> 所谓的数据集就是把数据收集起来，一般有以下分类：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512162850449.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAxMzc2MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">如果我们想获得以上的数据，可以通过以下3个网站去下载：<br> Kaggle网址：<a href="https://www.kaggle.com/datasets" rel="nofollow">https://www.kaggle.com/datasets</a><br> UCI数据集网址： <a href="http://archive.ics.uci.edu/ml/" rel="nofollow">http://archive.ics.uci.edu/ml/</a><br> scikit-learn网址：<a href="http://scikit-learn.org/stable/datasets/index.html#datasets" rel="nofollow">http://scikit-learn.org/stable/datasets/index.html#datasets</a><br> 后面学习的过程中，还是和之前以前，大部分使用Kaggle中的数据。</p> 
  <p>以上是我们获取数据集的介绍，那么我们获取的数据集一般由哪些部分构成呢？一般由特征值±目标值构成：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512163249552.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAxMzc2MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 之前我们使用pandas读取出来的是DataFrame格式的数据，其有行索引和列索引，如上的房子面积，房子位置，房子楼层等等，这些都是列索引，在这些列索引中，分为两个部分，为特征值和目标值，其上的目标值为房价，特城值为房子面积，房子位置，房子楼，房子朝向。我们可以根据这些信息去计算出一个房子的大致价格：<br> 1.首先的前提是有大量的数据<br> 2.这样就能找到特征值与目标值的关系<br> 3.然后建立一个模型，该模型就能根据一个房屋的特征值估算出其目标值（房屋价位）</p> 
  <p>当然，并不是每一个特征都是必须的，比如房子的价位跟跟房子地板的颜色等等，是没有太大的关系的。<br> 有的数据集是没有目标标的，那么没有，目标值我们拿过来干什么呢？在后续的过程中为大家讲解。</p> 
  <h2><a id="04__20"></a>04_特征工程的定义</h2> 
  <p>以后我们处理的数据，基本都是特征值与目标值。那么我们怎么去对数据中的特征值进行处理呢？如，前面楼房的例子中，假设我们收集的数据包含了房子地板颜色的特征，但是这个数据，我们没有用的，我们应该怎么办：</p> 
  <p>1.pandas：一个数据读取，基本格式处理非常方便的工具<br> pandas是我们常用基本数据的处理工具，在前面数据分析的章节已经详细的讲解，这里就不做深入介绍了。缺失值，数据筛选等等处理，都可以由pandas完成。在前面学习的过程中，我们经常会对重复值进行处理，但是在机器学习中，重复值是没有关系的，不需要进行处理。因为一样的数据，对机器学习是没有影响的（后续大家会深刻的体会到）。</p> 
  <p>在上面的例子中，我们发现，房子朝向，房子位置，其都是使用数值进行表示的，但是我们刚刚获取到的数据集，其肯定是使用字符串进行描述的，如：“朝东”，“朝南”等等。但是这样就出现了一个问题，在机器学习中，机器只能处理数值类型的数据，是没有办法对字符串进行学习的。<br> 如：我们告诉计算机朝南，但是计算机是没办法了解他的含义（如L没办法进行加减乘除等等）的，只有我们转为数值，其才能够理解，进而进行处理。<br> 再如:我们处理的数据是文本，我们要对文本进行分类处理，我们收集到的数据是文本，这些数据机器肯定是没有办法之间理解的。所以我们还需要一个工具，把我们通过pandas筛选出来的数据进行处理，把字符串数据转化为机器可以识别的数据，这样就有了sklearn。</p> 
  <p>2.sklearn：对特征的处理提供了强大的接口（其主要就是对特征进行处理）。<br> 当我们获取的数据，不满足机器学习的算法，我们可以通过sklearn提供的接口，把其数据转化为机器学习可以处理的数据，我们这对特征进行处理的这个过程称为特征工程。当然这个概念是比较广的，其也可以包括对数据集的筛选，删除（0当然，我们一般还是在pandas中进行处理）等等。</p> 
  <p>特征工程在整个机器学习当中，其是处于非常前面的一部分：</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512171523217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAxMzc2MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 特征工程的定义如下：特征工程是将原始数据转换为更好地代表预测模型的潜在问题的特征的过程，从而提高了对未知数据的模型准确性</p> 
  <p>如我们获得一篇英文文章，我们通过机器学习，对其进行分类：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512172031137.png" alt="在这里插入图片描述"><br> 我们把这篇文章先转化为以下数据：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512172100466.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAxMzc2MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 然后对这些数据使用机器学习的算法，就能对其进行分类了，</p> 
  <p>特征工程是十分重要的，其会直接影响我们的预测结果。下面我们对sklearn做一些简单的介绍。</p> 
  <pre><code class="prism language-txt">1.Python语言的机器学习工具
2.Scikit-learn包括许多知名的机器学习算法的实现
3.Scikit-learn文档完善，容易上手，丰富的API，使其在学术界颇受欢迎。
4.目前稳定版本0.18
</code></pre> 
  <p>当然，在学习过程中，我们弄明白他的原理是非常的重要的，在Scikit-learn中包含了很多机器学习的算法，在后续会为大家进行讲解，如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512172913681.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAxMzc2MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 在特征工程中，我们会学习以下几个要掉：</p> 
  <pre><code>1.特征抽取
2.特征预处理
3.数据的降维
</code></pre> 
  <h2><a id="05__60"></a>05_字典特征数据抽取</h2> 
  <p>我们先讲解一下第一点，即特征抽取。那么什么是特征抽取呢？其实在前面我们的例子中，把文本转化为数字的过程就是特城抽取。那么我们现在要讲解的字典特征数据抽取是什么呢？其就是把字典数据转化为可以供机器学习数据的过程。我们先做一个案例，编写代码如下：</p> 
  <pre><code class="prism language-py"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

<span class="token comment"># 实例化CountVectorizer</span>
vector <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 代用fit_transform输入数据并且进行转换</span>
res <span class="token operator">=</span> vector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"life is short,i like python"</span><span class="token punctuation">,</span><span class="token string">"life is too long,i dislike python"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 打印结果，先打印抽取特征的名字，在打印特征对应的数据(转化为array格式输出)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <p>打印结果如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span>  
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>可以看到，其把数据[“life is short,i like python”,“life is too long,i dislike python”]，转化成数值。这些数据就能被算法说使用了（当然还需要进行其他的处理，后续过程为大家讲解）。我们把上面的"life is short,i like python"与"life is too long,i dislike python"当做两篇文章，最后转化为了一个二维数组，二维数据组的每个元素都对应一篇文章。下面就是一个特城抽取的现象。</p> 
  <p>通过上面演示得出结论：特征抽取对文本等进行特征值化，其特征值化，就是转化为数值形式。其目的是为了计算机更好的去理解数据。下面我们来介绍一下特征抽取的API：</p> 
  <pre><code class="prism language-c"><span class="token comment">/*其中包含了所有特征抽取的API*/</span>
sklearn特征抽取API<span class="token punctuation">:</span>sklearn<span class="token punctuation">.</span>feature_extraction
</code></pre> 
  <p>字典特征值化的相关API：</p> 
  <pre><code class="prism language-c">作用：对字典数据进行特征值化
类：sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>DictVectorizer

DictVectorizer语法：
	<span class="token function">DictVectorizer</span><span class="token punctuation">(</span>sparse<span class="token operator">=</span>True<span class="token punctuation">,</span>…<span class="token punctuation">)</span>
	
		DictVectorizer<span class="token punctuation">.</span><span class="token function">fit_transform</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>       
		X<span class="token punctuation">:</span>字典或者包含字典的迭代器
		返回值：返回sparse矩阵
		
		DictVectorizer<span class="token punctuation">.</span><span class="token function">inverse_transform</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
		X<span class="token punctuation">:</span>array数组或者sparse矩阵
		返回值<span class="token punctuation">:</span>转换之前数据格式
		
		DictVectorizer<span class="token punctuation">.</span><span class="token function">get_feature_names</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
		返回类别名称
		
		DictVectorizer<span class="token punctuation">.</span><span class="token function">transform</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
		按照原先的标准转换
</code></pre> 
  <p>在后续我们会讲解fit_transform与transform的区别，现在我们只要注意到：fit_transform是关键，其会把数据特征值化。我们先做一些简单的例子，以下是编写流程，与相关数据：</p> 
  <pre><code class="prism language-c"><span class="token number">1.</span>实例化类DictVectorizer

<span class="token number">2.</span>调用fit_transform方法输入数据并转换（注意返回格式）

<span class="token number">3.</span>相关数据
<span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">}</span>，
<span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">}</span>，
<span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'深圳'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
</code></pre> 
  <p>我们编写代码如下：</p> 
  <pre><code class="prism language-py"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer

<span class="token keyword">def</span> <span class="token function">dictvec</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 字典数据特征抽取 :return:None """</span>
    <span class="token comment"># 1.实例化DictVectorizer</span>
    <span class="token builtin">dict</span> <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    res <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                              <span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                              <span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'深圳'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    dictvec<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p>运行结果如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'city=上海'</span><span class="token punctuation">,</span> <span class="token string">'city=北京'</span><span class="token punctuation">,</span> <span class="token string">'city=深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">]</span>
  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>	<span class="token number">1.0</span>
  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>	<span class="token number">100.0</span>
  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>	<span class="token number">1.0</span>
  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>	<span class="token number">60.0</span>
  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>	<span class="token number">1.0</span>
  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>	<span class="token number">30.0</span>
</code></pre> 
  <p>看到结果之后，初次发现观察，我们是很难理解的，那么我们使用以下两种方法进行修改：</p> 
  <pre><code class="prism language-py">方法<span class="token number">1</span>：把数据结果转化为array格式
<span class="token operator">-</span>	<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span>
<span class="token operator">+</span>	<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

方法二<span class="token number">2</span>：
<span class="token operator">-</span>	<span class="token builtin">dict</span> <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token operator">+</span>	<span class="token builtin">dict</span> <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
  <p>其两种修改方法，运行结果都如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'city=上海'</span><span class="token punctuation">,</span> <span class="token string">'city=北京'</span><span class="token punctuation">,</span> <span class="token string">'city=深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">1</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>  <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">1</span><span class="token punctuation">.</span>  <span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>现在和之前的数据进行对比我们就很容易明白之前的数据表示的是什么了，如： (0, 1) 1.0表示第0行1列数据为1.0，那么这些数据的0和1又代表什么呢？根据feature_names，我们可以知道第一列代表是否为上海，如果为上海，则为1，不为则为2。从上面例子我们知道fit_transform默返回的数据是sparse矩阵格式，其是为了更好的存储数据，减少存储空间</p> 
  <p>我们发现，其把每个类别（城市）都转化成了一个特征，那么如果类别非常的多，我们怎么办：我们会挑选一下有用的特征，可以人为，也可以通过后面学习的数据降维，或者删除一些没有必要的特征。</p> 
  <p>在字典特征抽取中，每个key与对应的values都会被当做一个特征抽取出来，则就是字典特征抽取。接下来我们讲解文本特征抽取</p> 
  <h2><a id="06__181"></a>06_文本特征抽取以及中文问题</h2> 
  <p>通过前面的讲解，我们有了大概的认识，那么就只做简单的介绍了：</p> 
  <pre><code class="prism language-c">作用：对文本数据进行特征值化
类：sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text<span class="token punctuation">.</span>CountVectorizer

CountVectorizer语法：
	<span class="token function">CountVectorizer</span><span class="token punctuation">(</span>max_df<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>min_df<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>…<span class="token punctuation">)</span>
	返回词频矩阵

		CountVectorizer<span class="token punctuation">.</span><span class="token function">fit_transform</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>       
		X<span class="token punctuation">:</span>文本或者包含文本字符串的可迭代对象
		返回值：返回sparse矩阵
		
		CountVectorizer<span class="token punctuation">.</span><span class="token function">inverse_transform</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
		X<span class="token punctuation">:</span>array数组或者sparse矩阵
		返回值<span class="token punctuation">:</span>转换之前数据格式
		
		CountVectorizer<span class="token punctuation">.</span><span class="token function">get_feature_names</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
		返回值<span class="token punctuation">:</span>单词列表
</code></pre> 
  <p>在这里我们要注意，该类在导入的时候还之前不一样，需要加一个text，为sklearn.feature_extraction.text.CountVectorizer。并且CountVectorizer()中是没有参数的，，所以我们想要得到array格式的数组。只能使用toarray()方法进行转换</p> 
  <p>下面是我们例子的数据：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">"life is short,i like python"</span><span class="token punctuation">,</span><span class="token string">"life is too long,i dislike python"</span><span class="token punctuation">]</span>
</code></pre> 
  <p>编写程序如下：</p> 
  <pre><code class="prism language-py"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">def</span> <span class="token function">countvec</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 对文本进行特征值化 :return: """</span>
    <span class="token comment"># 获得CountVectorizer实例化对象</span>
    count<span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 使用fit_transform进行文本特征抽取</span>
    data <span class="token operator">=</span> count<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"life is short,i like python"</span><span class="token punctuation">,</span><span class="token string">"life is too long,i dislike python"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 为了方便显示，把数据转化为array格式</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 显示特征值对应的索引以及数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span>  <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    countvec<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
  <p>打印信息如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'&lt;U7'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'&lt;U7'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>这里我们看到了inverse_transform的效果，其实质就是把数据进行了反转。文本使用CountVectorizer进行特征抽取，我们可以看到，会把所有文章中的所有词汇去重之后当做特征，然后统计么没篇文章这个词汇出现的个数。但是注意，这里是不包括单个词汇的。因为单个词汇的统计是没有意义的。</p> 
  <p>文本特征抽取的应用是十分广发的，特别是在对文本进行分类的方面，上面的例子，统计的是count，那么他到底有什么作用呢？如果我们需要去对文本进行分类，每种类型文章出现的一些特殊，或者具有代表性意义的词汇是不一样的（后续有详细讲解）</p> 
  <p>例子中使用的是英文文本，那么我们使用中文文本，其是否也能一样的处理呢？如我们现在对以下的文章进行文本特征值化</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">"人生苦短，我喜欢 python"</span><span class="token punctuation">,</span> <span class="token string">"人生漫长，不用python"</span><span class="token punctuation">]</span>
</code></pre> 
  <p>替换之前得文章数据，运行之后打印结果如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'不用python'</span><span class="token punctuation">,</span> <span class="token string">'人生漫长'</span><span class="token punctuation">,</span> <span class="token string">'人生苦短'</span><span class="token punctuation">,</span> <span class="token string">'我喜欢'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>我们可以发现，其统计的效果并不是我们想要的，但是如果替换成以下数据：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">"人生 苦短，我 喜欢 python"</span><span class="token punctuation">,</span> <span class="token string">"人生漫长，不用 python"</span><span class="token punctuation">]</span>
</code></pre> 
  <p>然后从执行程序，运行结果如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'不用'</span><span class="token punctuation">,</span> <span class="token string">'人生'</span><span class="token punctuation">,</span> <span class="token string">'人生漫长'</span><span class="token punctuation">,</span> <span class="token string">'喜欢'</span><span class="token punctuation">,</span> <span class="token string">'苦短'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>这样就达到了我们想要的结果，从这里我们可以知道，只要我们在调用文本特征抽取f中fit_transform函数的时候，传递进去的是已经通过空格隔开的，分词之后的数据，其就能帮助我们进行特征化处理了，所以我们先要对其进行分词，所以我们讲解一个jieba（结巴）的工具。其中使用很多强大的接口的。但是这里我们只使用其中的cut函数就可以了。</p> 
  <p>下面我们做一个案例，有数据如下：</p> 
  <pre><code>1、今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。

2、我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。

3、如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。
</code></pre> 
  <p>我们把其上看做3篇文章，现在要对其进行特征化处理，编写代码如下：</p> 
  <pre><code class="prism language-py"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">import</span> jieba

<span class="token keyword">def</span> <span class="token function">cutword</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 分词</span>
    con1 <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class="token punctuation">)</span>
    con2 <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class="token punctuation">)</span>
    con3 <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class="token punctuation">)</span>

    <span class="token comment"># 转化为列表</span>
    conten1 <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>con1<span class="token punctuation">)</span>
    conten2 <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>con2<span class="token punctuation">)</span>
    conten3 <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>con3<span class="token punctuation">)</span>

    <span class="token comment"># 把列表合成字符串，以空格隔开</span>
    c1 <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>conten1<span class="token punctuation">)</span>
    c2 <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>conten2<span class="token punctuation">)</span>
    c3 <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>conten3<span class="token punctuation">)</span>
    <span class="token keyword">return</span> c1<span class="token punctuation">,</span>c2<span class="token punctuation">,</span>c3

<span class="token keyword">def</span> <span class="token function">hanzivec</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 中文特征值化 :return: """</span>
    <span class="token comment"># 获取数据</span>
    c1<span class="token punctuation">,</span>c2<span class="token punctuation">,</span>c3 <span class="token operator">=</span> cutword<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 获得CountVectorizer实例化对象</span>
    count<span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 使用fit_transform进行文本特征抽取</span>
    data <span class="token operator">=</span> count<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span><span class="token punctuation">[</span>c1<span class="token punctuation">,</span>c2<span class="token punctuation">,</span>c3<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 为了方便显示，把数据转化为array格式</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 显示特征值对应的索引以及数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>count<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span>  <span class="token boolean">None</span>
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
	hanzivec<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p>运行结果如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">,</span> <span class="token string">'之前'</span><span class="token punctuation">,</span> <span class="token string">'了解'</span><span class="token punctuation">,</span> <span class="token string">'事物'</span><span class="token punctuation">,</span> <span class="token string">'今天'</span><span class="token punctuation">,</span> <span class="token string">'光是在'</span><span class="token punctuation">,</span> <span class="token string">'几百万年'</span><span class="token punctuation">,</span> <span class="token string">'发出'</span><span class="token punctuation">,</span> <span class="token string">'取决于'</span><span class="token punctuation">,</span> <span class="token string">'只用'</span><span class="token punctuation">,</span> <span class="token string">'后天'</span><span class="token punctuation">,</span> <span class="token string">'含义'</span><span class="token punctuation">,</span> <span class="token string">'大部分'</span><span class="token punctuation">,</span> <span class="token string">'如何'</span><span class="token punctuation">,</span> <span class="token string">'如果'</span><span class="token punctuation">,</span> <span class="token string">'宇宙'</span><span class="token punctuation">,</span> <span class="token string">'我们'</span><span class="token punctuation">,</span> <span class="token string">'所以'</span><span class="token punctuation">,</span> <span class="token string">'放弃'</span><span class="token punctuation">,</span> <span class="token string">'方式'</span><span class="token punctuation">,</span> <span class="token string">'明天'</span><span class="token punctuation">,</span> <span class="token string">'星系'</span><span class="token punctuation">,</span> <span class="token string">'晚上'</span><span class="token punctuation">,</span> <span class="token string">'某样'</span><span class="token punctuation">,</span> <span class="token string">'残酷'</span><span class="token punctuation">,</span> <span class="token string">'每个'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'秘密'</span><span class="token punctuation">,</span> <span class="token string">'绝对'</span><span class="token punctuation">,</span> <span class="token string">'美好'</span><span class="token punctuation">,</span> <span class="token string">'联系'</span><span class="token punctuation">,</span> <span class="token string">'过去'</span><span class="token punctuation">,</span> <span class="token string">'这样'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">3</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">3</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>可以看到，我们使用jieba进行分词，就能像处理英文一样对中文进行处理了，如果两篇文章分类是一样的，他们一下特殊词汇出现是差不多的。如科技，支付宝等等这些词汇。</p> 
  <h2><a id="07_tfdf_342"></a>07_tf-df分析问题</h2> 
  <p>接下来讲解tf-df，我们先来看看下图：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512210135691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAxMzc2MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 一篇文章出现了共享，车等词语，另外一篇出现了银行，经济，证券等其他词汇，我们人根据这些词汇是很容易分辨出文章的类型的。但是机器怎么分辨呢？上面我们看到一个词语占比的概念，那么他是什么意思呢？</p> 
  <p>在前面我们使用的count，即通过词汇出现的次数对文本进行分类，但是这种方式是十分不精确，一般不会使用。在每篇文章中，还会出现其他的词汇，并且数量是非常多的，但是他对我们文章的分类又没有太重要的作用，如你们，我，他们，明天，等等这些词汇。这些词汇，在每篇文章都会出现，但是他却无关紧要，根据这些词汇，我们是不能分辨出一篇文章的类别的。</p> 
  <p>为了解决这个问题，所以出现了TfIdf。其分为两个部分：TF（term frequency：词的频率，即之前我们统计词的次数），IDF（invers documen frequency：逆文档频率）。<br> TF：统计每个词出现的次数。<br> IDF：log（中文档数量/该词出现的文档数）。</p> 
  <p>TF * IDF：一个词的重要性，TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分<br> 能力，适合用来分类。<br> TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</p> 
  <p>为了大家更好的理解，我们先介绍一下他的API，然后做一个例子：</p> 
  <pre><code class="prism language-c">类：sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text<span class="token punctuation">.</span>TfidfVectorizer
	
<span class="token function">TfidfVectorizer</span><span class="token punctuation">(</span>stop_words<span class="token operator">=</span>None<span class="token punctuation">,</span>…<span class="token punctuation">)</span>
返回词的权重矩阵

	TfidfVectorizer<span class="token punctuation">.</span><span class="token function">fit_transform</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>       
	X<span class="token punctuation">:</span>文本或者包含文本字符串的可迭代对象
	返回值：返回sparse矩阵
	
	TfidfVectorizer<span class="token punctuation">.</span><span class="token function">inverse_transform</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
	X<span class="token punctuation">:</span>array数组或者sparse矩阵
	返回值<span class="token punctuation">:</span>转换之前数据格式
	
	TfidfVectorizer<span class="token punctuation">.</span><span class="token function">get_feature_names</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	返回值<span class="token punctuation">:</span>单词列表
</code></pre> 
  <p>我们编写程序如下：</p> 
  <pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">tfidfvec</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 中文特征值化 :return: """</span>
    <span class="token comment"># 获取数据</span>
    c1<span class="token punctuation">,</span>c2<span class="token punctuation">,</span>c3 <span class="token operator">=</span> cutword<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 获得CountVectorizer实例化对象</span>
    tf<span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 使用fit_transform进行文本特征抽取</span>
    data <span class="token operator">=</span> tf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span><span class="token punctuation">[</span>c1<span class="token punctuation">,</span>c2<span class="token punctuation">,</span>c3<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 显示特征值对应的索引以及数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span>  <span class="token boolean">None</span>
</code></pre> 
  <p>改函数运行结果如下：</p> 
  <pre><code class="prism language-py"><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">,</span> <span class="token string">'之前'</span><span class="token punctuation">,</span> <span class="token string">'了解'</span><span class="token punctuation">,</span> <span class="token string">'事物'</span><span class="token punctuation">,</span> <span class="token string">'今天'</span><span class="token punctuation">,</span> <span class="token string">'光是在'</span><span class="token punctuation">,</span> <span class="token string">'几百万年'</span><span class="token punctuation">,</span> <span class="token string">'发出'</span><span class="token punctuation">,</span> <span class="token string">'取决于'</span><span class="token punctuation">,</span> <span class="token string">'只用'</span><span class="token punctuation">,</span> <span class="token string">'后天'</span><span class="token punctuation">,</span> <span class="token string">'含义'</span><span class="token punctuation">,</span> <span class="token string">'大部分'</span><span class="token punctuation">,</span> <span class="token string">'如何'</span><span class="token punctuation">,</span> <span class="token string">'如果'</span><span class="token punctuation">,</span> <span class="token string">'宇宙'</span><span class="token punctuation">,</span> <span class="token string">'我们'</span><span class="token punctuation">,</span> <span class="token string">'所以'</span><span class="token punctuation">,</span> <span class="token string">'放弃'</span><span class="token punctuation">,</span> <span class="token string">'方式'</span><span class="token punctuation">,</span> <span class="token string">'明天'</span><span class="token punctuation">,</span> <span class="token string">'星系'</span><span class="token punctuation">,</span> <span class="token string">'晚上'</span><span class="token punctuation">,</span> <span class="token string">'某样'</span><span class="token punctuation">,</span> <span class="token string">'残酷'</span><span class="token punctuation">,</span> <span class="token string">'每个'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'秘密'</span><span class="token punctuation">,</span> <span class="token string">'绝对'</span><span class="token punctuation">,</span> <span class="token string">'美好'</span><span class="token punctuation">,</span> <span class="token string">'联系'</span><span class="token punctuation">,</span> <span class="token string">'过去'</span><span class="token punctuation">,</span> <span class="token string">'这样'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0.43643578</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.21821789</span> <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.43643578</span> <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.43643578</span> <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.21821789</span> <span class="token number">0.21821789</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>

 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.2410822</span>  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.2410822</span>  <span class="token number">0.2410822</span>  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.2410822</span>
  <span class="token number">0.55004769</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.2410822</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.48216441</span> <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.2410822</span> <span class="token punctuation">]</span>

 <span class="token punctuation">[</span><span class="token number">0.15698297</span> <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.62793188</span> <span class="token number">0.47094891</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.15698297</span> <span class="token number">0.15698297</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.15698297</span> <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0.1193896</span>  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.31396594</span>
  <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.15698297</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <p>其结果还是一个二维数组，其每个一维数组中的每个元素，体现的都是这个词在这篇文章中的重要性，我们可以对这些数据进行排序，然后得到最重要的词汇。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
