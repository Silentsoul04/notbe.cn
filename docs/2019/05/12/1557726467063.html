<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>瞎聊深度学习——IMDB影评文本分类 « NotBeCN</title>
  <meta name="description" content="          本文中我希望用IMDB数据集和神经网络对数据集中的影评内容进行“正面影评”和“负面影评”的二分类。   IMDB   IMDB数据集是Tensorflow中带有的数据集，其中包含来自互联网电影库的50000条影评文本，首先来下载该数据集并且查看一下：   加载数据（如果缓存中没有回自动下载该数...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/1557726467063.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">瞎聊深度学习——IMDB影评文本分类</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>本文中我希望用IMDB数据集和神经网络对数据集中的影评内容进行“正面影评”和“负面影评”的二分类。</p> 
  <h2>IMDB</h2> 
  <p>IMDB数据集是Tensorflow中带有的数据集，其中包含来自互联网电影库的50000条影评文本，首先来下载该数据集并且查看一下：</p> 
  <h3>加载数据（如果缓存中没有回自动下载该数据）：</h3> 
  <pre class="has">
<code class="language-python">import tensorflow as tf
from tensorflow import keras
import numpy as np

imdb = keras.datasets.imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)</code></pre> 
  <h3>查看数据：</h3> 
  <pre class="has">
<code class="language-python">print("Trraining entries:{},labels:{}".format(len(train_data),len(train_labels)))</code></pre> 
  <p>输出中可以看到我们训练集的样本量为25000</p> 
  <p><img alt="" class="has" height="39" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512160743478.png" width="334"></p> 
  <p>查看数据中的其中一个样本是什么：</p> 
  <pre class="has">
<code class="language-python">print(train_data[0])</code></pre> 
  <p><img alt="" class="has" height="43" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512204211249.png" width="913"></p> 
  <p>可以看书虽然是影评，在我们的数据集中译英转换为了数值类型而不是字符型，<span style="color:#f33b45;">其中每一个数字都代表一个词语</span>，后续会用其他的方法将数值型转换为字符型。</p> 
  <p>我们知道在神经网络的输入中必须要有相同的长度，所以我们先查看几条数据的长度是不是相同的：</p> 
  <pre class="has">
<code class="language-python">print(len(train_data[0]),len(train_data[10]),len(train_data[100]))</code></pre> 
  <p><img alt="" class="has" height="40" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512204727180.png" width="131"></p> 
  <p>由这个输出结果可以看出，每条影评的长度是不相同的所以我们要想办法处理这个问题，在这里我的办法设置一个最长值得限制，并将短的数据用零来填充：</p> 
  <pre class="has">
<code class="language-python">train_data = keras.preprocessing.sequence.pad_sequences(train_data,
                                                        value=0,
                                                        padding='post',
                                                        maxlen=256)

test_data = keras.preprocessing.sequence.pad_sequences(test_data,
                                                       value=0,
                                                       padding='post',
                                                       maxlen=256)
print(len(train_data[0]),len(train_data[10]),len(train_data[100]))</code></pre> 
  <p>输出结果如下，此时我们可以看出每一条数据的长度都是相同的：</p> 
  <p><img alt="" class="has" height="32" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512205443350.png" width="158"></p> 
  <p>keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype=’int32’, padding=’pre’, truncating=’pre’, value=0.)&nbsp;</p> 
  <p>函数说明：&nbsp;<br> 将长为nb_samples的序列（标量序列）转化为形如(nb_samples,nb_timesteps)2D numpy array。如果提供了参数maxlen，nb_timesteps=maxlen，否则其值为最长序列的长度。其他短于该长度的序列都会在后部填充0以达到该长度。长于nb_timesteps的序列将会被截断，以使其匹配目标长度。padding和截断发生的位置分别取决于padding和truncating.&nbsp;<br> 参数：</p> 
  <p>sequences：浮点数或整数构成的两层嵌套列表</p> 
  <p>maxlen：None或整数，为序列的最大长度。大于此长度的序列将被截短，小于此长度的序列将在后部填0.</p> 
  <p>dtype：返回的numpy array的数据类型</p> 
  <p>padding：‘pre’或‘post’，确定当需要补0时，在序列的起始还是结尾补</p> 
  <p>truncating：‘pre’或‘post’，确定当需要截断序列时，从起始还是结尾截断</p> 
  <p>value：浮点数，此值将在填充时代替默认的填充值0</p> 
  <h3><br> 构建模型</h3> 
  <p>神经网络通过层数的堆叠创建成，下面先说一下每一层的作用。</p> 
  <p>示例中，输入数据由字词-索引数组构成，要预测的标签是0或1（正面影评和负面影评）</p> 
  <p>第一层：Embedding层，该层会在整数编码的词汇表中查找每个字词-索引的嵌入向量，模型在接受训练时会学习这些向量，这些向量会向输出数组中添加一个维度，添加后的维度是（batch，sequence，embedding）；</p> 
  <p>第二层：一个&nbsp;<code>GlobalAveragePooling1D</code>&nbsp;层通过对序列维度求平均值，针对每个样本返回一个长度固定的输出向量。这样，模型便能够以尽可能简单的方式处理各种长度的输入。</p> 
  <p>第三层：该长度固定的输出向量会传入一个全连接 (<code>Dense</code>) 层（包含 16 个隐藏单元）。</p> 
  <p>第四层：最后一层与单个输出节点密集连接。应用&nbsp;<code>sigmoid</code>&nbsp;激活函数后，结果是介于 0 到 1 之间的浮点值，表示概率或置信水平。</p> 
  <pre class="has">
<code class="language-python">vocab_size = 10000

model = keras.Sequential()
model.add(keras.layers.Embedding(vocab_size, 16))
model.add(keras.layers.GlobalAveragePooling1D())
model.add(keras.layers.Dense(16, activation=tf.nn.relu))
model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))

model.summary()</code></pre> 
  <p>输出如下：</p> 
  <p><img alt="" class="has" height="300" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512211809534.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1MTY0NTU0,size_16,color_FFFFFF,t_70" width="403"></p> 
  <h3>损失函数和优化器</h3> 
  <p>构建完了神经网络下面我们来定义一个损失函数和优化器</p> 
  <pre class="has">
<code class="language-python">model.compile(optimizer=tf.train.AdamOptimizer(),
              loss='binary_crossentropy',
              metrics=['accuracy'])</code></pre> 
  <h3>创建验证集</h3> 
  <p>创建数据集的目的是为了检测模型处理未见过的数据时的准确率，我们取总数据的20%也就是10000条数据来创建验证集。</p> 
  <pre class="has">
<code class="language-python">x_val = train_data[:10000]
partial_x_train = train_data[10000:]

y_val = train_labels[:10000]
partial_y_train = train_labels[10000:]</code></pre> 
  <h3>训练模型并且评估模型</h3> 
  <p>用有 512 个样本的小批次训练模型 40 个周期。这将对&nbsp;<code>x_train</code>&nbsp;和&nbsp;<code>y_train</code>&nbsp;张量中的所有样本进行 40 次迭代。在训练期间，监控模型在验证集的 10000 个样本上的损失和准确率，最后我们使用evaluate来查看模型的误差和准确率：</p> 
  <pre class="has">
<code class="language-python">history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=40,
                    batch_size=512,
                    validation_data=(x_val, y_val),
                    verbose=1)
results = model.evaluate(test_data, test_labels)

print(results)</code></pre> 
  <p>最后的输出结果如下：</p> 
  <p><img alt="" class="has" height="41" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512212929409.png" width="345"></p> 
  <p>由此可见我们的模型准确率为0.87，并不是很完美，如果采用更好的方法可能会对准确率有更大的提高。</p> 
  <p>&nbsp;</p> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
