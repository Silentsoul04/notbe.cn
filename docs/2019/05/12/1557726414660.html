<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Python骚操作：爬虫爬取性感美女图，已装满我硬盘！ « NotBeCN</title>
  <meta name="description" content="         作为一名兢兢业业的猿，我们的工作就是写代码and找Bug，这种技术活周围的妹子比较少，为了防止工作乏味有了程序员鼓励师这个职业，当然并不是所有的公司都会给我们配备，这个时候我们就需要用自己的长处“自己创造”！   如果你对编程感兴趣或者想往编程方向发展，可以关注微信公众号【筑梦编程】，大家一起交...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/1557726414660.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">Python骚操作：爬虫爬取性感美女图，已装满我硬盘！</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>作为一名兢兢业业的猿，我们的工作就是写代码and找Bug，这种技术活周围的妹子比较少，为了防止工作乏味有了程序员鼓励师这个职业，当然并不是所有的公司都会给我们配备，这个时候我们就需要用自己的长处“自己创造”！</p> 
  <p>如果你对编程感兴趣或者想往编程方向发展，可以关注微信公众号<strong>【筑梦编程】</strong>，大家一起交流讨论！小编也会每天定时更新既有趣又有用的编程知识！</p> 
  <blockquote> 
   <p>GitHub:https://github.com/injetlee/Python/blob/master/%E7%88%AC%E8%99%AB%E9%9B%86%E5%90%88/meizitu.py</p> 
  </blockquote> 
  <p>本文目标</p> 
  <ol>
   <li> <p><strong>熟悉 Requests 库，Beautiful Soup 库</strong></p> </li> 
   <li> <p><strong>熟悉多线程爬取</strong></p> </li> 
   <li> <p><strong>送福利，妹子图</strong></p> </li> 
  </ol>
  <p>先来看看爬虫爬取的成果：</p> 
  <p><img alt="" class="has" height="650" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512153148708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDgxMTQxNw==,size_16,color_FFFFFF,t_70" width="627"></p> 
  <p>&nbsp;</p> 
  <p>其实这个项目去年就写好了，只是自己先消化一下，所以今天才放出来给大家看看！</p> 
  <p><strong>网站结构</strong></p> 
  <p>爬取的目标网址：http://meizitu.com/a/more_1.html&nbsp;</p> 
  <p>进去后就如同下图所示：</p> 
  <p><img alt="" class="has" height="670" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512153203824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDgxMTQxNw==,size_16,color_FFFFFF,t_70" width="598"></p> 
  <p>&nbsp;</p> 
  <p>这种图示一组一组的套图，点击一张图片可以进入这些套图的里面，大概一组套图有10张左右的图片，这些图还是1字排开的！</p> 
  <p><img alt="" class="has" height="800" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512153209709.png" width="178"></p> 
  <p>实现思路</p> 
  <p>看了界面的结构，那么我们的思路就有了。</p> 
  <ol>
   <li> <p><strong>构造几个URL链接，然后请求上面套图的列表，获取到每个页面的套图列表！</strong></p> </li> 
   <li> <p><strong>进入每一组套图里面，然后获取每组套图里的每张图片！</strong></p> </li> 
  </ol>
  <p>废话不多说，直接上代码了</p> 
  <ol>
   <li> <p><strong>下载界面的函数,利用 Requests 很方便实现。</strong></p> </li> 
  </ol>
  <pre>
<code>def download_page(url):</code><code> '''</code><code> 用于下载页面</code><code> '''</code><code> headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0"}</code><code> r = requests.get(url, headers=headers)</code><code> r.encoding = 'gb2312'</code><code> return r.text</code></pre> 
  <ol>
   <li> <p>获取套图的列表，Link是套图的链接（应该注释一下），text是套图的名字！</p> </li> 
  </ol>
  <p>def get_pic_list(html):</p> 
  <p>'''</p> 
  <p>获取每个页面的套图列表,之后循环调用get_pic函数获取图片</p> 
  <p>'''</p> 
  <p><code>soup = BeautifulSoup(html, 'html.parser')pic_list = soup.find_all('li', class_='wp-item')</code><code>for i in pic_list:</code><code>a_tag = i.find('h3', class_='tit').find('a')</code><code>link = a_tag.get('href') # 套图链接</code><code>text = a_tag.get_text() # 套图名字</code><code>get_pic(link, text)</code></p> 
  <ol>
   <li> <p>传入上一步中获取到的套图链接及套图名字,获取每组套图里面的图片,并保存,我在代码中注释了。</p> </li> 
  </ol>
  <pre>
<code>def get_pic(link, text):</code><code> '''</code><code> 获取当前页面的图片,并保存</code><code> '''</code><code> html = download_page(link) # 下载界面</code><code> soup = BeautifulSoup(html, 'html.parser')</code><code> pic_list = soup.find('div', id="picture").find_all('img') # 找到界面所有图片</code><code> headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0"}</code><code> create_dir('pic/{}'.format(text))</code><code> for i in pic_list:</code><code> pic_link = i.get('src') # 拿到图片的具体 url</code><code> r = requests.get(pic_link, headers=headers) # 下载图片，之后保存到文件</code><code> with open('pic/{}/{}'.format(text, pic_link.split('/')[-1]), 'wb') as f:</code><code> f.write(r.content)</code><code> time.sleep(1)</code></pre> 
  <p>完整代码</p> 
  <p>完整代码放在下面，利用多线程去爬取（其实也不多，5个罢了）</p> 
  <pre>
<code>import requests</code><code>import os</code><code>import time</code><code>import threading</code><code>from bs4 import BeautifulSoup</code><code>def download_page(url):</code><code> '''</code><code> 用于下载页面</code><code> '''</code><code> headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0"}</code><code> r = requests.get(url, headers=headers)</code><code> r.encoding = 'gb2312'</code><code> return r.text</code><code>def get_pic_list(html):</code><code> '''</code><code> 获取每个页面的套图列表,之后循环调用get_pic函数获取图片</code><code> '''</code><code> soup = BeautifulSoup(html, 'html.parser')</code><code> pic_list = soup.find_all('li', class_='wp-item')</code><code> for i in pic_list:</code><code> a_tag = i.find('h3', class_='tit').find('a')</code><code> link = a_tag.get('href')</code><code> text = a_tag.get_text()</code><code> get_pic(link, text)</code><code>def get_pic(link, text):</code><code> '''</code><code> 获取当前页面的图片,并保存</code><code> '''</code><code> html = download_page(link) # 下载界面</code><code> soup = BeautifulSoup(html, 'html.parser')</code><code> pic_list = soup.find('div', id="picture").find_all('img') # 找到界面所有图片</code><code> headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0"}</code><code> create_dir('pic/{}'.format(text))</code><code> for i in pic_list:</code><code> pic_link = i.get('src') # 拿到图片的具体 url</code><code> r = requests.get(pic_link, headers=headers) # 下载图片，之后保存到文件</code><code> with open('pic/{}/{}'.format(text, pic_link.split('/')[-1]), 'wb') as f:</code><code> f.write(r.content)</code><code> time.sleep(1) # 休息一下，不要给网站太大压力，避免被封</code><code>def create_dir(name):</code><code> if not os.path.exists(name):</code><code> os.makedirs(name)</code><code>def execute(url):</code><code> page_html = download_page(url)</code><code> get_pic_list(page_html)</code><code>def main():</code><code> create_dir('pic')</code><code> queue = [i for i in range(1, 72)] # 构造 url 链接 页码。</code><code> threads = []</code><code> while len(queue) &gt; 0:</code><code> for thread in threads:</code><code> if not thread.is_alive():</code><code> threads.remove(thread)</code><code> while len(threads) &lt; 5 and len(queue) &gt; 0: # 最大线程数设置为 5</code><code> cur_page = queue.pop(0)</code><code> url = 'http://meizitu.com/a/more_{}.html'.format(cur_page)</code><code> thread = threading.Thread(target=execute, args=(url,))</code><code> thread.setDaemon(True)</code><code> thread.start()</code><code> print('{}正在下载{}页'.format(threading.current_thread().name, cur_page))</code><code> threads.append(thread)</code><code>if __name__ == '__main__':</code><code> main()</code></pre> 
  <p>好了，之后运行，我们的爬虫就会孜孜不倦的以5倍的效率为我们下载漂亮妹子的图片啦。</p> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
