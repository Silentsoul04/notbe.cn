<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>pytorch基础知识二 « NotBeCN</title>
  <meta name="description" content="         线性回归的损失函数和梯度更新如下图：      一，numpy实现线性回归梯度下降   import numpy as npimport matplotlib.pyplot as pltdef get_fake_data(batch_size=8):    ''' 产生随机数据：y=x*2+3，...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/1557726262536.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">pytorch基础知识二</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>线性回归的损失函数和梯度更新如下图：</p> 
  <h3><img alt="" class="has" height="167" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190102220117460.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbnpvbmdoYW8=,size_16,color_FFFFFF,t_70" width="455"></h3> 
  <h3><strong>一，numpy实现线性回归梯度下降</strong></h3> 
  <pre class="has">
<code class="language-html">import numpy as np
import matplotlib.pyplot as plt
def get_fake_data(batch_size=8):
    ''' 产生随机数据：y=x*2+3，加上了一些噪声'''
    x = np.random.rand(batch_size, 1) * 5
    y = x * 2 + 3 + np.random.rand(batch_size, 1)*2
    return x, y

def get_gradient(theta,x,y):
    m=x.shape[0]
    Y_estimate=np.dot(x,theta)
    assert (Y_estimate.shape==(m,))
    error=Y_estimate-y
    assert (error.shape==(m,))
    cost =1.0/(2*m)*np.sum(error**2)
    #grad=(1.0/m)*np.dot(x.T,error).reshape(-1)#(2,)
    grad = (1.0 / m) * np.dot(error,x) # (2,)
    return grad,cost
def gradient_descent(x,y,iterations,alpha):

    theta=np.random.randn(2)
    costs=[]
    for i in range(iterations):
        grad,cost=get_gradient(theta,x,y)
        new_theta=theta-alpha*grad
        if i%100==0:
            print('{} iterations cost={}'.format(i,cost))
            costs.append(cost)
        theta=new_theta
    return costs,theta

def vis_data():
    # 来看看产生的x-y分布
    x, y = get_fake_data(batch_size=16)
    print(x.shape)
    print(y.shape)
    plt.scatter(np.squeeze(x), np.squeeze(y))
    plt.show()
if __name__=='__main__':
    batch_size=32
    data_x, data_y = get_fake_data(batch_size=batch_size)
    #添加一列为1的向量 实际上就是乘以 theta 就是b
    data_x=np.hstack((data_x,np.ones_like(data_x)))#(m,2)
    print(data_x)
    print(data_x.shape)

    costs,theta=gradient_descent(data_x,np.squeeze(data_y),iterations=50000,alpha=0.002)
    print(data_y.shape)

    #print(theta)
    y_predict=np.dot(data_x,theta)#theta[0]+theta[1]*data_x[:,1]
    print(y_predict.shape)
    plt.figure()
    #样本图
    print(data_x[:2])
    plt.scatter(data_x[:,0],np.squeeze(data_y),c='red')
    plt.plot(data_x[:,0],y_predict)
    plt.show()

</code></pre> 
  <p><img alt="" class="has" height="254" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019051215070061.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbnpvbmdoYW8=,size_16,color_FFFFFF,t_70" width="341"></p> 
  <p>红色的是散列点，蓝色的线是拟合的直线。</p> 
  <h3><strong>二，pytorch实现线性回归梯度下降</strong></h3> 
  <pre class="has">
<code class="language-html">import numpy as np
import matplotlib.pyplot as plt
import torch as t

device=t.device('cpu')

def get_fake_data(batch_size=8):
    ''' 产生随机数据：y=x*2+3，加上了一些噪声'''
    x = t.rand(batch_size, 1,device=device) * 5
    y = x * 2 + 3 + t.rand(batch_size, 1)*2
    return x, y

def vis_data():
    # 来看看产生的x-y分布
    x, y = get_fake_data(batch_size=16)
    print(x.shape)
    print(y.shape)
    plt.scatter(np.squeeze(x), np.squeeze(y))
    plt.show()
if __name__=='__main__':
    # vis_data()

    m=batch_size=32
    data_x, data_y = get_fake_data(batch_size=batch_size)
    #添加一列为1的向量 实际上就是乘以 theta 就是b
    data_x=t.from_numpy(np.hstack((data_x,np.ones_like(data_x))))#(m,2)
    print(data_x.shape)

    theta = t.randn((2, 1),requires_grad=True)
    iterations=500
    lr = 0.005  # 学习率
    losses=[]
    for i in range(iterations):
        # forward：计算loss
        y_pred = data_x.mm(theta)
        print('y_pred',y_pred.shape)
        loss = 1/(2*m) * (y_pred - data_y) ** 2
        print('loss',loss.shape)
        loss = loss.sum()
        print('loss', loss.shape)
        losses.append(loss.item())

        # backward：手动计算梯度
        loss.backward()

        # 更新参数
        theta.data.sub_(lr * theta.grad.data)

        # 梯度清零
        theta.grad.data.zero_()
    print('losses=',losses)
    # 画图
    plt.scatter(np.squeeze(data_x[:,0]), np.squeeze(data_y),c='red')
    y_predict=data_x.mm(theta)
    print('y_predict.shape',y_predict.shape)
    print(data_x.detach().numpy())
    plt.plot(data_x.detach().numpy()[:,0], y_predict.detach().numpy())  # predicted
    plt.show()</code></pre> 
  <p><img alt="" class="has" height="263" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512155718275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbnpvbmdoYW8=,size_16,color_FFFFFF,t_70" width="356"></p> 
  <h3><strong>三.对CIFAR10数据集进行训练</strong></h3> 
  <pre class="has">
<code class="language-html">import torch as t
import torchvision as tv
import torchvision.transforms as transforms
from torchvision.transforms import ToPILImage
import os
from PIL import Image
import matplotlib.pyplot as plt
import cv2

show = ToPILImage()  # 可以把Tensor转成Image，方便可视化

# 定义对数据的预处理
transform = transforms.Compose([
    transforms.ToTensor(),  # 转为Tensor 归一化至0～1
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # 归一化
])

path = './data'
if not os.path.exists(path):
    os.mkdir(path)
# 训练集
trainset = tv.datasets.CIFAR10(
    root=path,
    train=True,
    download=True,
    transform=transform)

trainloader = t.utils.data.DataLoader(
    trainset,
    batch_size=4,
    shuffle=True,
    num_workers=2)

# 测试集
testset = tv.datasets.CIFAR10(
    path,
    train=False,
    download=True,
    transform=transform)

testloader = t.utils.data.DataLoader(
    testset,
    batch_size=4,
    shuffle=False,
    num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

(data, label) = trainset[100]
print(data.shape)
print(classes[label])


def vis_data_cv2():
    new_data = data.numpy()
    new_data = (new_data * 0.5 + 0.5) * 255
    print(new_data.shape)
    new_data = new_data.transpose((1, 2, 0))
    new_data = cv2.resize(new_data, (100, 100))
    new_data = cv2.cvtColor(new_data, cv2.COLOR_RGB2BGR)
    print(new_data.shape)
    cv2.imwrite('1.jpg', new_data)


def vis_data_mutilpy():
    dataiter = iter(trainloader)
    images, labels = dataiter.next()  # 返回4张图片及标签
    print(' '.join('%11s' % classes[labels[j]] for j in range(4)))
    img = show(tv.utils.make_grid((images + 1) / 2)).resize((400, 100))
    import numpy as np
    img = np.array(img)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    print(img.shape)
    cv2.imwrite('2.jpg', img)


import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(x.size()[0], -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.softmax(self.fc3(x), dim=1)
        return x

net = Net()
print(net)
for name, parameters in net.named_parameters():
    print(name, ':', parameters.size())

params = list(net.parameters())
print(len(params))
print('params=', params)


from torch import optim
criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数
optimizer = optim.Adam(net.parameters(), lr=0.001)

t.set_num_threads(8)

losses=[]
for epoch in range(1):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        if i&lt;1000:
            # 输入数据
            inputs, labels = data
            # 梯度清零
            optimizer.zero_grad()
            # forward + backward
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            # print('loss=',loss)
            loss.backward()
            # 更新参数
            optimizer.step()
            # 打印log信息
            # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]
            losses.append(loss.item())
plt.plot(losses)
plt.show()
print('Finished Training')
correct = 0  # 预测正确的图片数
total = 0  # 总共的图片数
# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存
with t.no_grad():
    for i, data in enumerate(testloader):
        images, labels = data
        outputs = net(images)
        _, predicted = t.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum()
print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))
</code></pre> 
  <p>&nbsp;</p> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
