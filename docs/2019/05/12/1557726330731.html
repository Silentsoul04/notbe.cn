<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>这可能是你见过的最全的Python爬虫干货总结！ « NotBeCN</title>
  <meta name="description" content="                  本次分享从抓取、解析、存储、反爬、加速五个方面介绍了利用 Python 进行网络爬虫开发的相关知识点和技巧，介绍了不同场景下如何采取不同措施高效地进行数据抓取的方法，包括 Web 抓取、App 抓取、数据存储、代理选购、验证码破解、分布式抓取及管理、智能解析等多方面的内容，另外...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/1557726330731.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">这可能是你见过的最全的Python爬虫干货总结！</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>本次分享从抓取、解析、存储、反爬、加速五个方面介绍了利用 Python 进行网络爬虫开发的相关知识点和技巧，介绍了不同场景下如何采取不同措施高效地进行数据抓取的方法，包括 Web 抓取、App 抓取、数据存储、代理选购、验证码破解、分布式抓取及管理、智能解析等多方面的内容，另外还结合了不同场景介绍了常用的一些工具包，全部内容是我在从事网络爬虫研究过程以来的经验精华总结。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-a381bf0de1d4a9aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>爬取</p> 
  <p>对于爬取来说，我们需要学会使用不同的方法来应对不同情景下的数据抓取任务。</p> 
  <p>爬取的目标绝大多数情况下要么是网页，要么是 App，所以这里就分为这两个大类别来进行了介绍。</p> 
  <p>对于网页来说，我又将其划分为了两种类别，即服务端渲染和客户端渲染，对于 App 来说，我又针对接口的形式进行了四种类别的划分——普通接口、加密参数接口、加密内容接口、非常规协议接口。</p> 
  <p>所以整个大纲是这样子的：</p> 
  <ul> 
   <li> <p>网页爬取</p> </li> 
   <li> <p>服务端渲染</p> </li> 
   <li> <p>客户端渲染</p> </li> 
   <li> <p>App 爬取</p> </li> 
   <li> <p>普通接口</p> </li> 
   <li> <p>加密参数接口</p> </li> 
   <li> <p>加密内容接口</p> </li> 
   <li> <p>非常规协议接口</p> </li> 
  </ul> 
  <h3><a id="___31"></a>爬取 / 网页爬取</h3> 
  <p>服务端渲染的意思就是页面的结果是由服务器渲染后返回的，有效信息包含在请求的 HTML 页面里面，比如猫眼电影这个站点。客户端渲染的意思就是页面的主要内容由 JavaScript 渲染而成，真实的数据是通过 Ajax 接口等形式获取的，比如淘宝、微博手机版等等站点。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-9f1b18d03a16db42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>服务端渲染的情况就比较简单了，用一些基本的 HTTP 请求库就可以实现爬取，如 urllib、urllib3、pycurl、hyper、requests、grab 等框架，其中应用最多的可能就是 requests 了。</p> 
  <p>对于客户端渲染，这里我又划分了四个处理方法：</p> 
  <ul> 
   <li> <p>寻找 Ajax 接口，此种情形可以直接使用 Chrome/Firefox 的开发者工具直接查看 Ajax 具体的请求方式、参数等内容，然后用 HTTP 请求库模拟即可，另外还可以通过设置代理抓包来查看接口，如 Fiddler/Charles。</p> </li> 
   <li> <p>模拟浏览器执行，此种情形适用于网页接口和逻辑较为复杂的情况，可以直接以可见即可爬的方式进行爬取，如可以使用 Selenium、Splinter、Spynner、pyppeteer、PhantomJS、Splash、requests-html 等来实现。</p> </li> 
   <li> <p>直接提取 JavaScript 数据，此种情形适用于真实数据没有经过 Ajax 接口获取，而是直接包含在 HTML 结果的某个变量中，直接使用正则表达式将其提取即可。</p> </li> 
   <li> <p>模拟执行 JavaScript，某些情况下直接模拟浏览器执行效率会偏低，如果我们把 JavaScript 的某些执行和加密逻辑摸清楚了，可以直接执行相关的 JavaScript 来完成逻辑处理和接口请求，比如使用 Selenium、PyExecJS、PyV8、js2py 等库来完成即可。</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-363edbe0643b1569.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-e562786dd0e9cde5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-81c38fc096de16c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-91bdc81bb0b357e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="__App__61"></a>爬取 / App 爬取</h3> 
  <p>对于 App 的爬取，这里分了四个处理情况：</p> 
  <ul> 
   <li> <p>对于普通无加密接口，这种直接抓包拿到接口的具体请求形式就好了，可用的抓包工具有 Charles、Fiddler、mitmproxy。</p> </li> 
   <li> <p>对于加密参数的接口，一种方法可以实时处理，例如 Fiddler、mitmdump、Xposed 等，另一种方法是将加密逻辑破解，直接模拟构造即可，可能需要一些反编译的技巧。</p> </li> 
   <li> <p>对于加密内容的接口，即接口返回结果完全看不懂是什么东西，可以使用可见即可爬的工具 Appium，也可以使用 Xposed 来 hook 获取渲染结果，也可以通过反编译和改写手机底层来实现破解。</p> </li> 
   <li> <p>对于非常规协议，可以使用 Wireshark 来抓取所有协议的包，或者使用 Tcpdump 来进行 TCP 数据包截获。</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-81d01f5254e37992.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-f30c1429dcdc68ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-65dfb76164dce868.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>以上便是爬取流程的相关分类和对应的处理方法。</p> 
  <h2><a id="_84"></a>解析</h2> 
  <p>对于解析来说，对于 HTML 类型的页面来说，常用的解析方法其实无非那么几种，正则、XPath、CSS Selector，另外对于某些接口，常见的可能就是 JSON、XML 类型，使用对应的库进行处理即可。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-d9ff40d1a12047be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>这些规则和解析方法其实写起来是很繁琐的，如果我们要爬上万个网站，如果每个网站都去写对应的规则，那么不就太累了吗？所以智能解析便是一个需求。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-95bec8bac95f953d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>智能解析意思就是说，如果能提供一个页面，算法可以自动来提取页面的标题、正文、日期等内容，同时把无用的信息给刨除，例如上图，这是 Safari 中自带的阅读模式自动解析的结果。</p> 
  <p>对于智能解析，下面分为四个方法进行了划分：</p> 
  <ul> 
   <li> <p>readability 算法，这个算法定义了不同区块的不同标注集合，通过权重计算来得到最可能的区块位置。</p> </li> 
   <li> <p>疏密度判断，计算单位个数区块内的平均文本内容长度，根据疏密程度来大致区分。</p> </li> 
   <li> <p>Scrapyly 自学习，是 Scrapy 开发的组件，指定⻚页⾯面和提取结果样例例，其可⾃自学习提取规则，提取其他同类⻚页⾯面。</p> </li> 
   <li> <p>深度学习，使⽤用深度学习来对解析位置进⾏行行有监督学习，需要⼤大量量标注数据。</p> </li> 
  </ul> 
  <p>如果能够容忍一定的错误率，可以使用智能解析来大大节省时间。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-fbf30aa6e24d8212.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>目前这部分内容我也还在探索中，准确率有待继续提高。</p> 
  <h2><a id="_115"></a>存储</h2> 
  <p>存储，即选用合适的存储媒介来存储爬取到的结果，这里还是分为四种存储方式来进行介绍。</p> 
  <ul> 
   <li> <p>文件，如 JSON、CSV、TXT、图⽚、视频、⾳频等，常用的一些库有 csv、xlwt、json、pandas、pickle、python-docx 等。</p> </li> 
   <li> <p>数据库，分为关系型数据库、非关系型数据库，如 MySQL、MongoDB、HBase 等，常用的库有 pymysql、pymssql、redis-py、pymongo、py2neo、thrift。</p> </li> 
   <li> <p>搜索引擎，如 Solr、ElasticSearch 等，便于检索和实现⽂本匹配，常用的库有 elasticsearch、pysolr 等。</p> </li> 
   <li> <p>云存储，某些媒体文件可以存到如七⽜牛云、又拍云、阿里云、腾讯云、Amazon S3 等，常用的库有 qiniu、upyun、boto、azure-storage、google-cloud-storage 等。</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-a75ccc560d3fe0ab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-37758003b1a982f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>这部分的关键在于和实际业务相结合，看看选用哪种方式更可以应对业务需求。</p> 
  <h2><a id="_135"></a>反爬</h2> 
  <p>反爬这部分是个重点，爬虫现在已经越来越难了，非常多的网站已经添加了各种反爬措施，在这里可以分为非浏览器检测、封 IP、验证码、封账号、字体反爬等。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-70072360c125f609.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>下面主要从封 IP、验证码、封账号三个方面来阐述反爬的处理手段。</p> 
  <h3><a id="___IP_144"></a>反爬 / 封 IP</h3> 
  <p>对于封 IP 的情况，可以分为几种情况来处理：</p> 
  <ul> 
   <li> <p>首先寻找手机站点、App 站点，如果存在此类站点，反爬会相对较弱。</p> </li> 
   <li> <p>使用代理，如抓取免费代理、购买付费代理、使用 Tor 代理、Socks 代理等。</p> </li> 
   <li> <p>在代理的基础上维护自己的代理池，防止代理浪费，保证实时可用。</p> </li> 
   <li> <p>搭建 ADSL 拨号代理，稳定高效。</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-2550fd51930101cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="___159"></a>反爬 / 验证码</h3> 
  <p>验证码分为非常多种，如普通图形验证码、算术题验证码、滑动验证码、点触验证码、手机验证码、扫二维码等。</p> 
  <ul> 
   <li> <p>对于普通图形验证码，如果非常规整且没有变形或干扰，可以使用 OCR 识别，也可以使用机器学习、深度学习来进行模型训练，当然打码平台是最方便的方式。</p> </li> 
   <li> <p>对于算术题验证码，推荐直接使用打码平台。</p> </li> 
   <li> <p>对于滑动验证码，可以使用破解算法，也可以模拟滑动。后者的关键在于缺口的找寻，可以使用图片比对，也可以写基本的图形识别算法，也可以对接打码平台，也可以使用深度学习训练识别接口。</p> </li> 
   <li> <p>对于点触验证码，推荐使用打码平台。</p> </li> 
   <li> <p>对于手机验证码，可以使用验证码分发平台，也可以购买专门的收码设备，也可以人工验证。</p> </li> 
   <li> <p>对于扫二维码，可以人工扫码，也可以对接打码平台。</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-0743206c15d6313b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-0100af75c2119744.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-a04c8e6f041e870f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="___184"></a>反爬 / 封账号</h3> 
  <p>某些网站需要登录才能爬取，但是一个账号登录之后请求过于频繁会被封号，为了避免封号，可以采取如下措施：</p> 
  <ul> 
   <li> <p>寻找手机站点或 App 站点，此种类别通常是接口形式，校验较弱。</p> </li> 
   <li> <p>寻找无登录接口，尽可能寻找⽆无需登录即可爬取的接口。</p> </li> 
   <li> <p>维护 Cookies 池，使⽤用批量账号模拟登录，使⽤时随机挑选可用 Cookies 使⽤即可，实现：<a href="https://github.com/Python3WebSpider/CookiesPool%E3%80%82" rel="nofollow">https://github.com/Python3WebSpider/CookiesPool。</a></p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-8f132742bf3f7512.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h2><a id="_197"></a>加速</h2> 
  <p>当爬取的数据量非常大时，如何高效快速地进行数据抓取是关键。</p> 
  <p>常见的措施有多线程、多进程、异步、分布式、细节优化等。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-c9b61560fe07bd79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="___206"></a>加速 / 多线程、多进程</h3> 
  <p>爬虫是网络请求密集型任务，所以使用多进程和多线程可以大大提高抓取效率，如使用 threading、multiprocessing 等。</p> 
  <h3><a id="___210"></a>加速 / 异步</h3> 
  <p>将爬取过程改成非阻塞形式，当有响应式再进行处理，否则在等待时间内可以运行其他任务，如使用 asyncio、aiohttp、Tornado、Twisted、gevent、grequests、pyppeteer、pyspider、Scrapy 等。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-06d3200e08530577.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="___216"></a>加速 / 分布式</h3> 
  <p>分布式的关键在于共享爬取队列，可以使用 celery、huey、rq、rabbitmq、kafka 等来实现任务队列的对接，也可以使用现成的框架 pyspider、Scrapy-Redis、Scrapy-Cluster 等。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-aad6f98ea513c9fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="___223"></a>加速 / 优化</h3> 
  <p>可以采取某些优化措施来实现爬取的加速，如：</p> 
  <ul> 
   <li> <p>DNS 缓存</p> </li> 
   <li> <p>使用更快的解析方法</p> </li> 
   <li> <p>使用更高效的去重方法</p> </li> 
   <li> <p>模块分离化管控</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-0cc7e75fc697c031.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <h3><a id="___238"></a>加速 / 架构</h3> 
  <p>如果搭建了分布式，要实现高效的爬取和管理调度、监控等操作，我们可以使用两种架构来维护我们的爬虫项目。</p> 
  <ul> 
   <li> <p>将 Scrapy 项目打包为 Docker 镜像，使用 K8S 控制调度过程。</p> </li> 
   <li> <p>将 Scrapy 项目部署到 Scrapyd，使用专用的管理工具如 SpiderKeeper、Gerapy 等管理。</p> </li> 
  </ul> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-fc4ed9946a1d6334.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>以上便是我分享的全部内容，所有的内容几乎都展开了</p> 
  <blockquote> 
   <p><strong>大家在学python的时候肯定会遇到很多难题，以及对于新技术的追求，这里推荐一下我们的Python学习扣qun：784758214，这里是python学习者聚集地！！同时，自己是一名高级python开发工程师，从基础的python脚本到web开发、爬虫、django、数据挖掘等，零基础到项目实战的资料都有整理。送给每一位python的小伙伴！每日分享一些学习的方法和需要注意的小细节</strong></p> 
  </blockquote> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-2d9795e33164f8d4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>另外对于这部分内容，其实还有我制作的更丰富的思维导图，预览图如下：</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-069c2d3eb52bf4da.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
