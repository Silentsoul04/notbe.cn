<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>SAGAN(Self-Attention Generative Adversarial Networks)论文笔记 « NotBeCN</title>
  <meta name="description" content="          论文链接：Self-Attention Generative Adversarial Networks   这篇论文是将自注意力机制引入生成对抗网络用于图像生成任务。   摘要：   这篇论文，作者提出了自注意力生成对抗网络(SAGAN)来建模像素间的远距离关系，用于图像生成任务。传统的生成对...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/xuefengyang666_90137109.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">SAGAN(Self-Attention Generative Adversarial Networks)论文笔记</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>论文链接：<a href="https://arxiv.org/pdf/1805.08318.pdf" rel="nofollow">Self-Attention Generative Adversarial Networks</a></p> 
  <p>这篇论文是将自注意力机制引入生成对抗网络用于图像生成任务。</p> 
  <p><strong>摘要：</strong></p> 
  <p style="text-indent:50px;">这篇论文，作者提出了自注意力生成对抗网络(SAGAN)来建模像素间的远距离关系，用于图像生成任务。传统的生成对抗网络(GAN)生成高分辨率图像的细节仅仅利用了低分辨率特征图的局部空间信息。在SAGAN，会利用特征图上所有的位置信息，而不仅仅是局部位置信息。此外，判别器还可以检查图像中较远部分的细节特征是否一致。最近有研究表明生成器的状态会影响GAN的性能，根据这个问题，作者对生成器使用谱范数归一化能有效提高训练的稳定性。作者提出的SAGAN在ImageNet数据集上实现了最好的结果，将最高的Inception分数从36.8提高到52.52，并且将Fréchet Inception距离从27.62降低到18.65。引入注意力的卷积层可视化显示，生成器利用了与目标形状对应的邻域，而不是固定形状的局部区域。</p> 
  <p><strong>思路：</strong></p> 
  <p style="text-indent:50px;">图像合成是计算机视觉中的一个重要问题。基于深度卷积神经网络的生成对抗网络在这方面已经取得了显著的进步。然而，通过仔细检查这些模型生成的样本，我们可以发现，卷积神经网络在对多类别数据集上进行训练时，对某些图像类别的建模要比其他类别困难得多（比如ImageNet），比如，在ImageNet数据集上训练的GAN模型擅长合成有很少结构约束的目标，比如海洋，天空和风景等类别，这些类别纹理特征比几何特征更明显。但是不能很好地捕捉某些目标固有的几何或结构模式，比如狗，通常能生成逼真的皮毛纹理但是不能生成清晰的狗爪。一个可能的解释是这些模型主要依赖卷积去建模图像不同区域的依赖关系。由于卷积操作只有很小的感受野（因为卷积核大部分是<img alt="3\times 3" class="mathcode" src="https://private.codecogs.com/gif.latex?3%5Ctimes%203">）,远距离的依赖关系需要经过几层卷积操作才能获取到（因为有池化层存在，每次池化下采样，感受野就会扩大，多个池化之后，感受野就能达到整幅图的大小，但是这仅仅是理论上的，实际的感受野比这小的多）。使得模型无法获取远距离依赖关系的愿意有多种：模型太小，学习能力不足，无法获取远距离依赖关系；因为需要多个层的处理，才能获取更大感受野从而获取远距离依赖关系，但是优化算法很难优化这些参数（找不到最优解，因为传到每层的梯度都不一样，后面作者提出的SAGAN，是要在一层直接获取远距离依赖关系，而不是通过多层来获取）；通过多层获取到的远距离依赖关系没有统计分布的代表性，很难泛化到从未见过的输入数据中。增加卷积核的大小虽然能提高网络的特征提取能力（参数多了，感受野也变大了）但是会增加计算负担。而自注意力机制，可以在不增加计算负担的情况下，获取像素间的远距离依赖关系。自注意力模块会通过其它所有像素位置信息的加权和来计算每个位置的响应值，计算这些权重向量仅仅需要很小的计算代价。作者将自注意力机制引入GAN用于图像生成任务，可以弥补传统GAN不能很好建模像素远距离依赖关系的问题，这样生成的图像细节更加真实清晰，判别器也可以利用远距离的细节来约束当前合成图像的细节，使得结果更真实。除此之外，作者还将谱归一化应用到了生成器网络，之前的研究仅仅是添加在判别网络，也就是说，作者在生成器网络和判别器网络中都添加了谱归一化。</p> 
  <p><strong>自注意力模块：</strong></p> 
  <p style="text-align:center;"><img alt="" class="has" height="545" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512103627601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZWZlbmd5YW5nNjY2,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p style="text-indent:50px;">&nbsp;上图是作者提出的自注意力模块，可以看出，来自上一层的特征图x通过三个不同的<img alt="1\times 1" class="mathcode" src="https://private.codecogs.com/gif.latex?1%5Ctimes%201">卷积被转换为三个不同的特征空间f(x),g(x),h(x)。其实这一步主要是为了降低计算量，一般f(x),g(x)输出的特征通道数是输入特征图通道数的1/8，然后用f(x)生成的特征图重新排列成（<img alt="H\times W,C" class="mathcode" src="https://private.codecogs.com/gif.latex?H%5Ctimes%20W%2CC">）转置后和g(x)生成的特征图（也重新排列成<img alt="H\times W,C" class="mathcode" src="https://private.codecogs.com/gif.latex?H%5Ctimes%20W%2CC">）相乘得到大小为<img alt="(H\times W,H\times W)" class="mathcode" src="https://private.codecogs.com/gif.latex?%28H%5Ctimes%20W%2CH%5Ctimes%20W%29">的二矩阵<img alt="（H\times W,H\times W）" class="mathcode" src="https://private.codecogs.com/gif.latex?%25uFF08H%5Ctimes%20W%2CH%5Ctimes%20W%25uFF09">，再经过softmax对该矩阵最后一个维度将数值归一化到[0,1]，没有这一步可能会导致梯度爆炸(我试过，，)，因为数值太大了。然后和h(x)生成的特征图（也重新排列成<img alt="H\times W,C" class="mathcode" src="https://private.codecogs.com/gif.latex?H%5Ctimes%20W%2CC">）相乘得到大小为<img alt="(H\times W,C)" class="mathcode" src="https://private.codecogs.com/gif.latex?%28H%5Ctimes%20W%2CC%29">的矩阵，然后重排列成<img alt="(H\times W\times C)" class="mathcode" src="https://private.codecogs.com/gif.latex?%28H%5Ctimes%20W%5Ctimes%20C%29">，作为注意力特征图，然后乘以一个系数<img alt="\gamma" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Cgamma">,和x逐元素相加即可，其中<img alt="\gamma" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Cgamma">初始为0，作者说先让网络学习局部信息，再慢慢学习远距离信息，即由易到难。以下是计算公式，基本就是上面所描述的：</p> 
  <p style="text-align:center;"><img alt="" class="has" height="862" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512110533401.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZWZlbmd5YW5nNjY2,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><strong>损失函数：</strong></p> 
  <p>&nbsp;</p> 
  <p style="text-align:center;"><img alt="" class="has" height="123" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512110651304.png" width="1200"></p> 
  <p>&nbsp;网络是交替训练的方式进行，损失函数和其他用于图像生成GAN网络的一样。</p> 
  <p><strong>谱范数正则化</strong><strong>：</strong></p> 
  <p style="text-indent:50px;">最开始谱范数正则化是用于判别器网络。通过限制每一层的谱范数来约束Lipschitz常数，与其他正则化技术相比，谱范数正则化不需要额外的超参数(将所有权层的谱范数设置为1在实践中表现良好)。此外，计算成本也相对较小。作者发现，谱范数正则化也可以用于生成网络中，可以防止生成网络参数值过大，出现异常梯度，导致训练不稳定。而且在判别器和生成器网络都使用谱范数正则化，在训练过程中，判别器需要更少的更新次数（消除了数值震荡，收敛更快），提高了训练效率。科普一下什么是谱范数，谱范数类似于矩阵的特征值，但是特征值只有方阵才有。矩阵可以表示成一个高维空间，空间的维数等于矩阵的秩，高维空间可以划分成更小的子空间组成，举个不是很严谨的例子，高维空间就是由很多子空间的加权和，而特征值，奇异值就是对应的权值。谱范数是最大的那个奇异值。也就是说，每层的输出，都会将权值除以该特征图的谱范数。求解特征图谱范数是用近似值代替的，迭代一次效果就可以。</p> 
  <p><strong>学习率设置：</strong></p> 
  <p>通常使用了正则化的判别网络会降低GAN网络训练速度，在训练期间，使用正则化的判别器GAN通常每更新一次生成器网络，就要更新多次判别器网络（让判别器多学习几次）。作者对判别器和生成器使用不同的学习率，判别器学习率调大一些，需要更新的次数就可以减少。这样就可以缩短训练时间。</p> 
  <p><strong>实验结果：</strong></p> 
  <p style="text-align:center;"><img alt="" class="has" height="337" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512141730663.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZWZlbmd5YW5nNjY2,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p style="text-align:center;"><img alt="" class="has" height="839" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512141802897.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZWZlbmd5YW5nNjY2,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p style="text-align:center;"><img alt="" class="has" height="382" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512141833718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1ZWZlbmd5YW5nNjY2,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
