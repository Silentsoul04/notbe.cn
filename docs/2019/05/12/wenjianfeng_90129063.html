<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Kafka实现淘宝亿万级数据统计 « NotBeCN</title>
  <meta name="description" content="         一、了解淘宝Kafka架构   在ActiveMQ、RabbitMQ、RocketMQ、Kafka消息中间件之间，我们为什么要选择Kafka?   天猫在电商节如何处理大数据？技术架构上采用了哪些策略？   1、应用无状态(淘宝session框架)   2、有效使用缓存(Tair)   3、应用...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/wenjianfeng_90129063.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">Kafka实现淘宝亿万级数据统计</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h1>一、了解淘宝Kafka架构</h1> 
  <p>在ActiveMQ、RabbitMQ、RocketMQ、Kafka消息中间件之间，<strong>我们为什么要选择Kafka?</strong></p> 
  <p><strong>天猫在电商节如何处理大数据？技术架构上采用了哪些策略？</strong></p> 
  <p>1、应用无状态(淘宝session框架)</p> 
  <p>2、有效使用缓存(Tair)</p> 
  <p>3、应用拆分(HSF)</p> 
  <p>4、数据库拆分(TDDL)</p> 
  <p>5、异步通信(Notify)</p> 
  <p>6、非结构化数据存储 ( TFS,NOSQL)</p> 
  <p>7、监控、预警系统</p> 
  <p>8、配置统一管理</p> 
  <p>看一下2018年双11当天的成交额。</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p1.pstatp.com/large/pgc-image/fa056bade9ff40cf82181ee7b0cdbdb6"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <h1><a name="t1"></a>二、kafka实现天猫亿万级数据统计架构</h1> 
  <p>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p9.pstatp.com/large/pgc-image/a708e67e537944db85cccd67849a2bfb"></p> 
  <p>&nbsp;</p> 
  <p><strong>Data Access：</strong>数据通道</p> 
  <p><strong>Computing：</strong>计算</p> 
  <p><strong>Persistence：</strong>执行保存方式</p> 
  <p><strong>spout：</strong>表示一个流的源头，产生tuple</p> 
  <p><strong>bolt：</strong>处理输入流并产生多个输出流，可以做简单的数据转换计算，复杂的流处理一般需要经过多个bolt进行处理。</p> 
  <p><strong>为什么不能用分布式文件HDFS集群？</strong></p> 
  <p><strong>1、实时性：</strong>hdfs的实时性没有kafka高。</p> 
  <p><strong>2、消费量的记录：</strong>hdfs不会记录你这个块文件消费到了哪里，而基于zookeeper的kafka会记录你消费的点。</p> 
  <p><strong>3、并发消费：</strong>hdfs不支持并发消费，而kafka支持并发消费，即多个consumer。</p> 
  <p><strong>4、弹性且有序：</strong>当数据量会很大，而且处理完之后就可以删除时，频繁的读写会对hdfs中NameNode造成很大的压力。而kafka的消费点是记录在zookeeper的，并且kafka的每条数据都是有“坐标”的，所以消费的时候只要这个“坐标”向后移动就行了，而且删除的时候只要把这个“坐标”之前的数据删掉即可。</p> 
  <h1><a name="t2"></a>三、什么是Kafka?</h1> 
  <p>&nbsp;</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p3.pstatp.com/large/pgc-image/160010f9908849769efaaf4f5182f0b6"></p> 
  <p>&nbsp;</p> 
  <p>通过上图就可以了解到，生产者Producers(农民和厨师)，消费主题top(鱼，骨头，草，香蕉),消费者Comsumer(猫，狗，老牛，猴子)，生产者根据消费主题获取自己想要的食物。</p> 
  <h1><a name="t3"></a>四、Kafka架构原理</h1> 
  <p>&nbsp;</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p3.pstatp.com/large/pgc-image/1e84a505a91b4616b253d007ad2236d4"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <h1><a name="t4"></a>五、Kafka能帮我们解决什么问题？</h1> 
  <p>请高手指明一下kafka解决了什么问题，什么场景下使用？消息订阅和发布吗，好像redis也支持，功能是否有重叠？</p> 
  <p><strong>1）、消息队列</strong></p> 
  <p>假设你意气风发，要开发新一代的互联网应用，以期在互联网事业中一展宏图。借助云计算，很容易开发出如下原型系统：</p> 
  <p>Web应用：部署在云服务器上，为个人电脑或者移动用户提供的访问体验。</p> 
  <p>SQL数据库：为Web应用提供数据持久化以及数据查询。</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p1.pstatp.com/large/pgc-image/e4cc83fa6ef642cc8546921198d388c7"></p> 
  <p>&nbsp;</p> 
  <p>这套架构简洁而高效，很快能够部署到百度云等云计算平台，以便快速推向市场。互联网不就是讲究小步快跑嘛！</p> 
  <p>可惜好景不长。随着用户的迅速增长，所有的访问都直接通过SQL数据库使得它不堪重负，不得不加上缓存服务以降低SQL数据库的荷载；为了理解用户行为，开始收集日志并保存到Hadoop上离线处理，同时把日志放在全文检索系统中以便快速定位问题；由于需要给投资方看业务状况，也需要把数据汇总到数据仓库中以便提供交互式报表。</p> 
  <p>此时的系统的架构已经盘根错节了，考虑将来还会加入实时模块以及外部数据交互，真是痛并快乐着……</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p1.pstatp.com/large/pgc-image/f1c9234842b649f881f14f0e41c2352d"></p> 
  <p>&nbsp;</p> 
  <p>这时候，应该跑慢一些，让灵魂跟上来。</p> 
  <p>本质上，这是一个数据集成问题。没有任何一个系统能够解决所有的事情，所以业务数据根据不同用途存而放在不同的系统，比如归档、分析、搜索、缓存等。数据冗余本身没有任何问题，但是不同系统之间像意大利面条一样复杂的数据同步却是挑战。</p> 
  <p>这时候就轮到Kafka出场了。</p> 
  <p>Kafka可以让合适的数据以合适的形式出现在合适的地方。<strong>Kafka的做法是提供消息队列，让生产者单往队列的末尾添加数据，让多个消费者从队列里面依次读取数据然后自行处理。</strong>之前连接的复杂度是O(N^2)，而现在降低到O(N)，扩展起来方便多了：</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p1.pstatp.com/large/pgc-image/dfef753fbaef40d194379902396fca36"></p> 
  <p>&nbsp;</p> 
  <p>在Kafka的帮助下，你的互联网应用终于能够支撑飞速增长的业务，成为下一个BAT指日可待。</p> 
  <p>以上故事说明了Kafka主要用途是数据集成，或者说是流数据集成，以Pub/Sub形式的消息总线形式提供。但是，Kafka不仅仅是一套传统的消息总线，本质上Kafka是分布式的流数据平台，因为以下特性而著名：</p> 
  <p><strong>·</strong>提供Pub/Sub方式的海量消息处理。</p> 
  <p><strong>·</strong>以高容错的方式存储海量数据流。</p> 
  <p><strong>·</strong>保证数据流的顺序。</p> 
  <p><strong>2）、日志采集</strong></p> 
  <p><strong>1.技术选型</strong></p> 
  <p>服务端日志采集主要通过在Controller的接口中进行埋点，然后通过AOP技术、Kafka消息系统以及logback对用户行为进行采集。之所以使用AOP技术是因为AOP的以下重要特定：</p> 
  <p><strong>·</strong>代码的侵入性小。对于业务代码的侵入性小，只需要在Controller的接口上添加注解，然后在其他模块对用户行为进行采集。</p> 
  <p><strong>·</strong>重用性。对于相同作用的代码可以进行重用。</p> 
  <p><strong>·</strong>扩展性。能够很好的对系统进行扩展。</p> 
  <p>由于使用异步方式对用户行为信息进行收集，因此需要使用消息中间件。目前消息中间件非常多，比较流行的有ActiveMQ、ZeroMQ、RabbitMQ、Kafka等。每个消息中间件都有各种的优势劣势，之所以使用Kafka消息中间件，是因为以下几点因素：</p> 
  <p><strong>·</strong>高性能。每秒钟可以处理数以千计生产者生成的消息。</p> 
  <p><strong>·</strong>高扩展性。可以通过简单的增加服务器横向扩展Kafka集群的容量。</p> 
  <p><strong>·</strong>分布式。消息来自数以千计的服务，使用分布式来解决单机处理海量数据的瓶颈。</p> 
  <p><strong>·</strong>持久性。Kafka中的消息可以持久化到硬盘上，这样可以防止数据的丢失。</p> 
  <p>因为用户的行为数据最终是以日志的形式持久化的，因此使用logback对日志持久化到日志服务器中。</p> 
  <p><strong>2.总体架构</strong></p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p1.pstatp.com/large/pgc-image/7ae5e75c9b254caa9f64f39a38f29257"></p> 
  <p>&nbsp;</p> 
  <p>服务端日志采集系统主要由两个工程组成：陆金所-bi-core和lu-bi-service。由于中国平安陆金所使用dubbo框架，因此有服务提供方和服务消费方。lu-bi-core被web、wap和mainsite服务消费方依赖。此外，lu-bi-service也依赖于lu-bi-core，主要是依赖于其中的一些实体类及工具类。</p> 
  <p>lu-bi-core工程为Kafka消息的生产者，主要封装实现切面的具体逻辑，其主要职责如下：</p> 
  <p><strong>·</strong>解析用户请求的Request信息：从Request中提取用户的基本信息，如设备型号、用户的供应商、ip、设备的分辨率、设备平台、设备的操作系统、设备id、app渠道等。</p> 
  <p><strong>·</strong>接口对应的参数：通过切面可以提取接口的参数值，从而知道用户的业务信息。</p> 
  <p><strong>·</strong>应用层返回的结果信息：因为切面使用AfterReturning方式，因此可以获取用层的返回结果，从返回结果中可以提取有用的信息。</p> 
  <p><strong>·</strong>用户的基本信息：用户的id信息。</p> 
  <p><strong>·</strong>信息格式化：将信息转化成JSON字符串。</p> 
  <p><strong>·</strong>发送消息：将最终需要发送的消息放入本地阻塞队列中，通过另一个线程异步从阻塞队列中获取消息并发送到Kafka Broker中。</p> 
  <p>lu-bi-service工程为Kafka消息的消费者，其主要职责如下：</p> 
  <p><strong>·</strong>实时从Kafka中拉取最新的数据。</p> 
  <p><strong>·</strong>将JSON字符串转化成，方便进一步对用信息进行加工。</p> 
  <p><strong>·</strong>对用户的ip进行解析，获取ip对应的地区以及经纬度信息。</p> 
  <p><strong>·</strong>将加工好的最终信息持久化到log文件中。</p> 
  <p><strong>3.部署图</strong></p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p1.pstatp.com/large/pgc-image/aa204cd616f04d139fbe8bcbddde7aba"></p> 
  <p>&nbsp;</p> 
  <p>上图为陆金所与日志系统系统相关的部署图，App、Wap和Mainsite服务器集群分别对应不同终端的应用。Kafka集群使用杭研的集群，目前有10个Broker。日志服务器有两台，通过Kafka的均衡策略对日志进行消费。</p> 
  <p><strong>4.日志采集的流程</strong></p> 
  <p>日志采集流程图如下所示：</p> 
  <p><img alt="Kafka实现淘宝亿万级数据统计" class="has" src="http://p3.pstatp.com/large/pgc-image/39527a3e582646259624de40077ab062"></p> 
  <p>&nbsp;</p> 
  <p>上图为消息生产者和消息消费者共同组成的流程图。</p> 
  <p>消息生产者的具体步骤如下：</p> 
  <p><strong>·</strong>通过切面拦截用户的请求。</p> 
  <p><strong>·</strong>从切面中提取请求头的基本信息，如设备信息，cookie信息，ip信息等。</p> 
  <p><strong>·</strong>提取请求的接口参数信息。</p> 
  <p><strong>·</strong>从接口返回值中提取相关信息，如id，pvid等。</p> 
  <p><strong>·</strong>将提取的信息封装成JSON字符串，放到阻塞队列中，假如阻塞队列溢出会有三次重试机制。</p> 
  <p><strong>·</strong>异步线程从本地阻塞队列中获取数据，并将信息组装发送到Kafka的Broker中，此时消息生产者结束。</p> 
  <p>消息消费者的具体步骤如下：</p> 
  <p><strong>·</strong>实时从Kafka Broker中批量拉取消息。</p> 
  <p><strong>·</strong>将拉取的消息转化成对象。</p> 
  <p><strong>·</strong>解析ip对应的国家、省份、城市、经纬度信息。</p> 
  <p><strong>·</strong>对不同业务场景的信息进一步解析。</p> 
  <p><strong>·</strong>将日志信息转化成JSON字符串，持久化到log文件中。</p> 
  <p><strong>5. 相关配置</strong></p> 
  <p><strong>·</strong>application-XXX.properties：该配置放Kafka的相关属性，包括topic、groupId、server等信息。</p> 
  <p><strong>·</strong>lu-log-msg.xml：该配置放在app-web，mainsite-web，wap-web的src/main/resources目录下，主要是初始化kafka生产者的信息。</p> 
  <p><strong>·</strong>lu-bi-service.xml：该配置放在lu-bi-service工程的src/main/resources目录下，主要用于加载kafka消费者的配置信息，并且启动kafka消费者服务。</p> 
  <p><strong>·</strong>logback.xml：该配置放在lu-bi-service工程的src/main/resources目录下，主要用于声明日志文件存放的目录，需要持久化的日志的package路径，以及日志持久化的格式。</p> 
  <p><strong>·</strong>ip_conf.txt：该配置放在lu-bi-service工程的src/main/resources目录下，用于解析ip对应的地域、经纬度等信息。</p> 
  <h1><a name="t5"></a>六、关于面试问题</h1> 
  <p><strong>Redis和Kafka区别？</strong></p> 
  <p>老师就跟大家举个例子：</p> 
  <p>老板有个好消息要告诉大家，公司要发放年终奖，有两个办法:</p> 
  <p>1.到会议室每个座位上挨个儿告诉每个人。什么？张三去上厕所了？那张三就只能错过好消息了！</p> 
  <p>2.老板把消息写到会议上的黑板报上，谁想知道就来看一下，什么？张三请假了？没关系，我一周之后才擦掉，总会看见的！什么张三请假两周？那就算了，我反正只保留一周，不然其他好消息没地方写了！</p> 
  <p>redis用第一种办法，kafka用第二种办法，知道什么区别了吧~</p> 
  <p><strong>Redis PUB/SUB使用场景：</strong></p> 
  <p>1. 消息持久性需求不高</p> 
  <p>2. 吞吐量要求不高</p> 
  <p>3. 可以忍受数据丢失</p> 
  <p>4. 数据量不大</p> 
  <p><strong>Kafka使用场景：</strong></p> 
  <p>上面以外的其他场景：</p> 
  <p>1. 高可靠性</p> 
  <p>2. 高吞吐量</p> 
  <p>3. 持久性高</p> 
  <p><strong>Kafka、RabbitMQ、RocketMQ等消息中间件的对比</strong></p> 
  <p>有关测试结论：</p> 
  <p>Kafka的吞吐量高达17.3w/s，不愧是高吞吐量消息中间件的行业老大。这主要取决于它的队列模式保证了写磁盘的过程是线性IO。此时broker磁盘IO已达瓶颈。</p> 
  <p>RocketMQ也表现不俗，吞吐量在11.6w/s，磁盘IO %util已接近100%。RocketMQ的消息写入内存后即返回ack，由单独的线程专门做刷盘的操作，所有的消息均是顺序写文件。</p> 
  <p>RabbitMQ的吞吐量5.95w/s，CPU资源消耗较高。它支持AMQP协议，实现非常重量级，为了保证消息的可靠性在吞吐量上做了取舍。我们还做了RabbitMQ在消息持久化场景下的性能测试，吞吐量在2.6w/s左右。</p> 
  <p><strong>所以在服务端处理同步发送的性能上，Kafka&gt;RocketMQ&gt;RabbitMQ</strong></p> 
  <blockquote>
   <strong>文章转自：</strong>https://gper.gupaoedu.com/articleContent?id=655
  </blockquote> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
