<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>cp2 Advanced HTML Parsing( including Regexpression ) « NotBeCN</title>
  <meta name="description" content="         ################################################################   from urllib.request import urlopen from bs4 import BeautifulSoup html=urlopen('ht...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/Linli522362242_90139705.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">cp2 Advanced HTML Parsing( including Regexpression )</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>################################################################</p> 
  <pre>
<span style="color:#7c79e5;"><strong>from urllib.request import urlopen from bs4 import BeautifulSoup html=urlopen('</strong></span><span><strong>http://www.pythonscraping.com/pages/page3.html</strong></span><span style="color:#7c79e5;"><strong>') bs=BeautifulSoup(html, 'html.parser')</strong></span></pre> 
  <p>#find_all(tag, attributes, recursive, text, limit, keywords)</p> 
  <p><span style="color:#7c79e5;"><strong>nameList =</strong></span><span><strong> bs.findAll('span', {'class':'green'})</strong></span></p> 
  <p><span style="color:#7c79e5;"><strong>for name in nameList: </strong></span></p> 
  <p><span style="color:#7c79e5;"><strong>&nbsp; &nbsp; &nbsp; print(</strong></span><span><strong>name.get_text()</strong></span><span style="color:#7c79e5;"><strong>)</strong></span></p> 
  <pre>
nameList = <span style="color:#7c79e5;"><strong>bs.find_all(text='the prince')########</strong></span>
print(len(nameList))</pre> 
  <p>for child in <span><strong>bs.find('table', {'id':'giftList'}).children</strong></span>:<br> &nbsp;&nbsp;&nbsp; print(child)</p> 
  <pre>
for sibling in <span><strong>bs.find('table', {'id':'giftList'}).tr.next_siblings</strong></span>:
    print(sibling)</pre> 
  <pre>
                     #&lt;img src="../img/gifts/img1.jpg"&gt;
print(<strong>bs.find('img', {'src':'../img/gifts/img1.jpg'}
             ).parent.previous_sibling.get_text()</strong>
            )<span style="color:#7c79e5;"><strong># $15.00</strong></span>

#&lt;td&gt;$15.00&lt;/td&gt;
#&lt;td&gt;&lt;img src="../img/gifts/img1.jpg"&gt;&lt;/td&gt;&lt;/tr&gt;</pre> 
  <pre>
images = bs.find_all('img', {'src':<span style="color:#7c79e5;"><strong>re.compile('\.\.\/img\/gifts\/img.*\.jpg'</strong></span>)})
#images = bs.find_all('img', {'src':<span style="color:#7c79e5;"><strong>re.compile('\.\.\/img\/gifts/img.*\.jpg'</strong></span>)})

for image in images:
    print(image['src'])</pre> 
  <p><img alt="" class="has" height="101" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512141141785.png" width="435"></p> 
  <p># the following retrieves <strong>all tags that have exactly two attributes</strong>:</p> 
  <pre>
print(
        bs.find_all(lambda tag: len(tag.attrs)==2)
)</pre> 
  <p>That is,<br> it will find tags with two attributes, such as the following:<br> &lt;div <strong>class</strong>="body" <strong>id</strong>="content"&gt;&lt;/div&gt;<br> &lt;span <strong>style</strong>="color:red" <strong>class</strong>="title"&gt;&lt;/span&gt;</p> 
  <p>################################################################</p> 
  <p>bs.find_all(lambda tag: tag.get_text() ==<br> 'Or maybe he\'s only resting?')</p> 
  <p>This can also be accomplished without a lambda function:<br> bs.find_all('', text='Or maybe he\'s only resting?')</p> 
  <p><img alt="" class="has" height="25" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512143528531.png" width="510"></p> 
  <p>################################################################</p> 
  <pre>
<span style="color:#7c79e5;"><strong>from urllib.request import urlopen from bs4 import BeautifulSoup</strong></span>

<span style="color:#7c79e5;"><strong>html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html') bs = BeautifulSoup(html.read(), 'html.parser')</strong></span>

#find_all(tag, attributes, recursive, text, limit, keywords)
<span style="color:#7c79e5;"><strong>nameList = bs.findAll('span', {'class':'green'})</strong></span>
for name in nameList:
    print(name.get_text())

<strong><span style="color:#7c79e5;">nameList = bs.find_all(text='the prince') ############</span></strong>
print(len(nameList))
</pre> 
  <h1><strong>Result:</strong></h1> 
  <p>http://www.pythonscraping.com/pages/warandpeace.html</p> 
  <p><img alt="" class="has" height="681" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512133937624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="805"></p> 
  <p>...</p> 
  <p><img alt="" class="has" height="590" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512134128808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="803"></p> 
  <p><img alt="" class="has" height="815" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512134220573.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="372"></p> 
  <p>################################################################</p> 
  <pre>
from urllib.request import urlopen
from bs4 import BeautifulSoup

<span style="color:#7c79e5;"><strong>html=urlopen('http://www.pythonscraping.com/pages/page3.html') bs=BeautifulSoup(html, 'html.parser')</strong></span>
                                                #.descendants
for child in <span style="color:#7c79e5;"><strong>bs.find('table', {'id':'giftList'}).children:</strong></span>
    print(child)</pre> 
  <h1><strong>Result:</strong></h1> 
  <p><img alt="" class="has" height="921" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512134844390.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><img alt="" class="has" height="983" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019051213492528.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="650"></p> 
  <pre>
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen('http://www.pythonscraping.com/pages/page3.html')
bs = BeautifulSoup(html, 'html.parser')

for sibling in bs.find('table', {'id':'giftList'}).tr.next_siblings:
    print(sibling)</pre> 
  <p>&nbsp;</p> 
  <p><strong>Result:</strong></p> 
  <p><img alt="" class="has" height="896" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512140351465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="698"></p> 
  <p><img alt="" class="has" height="1016" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512140442185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="643"></p> 
  <pre>
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen('http://www.pythonscraping.com/pages/page3.html')
bs = BeautifulSoup(html, 'html.parser')

                     #&lt;img src="../img/gifts/img1.jpg"&gt;
print(bs.find('img', {'src':'../img/gifts/img1.jpg'}
             ).parent.previous_sibling.get_text()
            )#   $15.00

#&lt;td&gt;$15.00&lt;/td&gt;
#&lt;td&gt;&lt;img src="../img/gifts/img1.jpg"&gt;&lt;/td&gt;&lt;/tr&gt;</pre> 
  <p><img alt="" class="has" height="62" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512140753309.png" width="455"></p> 
  <p><img alt="" class="has" height="311" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512141718684.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="647"></p> 
  <p><img alt="" class="has" height="106" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512142019727.png" width="669"></p> 
  <p><img alt="" class="has" height="57" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512142043440.png" width="431"></p> 
  <p><img alt="" class="has" height="351" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512142122816.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="656"></p> 
  <p><img alt="" class="has" height="128" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512142227256.png" width="663"></p> 
  <p><img alt="" class="has" height="721" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512141741216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="641"></p> 
  <p><img alt="" class="has" height="845" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512142348747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpbmxpNTIyMzYyMjQy,size_16,color_FFFFFF,t_70" width="542"></p> 
  <p><img alt="" class="has" height="30" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512142525339.png" width="369"></p> 
  <pre>
from urllib.request import urlopen
from bs4 import BeautifulSoup
import re

html = urlopen('http://www.pythonscraping.com/pages/page3.html')
bs = BeautifulSoup(html, 'html.parser')

images = bs.find_all('img', {'src':re.compile('\.\.\/img\/gifts\/img.*\.jpg')})

for image in images:
    print(image['src'])

print(
        #bs.find_all(lambda tag: len(tag.attrs)==2)
        bs.find_all(lambda tag: tag.get_text() == 'Or maybe he\'s only resting?')
)</pre> 
  <p><img alt="" class="has" height="160" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512143506177.png" width="514"></p> 
 </div> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
