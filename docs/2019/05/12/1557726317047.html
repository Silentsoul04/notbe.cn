<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>狼多肉少？从拉勾招聘看Python就业前景 « NotBeCN</title>
  <meta name="description" content="                  1.数据采集   事情的起源是这样的，某个风和日丽的下午… 习惯性的打开知乎准备划下水，看到一个问题刚好邀请回答      于是就萌生了采集下某招聘网站Python岗位招聘的信息，看一下目前的薪水和岗位分布，说干就干。   先说下数据采集过程中遇到的问题，首先请求头是一定要伪装...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/1557726317047.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">狼多肉少？从拉勾招聘看Python就业前景</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="1_0"></a>1.数据采集</h2> 
  <p>事情的起源是这样的，某个风和日丽的下午… 习惯性的打开知乎准备划下水，看到一个问题刚好邀请回答</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-f051f93e84e120ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>于是就萌生了采集下某招聘网站Python岗位招聘的信息，看一下目前的薪水和岗位分布，说干就干。</p> 
  <p>先说下数据采集过程中遇到的问题，首先请求头是一定要伪装的，否则第一步就会给你弹出<strong>你的请求太频繁，请稍后再试</strong>，其次网站具有多重反爬策略，解决方案是每次先获取session然后更新我们的session进行抓取，最后拿到了想要的数据。</p> 
  <p>Chrome浏览器右键检查查看<strong>network</strong>，找到链接<code>https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false</code></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-8d3d308af8e41ff9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>可以看到返回的数据正是页面的Python招聘详情，于是我直接打开发现直接提示<code>{"status":false,"msg":"您操作太频繁,请稍后再访问","clientIp":"124.77.161.207","state":2402}</code>，机智的我察觉到事情并没有那么简单<img src="https://upload-images.jianshu.io/upload_images/13090773-327019c5e401f457.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <blockquote> 
   <p><strong>大家在学python的时候肯定会遇到很多难题，以及对于新技术的追求，这里推荐一下我们的Python学习扣qun：784758214，这里是python学习者聚集地！！同时，自己是一名高级python开发工程师，从基础的python脚本到web开发、爬虫、django、数据挖掘等，零基础到项目实战的资料都有整理。送给每一位python的小伙伴！每日分享一些学习的方法和需要注意的小细节</strong></p> 
  </blockquote> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-2d9795e33164f8d4.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>真正的较量才刚刚开始，我们先来分析下请求的报文，</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-eefcd4f90bbd9c79.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-36d56931a17179d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>可以看到请求是以<code>post</code>的方式传递的，同时传递了参数</p> 
  <pre><code>datas = {
            'first': 'false',
            'pn': x,
            'kd': 'python',
        }

</code></pre> 
  <p>同时不难发现每次点击下一页都会同时发送一条<code>get</code>请求</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-946486838c8a5797.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-a47d00abbd45f641.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>经过探索，发现这个<code>get</code>请求和我们<code>post</code>请求是一致的，那么问题就简单许多，整理一下思路<img src="https://upload-images.jianshu.io/upload_images/13090773-f0ba475e1f0070fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><strong>关键词：</strong><code>python</code> **搜索范围：**全国 **数据时效：**2019.05.05</p> 
  <pre><code>#!/usr/bin/env python3.4
# encoding: utf-8
"""
Created on 19-5-05
@title: ''
@author: Xusl
"""
import json
import requests
import xlwt
import time

# 获取存储职位信息的json对象，遍历获得公司名、福利待遇、工作地点、学历要求、工作类型、发布时间、职位名称、薪资、工作年限
def get_json(url, datas):
    my_headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36",
        "Referer": "https://www.lagou.com/jobs/list_Python?city=%E5%85%A8%E5%9B%BD&amp;cl=false&amp;fromSearch=true&amp;labelWords=&amp;suginput=",
        "Content-Type": "application/x-www-form-urlencoded;charset = UTF-8"
    }
    time.sleep(5)
    ses = requests.session()    # 获取session
    ses.headers.update(my_headers)  # 更新
    ses.get("https://www.lagou.com/jobs/list_python?city=%E5%85%A8%E5%9B%BD&amp;cl=false&amp;fromSearch=true&amp;labelWords=&amp;suginput=")
    content = ses.post(url=url, data=datas)
    result = content.json()
    info = result['content']['positionResult']['result']
    info_list = []
    for job in info:
        information = []
        information.append(job['positionId'])  # 岗位对应ID
        information.append(job['city'])  # 岗位对应城市
        information.append(job['companyFullName'])  # 公司全名
        information.append(job['companyLabelList'])  # 福利待遇
        information.append(job['district'])  # 工作地点
        information.append(job['education'])  # 学历要求
        information.append(job['firstType'])  # 工作类型
        information.append(job['formatCreateTime'])  # 发布时间
        information.append(job['positionName'])  # 职位名称
        information.append(job['salary'])  # 薪资
        information.append(job['workYear'])  # 工作年限
        info_list.append(information)
        # 将列表对象进行json格式的编码转换,其中indent参数设置缩进值为2
        # print(json.dumps(info_list, ensure_ascii=False, indent=2))
    # print(info_list)
    return info_list

def main():
    page = int(input('请输入你要抓取的页码总数：'))
    # kd = input('请输入你要抓取的职位关键字：')
    # city = input('请输入你要抓取的城市：')

    info_result = []
    title = ['岗位id', '城市', '公司全名', '福利待遇', '工作地点', '学历要求', '工作类型', '发布时间', '职位名称', '薪资', '工作年限']
    info_result.append(title)
    for x in range(1, page+1):
        url = 'https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'
        datas = {
            'first': 'false',
            'pn': x,
            'kd': 'python',
        }
        try:
            info = get_json(url, datas)
            info_result = info_result + info
            print("第%s页正常采集" % x)
        except Exception as msg:
            print("第%s页出现问题" % x)

        # 创建workbook,即excel
        workbook = xlwt.Workbook(encoding='utf-8')
        # 创建表,第二参数用于确认同一个cell单元是否可以重设值
        worksheet = workbook.add_sheet('lagouzp', cell_overwrite_ok=True)
        for i, row in enumerate(info_result):
            # print(row)
            for j, col in enumerate(row):
                # print(col)
                worksheet.write(i, j, col)
        workbook.save('lagouzp.xls')

if __name__ == '__main__':
    main()

</code></pre> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-21d46c7be011c4d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-7ea22bd0ee627cf7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>当然存储于excel当然是不够的，之前一直用<code>matplotlib</code>做数据可视化，这次换个新东西<code>pyecharts</code>。</p> 
  <h2><a id="2pyecharts_148"></a>2.了解pyecharts</h2> 
  <p>pyecharts是一款将python与echarts结合的强大的数据可视化工具，包含多种图表</p> 
  <ul> 
   <li>Bar（柱状图/条形图）</li> 
   <li>Bar3D（3D 柱状图）</li> 
   <li>Boxplot（箱形图）</li> 
   <li>EffectScatter（带有涟漪特效动画的散点图）</li> 
   <li>Funnel（漏斗图）</li> 
   <li>Gauge（仪表盘）</li> 
   <li>Geo（地理坐标系）</li> 
   <li>Graph（关系图）</li> 
   <li>HeatMap（热力图）</li> 
   <li>Kline（K线图）</li> 
   <li>Line（折线/面积图）</li> 
   <li>Line3D（3D 折线图）</li> 
   <li>Liquid（水球图）</li> 
   <li>Map（地图）</li> 
   <li>Parallel（平行坐标系）</li> 
   <li>Pie（饼图）</li> 
   <li>Polar（极坐标系）</li> 
   <li>Radar（雷达图）</li> 
   <li>Sankey（桑基图）</li> 
   <li>Scatter（散点图）</li> 
   <li>Scatter3D（3D 散点图）</li> 
   <li>ThemeRiver（主题河流图）</li> 
   <li>WordCloud（词云图）</li> 
  </ul> 
  <p><strong>用户自定义</strong></p> 
  <ul> 
   <li>Grid 类：并行显示多张图</li> 
   <li>Overlap 类：结合不同类型图表叠加画在同张图上</li> 
   <li>Page 类：同一网页按顺序展示多图</li> 
   <li>Timeline 类：提供时间线轮播多张图</li> 
  </ul> 
  <p>另外需要注意的是从版本0.3.2 开始，为了缩减项目本身的体积以及维持 pyecharts 项目的轻量化运行，pyecharts 将不再自带地图 js 文件。如用户需要用到地图图表（Geo、Map），可自行安装对应的地图文件包。</p> 
  <blockquote> 
   <ol> 
    <li><a href="https://link.juejin.im?target=https%3A%2F%2Fecharts-maps.github.io%2Fecharts-countries-js%2F" rel="nofollow">全球国家地图</a>:&nbsp;<a href="https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fpyecharts%2Fecharts-countries-pypkg" rel="nofollow">echarts-countries-pypkg</a>&nbsp;(1.9MB): 世界地图和 213 个国家，包括中国地图</li> 
    <li><a href="https://link.juejin.im?target=https%3A%2F%2Fecharts-maps.github.io%2Fecharts-china-provinces-js%2F" rel="nofollow">中国省级地图</a>:&nbsp;<a href="https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fpyecharts%2Fecharts-china-provinces-pypkg" rel="nofollow">echarts-china-provinces-pypkg</a>&nbsp;(730KB)：23 个省，5 个自治区</li> 
    <li><a href="https://link.juejin.im?target=https%3A%2F%2Fecharts-maps.github.io%2Fecharts-china-cities-js%2F" rel="nofollow">中国市级地图</a>:&nbsp;<a href="https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fpyecharts%2Fecharts-china-cities-pypkg" rel="nofollow">echarts-china-cities-pypkg</a>&nbsp;(3.8MB)：370 个中国城市</li> 
   </ol> 
  </blockquote> 
  <p><strong>也可以使用命令进行安装</strong></p> 
  <pre><code>pip install echarts-countries-pypkg
pip install echarts-china-provinces-pypkg
pip install echarts-china-cities-pypkg

</code></pre> 
  <h2><a id="3_198"></a>3.数据可视化（代码+展示）</h2> 
  <ul> 
   <li><strong>各城市招聘数量</strong></li> 
  </ul> 
  <pre><code>from pyecharts import Bar

city_nms_top10 = ['北京', '上海', '深圳', '成都', '杭州', '广州', '武汉', '南京', '苏州', '郑州', '天津', '西安', '东莞', '珠海', '合肥', '厦门', '宁波',
                  '南宁', '重庆', '佛山', '大连', '哈尔滨', '长沙', '福州', '中山']
city_nums_top10 = [149, 95, 77, 22, 17, 17, 16, 13, 7, 5, 4, 4, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]

bar = Bar("Python岗位", "各城市数量")
bar.add("数量", city_nms, city_nums, is_more_utils=True)
# bar.print_echarts_options() # 该行只为了打印配置项，方便调试时使用
bar.render('Python岗位各城市数量.html')  # 生成本地 HTML 文件

</code></pre> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-053d0073fe3df26f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <ul> 
   <li><strong>地图分布展示（这个场景意义不大，不过多分析）</strong></li> 
  </ul> 
  <pre><code>from pyecharts import Geo

city_datas = [('北京', 149), ('上海', 95), ('深圳', 77), ('成都', 22), ('杭州', 17), ('广州', 17), ('武汉', 16), ('南京', 13), ('苏州', 7),
     ('郑州', 5), ('天津', 4), ('西安', 4), ('东莞', 3), ('珠海', 2), ('合肥', 2), ('厦门', 2), ('宁波', 1), ('南宁', 1), ('重庆', 1),
     ('佛山', 1), ('大连', 1), ('哈尔滨', 1), ('长沙', 1), ('福州', 1), ('中山', 1)]
geo = Geo("Python岗位城市分布地图", "数据来源拉勾", title_color="#fff",
                  title_pos="center", width=1200,
                  height=600, background_color='#404a59')
attr, value = geo.cast(city_datas)
geo.add("", attr, value, visual_range=[0, 200], visual_text_color="#fff",
                symbol_size=15, is_visualmap=True)
geo.render("Python岗位城市分布地图_scatter.html")

geo = Geo("Python岗位城市分布地图", "数据来源拉勾", title_color="#fff",
                  title_pos="center", width=1200,
                  height=600, background_color='#404a59')
        attr, value = geo.cast(city_datas)
        geo.add("", attr, value, type="heatmap", visual_range=[0, 10], visual_text_color="#fff",
                symbol_size=15, is_visualmap=True)
        geo.render("Python岗位城市分布地图_heatmap.html")

</code></pre> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-fcb4c06994456117.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-291da4ede3df6877.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <ul> 
   <li><strong>各个城市招聘情况</strong></li> 
  </ul> 
  <pre><code>from pyecharts import Pie

city_nms_top10 = ['北京', '上海', '深圳', '成都', '广州', '杭州', '武汉', '南京', '苏州', '郑州']
city_nums_top10 = [149, 95, 77, 22, 17, 17, 16, 13, 7, 5]
pie = Pie()
pie.add("", city_nms_top10, city_nums_top10, is_label_show=True)
# pie.show_config()
pie.render('Python岗位各城市分布饼图.html')

</code></pre> 
  <p><img src="https://upload-images.jianshu.io/upload_images/13090773-eded085e08f5db31.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p><strong>北上深</strong>的岗位明显碾压其它城市，这也反映出为什么越来越多的it从业人员毕业以后相继奔赴一线城市，除了一线城市的薪资高于二三线这个因素外，还有一个最重要的原因<strong>供需关系</strong>，因为一线岗位多，可选择性也就比较高，反观二三线的局面，很有可能你跳个几次槽，发现同行业能呆的公司都待过了…</p> 
  <ul> 
   <li><strong>薪资范围</strong><img src="https://upload-images.jianshu.io/upload_images/13090773-b250ac37432cfaf0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></li> 
  </ul> 
  <p>由此可见，python的岗位薪资多数在10k~20k，想从事Python行业的可以把工作年限和薪资结合起来参考一下。</p> 
  <ul> 
   <li><strong>学历要求 + 工作年限</strong><img src="https://upload-images.jianshu.io/upload_images/13090773-0b1d67602dfc9739.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></li> 
  </ul> 
  <p>从工作年限来看，1-3年或者3-5年工作经验的招聘比较多，而应届生和一年以下的寥寥无几，对实习生实在不太友好，学历也普遍要求本科，多数公司都很重视入职人员学历这点毋容置疑，虽然学历不代表一切，但是对于一个企业来说，想要短时间内判断一个人的能力，最快速有效的方法无疑是从学历入手。学历第一关，面试第二关。</p> 
  <p>但是，这不代表学历不高的人就没有好的出路，现在的大学生越来越多，找工作也越来越难，竞争越来越激烈，即使具备高学历，也不能保证你一定可以找到满意的工作，天道酬勤，<strong>特别是it这个行业，知识的迭代，比其他行业来的更频密。不断学习，拓展自己学习的广度和深度，才是最正确的决定。</strong></p> 
  <p><strong>就业寒冬来临，我们需要的是理性客观的看待，而不是盲目地悲观或乐观。从以上数据分析，如果爱好Python，仍旧可以入坑，不过要注意一个标签有工作经验，就算没有工作经验，自己在学习Python的过程中一定要尝试独立去做一个完整的项目，爬虫也好，数据分析也好，亦或者是开发，都要尝试独立去做一套系统，在这个过程中培养自己思考和解决问题的能力。持续不断的学习，才是对自己未来最好的投资，也是度过寒冬最正确的姿势。</strong></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
