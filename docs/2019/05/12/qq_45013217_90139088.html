<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>python机器学习案例系列教程——LightGBM算法 « NotBeCN</title>
  <meta name="description" content="                     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;       ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/qq_45013217_90139088.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">python机器学习案例系列教程——LightGBM算法</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <div class="markdown_views" id="content_views">
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   <!-- flowchart &#31661;&#22836;&#22270;&#26631; &#21247;&#21024; -->&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
   <div class="markdown_views" id="content_views">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    <!-- flowchart &amp;#31661;&amp;#22836;&amp;#22270;&amp;#26631; &amp;#21247;&amp;#21024; -->&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    <h2 id="安装"><a></a><a target="_blank"></a>安装</h2>
    <pre class="prettyprint"><code class="hljs cmake has-numbering">pip <span class="hljs-keyword">install</span> lightgbm</code>
     <div class="hljs-button {2}"></div>
     <ul class="pre-numbering">
      <li>1</li>
     </ul>
     <ul class="pre-numbering">
      <li>1</li>
     </ul></pre>
    <p>gitup网址：<a href="https://github.com/Microsoft/LightGBM" rel="nofollow" target="_blank">https://github.com/Microsoft/LightGBM</a></p>
    <h2 id="中文教程"><a></a><a target="_blank"></a>中文教程</h2>
    <p><a href="http://lightgbm.apachecn.org/cn/latest/index.html" rel="nofollow" target="_blank">http://lightgbm.apachecn.org/cn/latest/index.html</a></p>
    <h2 id="lightgbm简介"><a></a><a target="_blank"></a>lightGBM简介</h2>
    <p>xgboost的出现，让数据民工们告别了传统的机器学习算法们：RF、GBM、SVM、LASSO……..。现在微软推出了一个新的boosting框架，想要挑战xgboost的江湖地位。</p>
    <p>顾名思义，lightGBM包含两个关键点：light即轻量级，GBM 梯度提升机。</p>
    <p>LightGBM 是一个梯度 boosting 框架，使用基于学习算法的决策树。它可以说是分布式的，高效的，有以下优势：</p>
    <ul>
     <li><p>更快的训练效率</p></li>
     <li><p>低内存使用</p></li>
     <li><p>更高的准确率</p></li>
     <li><p>支持并行化学习</p></li>
     <li><p>可处理大规模数据</p></li>
    </ul>
   </div>
   <p>如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击<a href="http://www.captainbed.net/csdn" rel="nofollow" target="_blank">这里</a>可以查看教程。</p>
   <h2 id="xgboost缺点"><a></a><a target="_blank"></a>xgboost缺点</h2>
   <p>其缺点，或者说不足之处：</p>
   <p>每轮迭代时，都需要遍历整个训练数据多次。如果把整个训练数据装进内存则会限制训练数据的大小；如果不装进内存，反复地读写训练数据又会消耗非常大的时间。</p>
   <p>预排序方法（pre-sorted）：首先，空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如排序后的索引，为了后续快速的计算分割点），这里需要消耗训练数据两倍的内存。其次时间上也有较大的开销，在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。</p>
   <p>对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss。</p>
   <h2 id="lightgbm特点"><a></a><a target="_blank"></a>lightGBM特点</h2>
   <p>以上与其说是xgboost的不足，倒不如说是lightGBM作者们构建新算法时着重瞄准的点。解决了什么问题，那么原来模型没解决就成了原模型的缺点。</p>
   <p>概括来说，lightGBM主要有以下特点：</p>
   <ul>
    <li><p>基于Histogram的决策树算法</p></li>
    <li><p>带深度限制的Leaf-wise的叶子生长策略</p></li>
    <li><p>直方图做差加速</p></li>
    <li><p>直接支持类别特征(Categorical Feature)</p></li>
    <li><p>Cache命中率优化</p></li>
    <li><p>基于直方图的稀疏特征优化</p></li>
    <li><p>多线程优化</p></li>
   </ul>
   <p>前2个特点使我们尤为关注的。</p>
   <p><strong>Histogram算法</strong></p>
   <p>直方图算法的基本思想：先把连续的浮点特征值离散化成k个整数，同时构造一个宽度为k的直方图。遍历数据时，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。</p>
   <p><strong>带深度限制的Leaf-wise的叶子生长策略</strong></p>
   <p>Level-wise过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，也好控制模型复杂度，不容易过拟合。但实际上Level-wise是一种低效算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p>
   <p>Leaf-wise则是一种更为高效的策略：每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。</p>
   <p>Leaf-wise的缺点：可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度限制，在保证高效率的同时防止过拟合。</p>
   <h2 id="xgboost和lightgbm"><a></a><a target="_blank"></a>xgboost和lightgbm</h2>
   <p><strong>决策树算法</strong></p>
   <p>XGBoost使用的是pre-sorted算法，能够更精确的找到数据分隔点；</p>
   <ul>
    <li>首先，对所有特征按数值进行预排序。</li>
    <li>其次，在每次的样本分割时，用O(# data)的代价找到每个特征的最优分割点。</li>
    <li>最后，找到最后的特征以及分割点，将数据分裂成左右两个子节点。 </li>
   </ul>
   <p>优缺点： </p>
   <p>这种pre-sorting算法能够准确找到分裂点，但是在空间和时间上有很大的开销。 </p>
   <ul>
    <li>i. 由于需要对特征进行预排序并且需要保存排序后的索引值（为了后续快速的计算分裂点），因此内存需要训练数据的两倍。 </li>
    <li>ii. 在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。</li>
   </ul>
   <p>LightGBM使用的是histogram算法，占用的内存更低，数据分隔的复杂度更低。</p>
   <p>其思想是将连续的浮点特征离散成k个离散值，并构造宽度为k的Histogram。然后遍历训练数据，统计每个离散值在直方图中的累计统计量。在进行特征选择时，只需要根据直方图的离散值，遍历寻找最优的分割点。</p>
   <p>Histogram 算法的优缺点：</p>
   <ul>
    <li>Histogram算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在实际的数据集上表明，离散化的分裂点对最终的精度影响并不大，甚至会好一些。原因在于decision tree本身就是一个弱学习器，采用Histogram算法会起到正则化的效果，有效地防止模型的过拟合。</li>
    <li>时间上的开销由原来的<code>O(#data * #features)</code>降到<code>O(k * #features)</code>。由于离散化，<code>#bin</code>远小于<code>#data</code>，因此时间上有很大的提升。</li>
    <li>Histogram算法还可以进一步加速。一个叶子节点的Histogram可以直接由父节点的Histogram和兄弟节点的Histogram做差得到。一般情况下，构造Histogram需要遍历该叶子上的所有数据，通过该方法，只需要遍历Histogram的k个捅。速度提升了一倍。 </li>
   </ul>
   <p><strong>决策树生长策略</strong></p>
   <p>XGBoost采用的是按层生长level（depth）-wise生长策略，如Figure 1所示，能够同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合；但不加区分的对待同一层的叶子，带来了很多没必要的开销。因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。 </p>
   <p><img title="" alt="这里写图片描述" src="http://5b0988e595225.cdn.sohucs.com/images/20171123/ce94828e7b7a4580a59a0f91d95e5f83.png"></p>
   <p>LightGBM采用leaf-wise生长策略，如Figure 2所示，每次从当前所有叶子中找到分裂增益最大（一般也是数据量最大）的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。 </p>
   <p><img title="" alt="这里写图片描述" src="http://5b0988e595225.cdn.sohucs.com/images/20171123/0159a3990a544d00a6cd025d9a33b499.png"></p>
   <p><strong>网络通信优化</strong></p>
   <p>XGBoost由于采用pre-sorted算法，通信代价非常大，所以在并行的时候也是采用histogram算法；LightGBM采用的histogram算法通信代价小，通过使用集合通信算法，能够实现并行计算的线性加速。</p>
   <p><strong>LightGBM支持类别特征</strong></p>
   <p>实际上大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征，转化one-hotting特征，降低了空间和时间的效率。而类别特征的使用是在实践中很常用的。基于这个考虑，LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的0/1展开。并在决策树算法上增加了类别特征的决策规则。</p>
   <h2 id="lightgbm调参"><a></a><a target="_blank"></a>lightGBM调参</h2>
   <p>所有的参数含义，参考：<a href="http://lightgbm.apachecn.org/cn/latest/Parameters.html" rel="nofollow" target="_blank">http://lightgbm.apachecn.org/cn/latest/Parameters.html</a></p>
   <p>调参过程：</p>
   <p>（1）num_leaves</p>
   <p>LightGBM使用的是leaf-wise的算法，因此在调节树的复杂程度时，使用的是num_leaves而不是max_depth。</p>
   <p>大致换算关系：num_leaves = 2^(max_depth)</p>
   <p>（2）样本分布非平衡数据集：可以param[‘is_unbalance’]=’true’</p>
   <p>（3）Bagging参数：bagging_fraction+bagging_freq（必须同时设置）、feature_fraction</p>
   <p>（4）min_data_in_leaf、min_sum_hessian_in_leaf</p>
   <h2 id="sklearn接口形式的lightgbm示例"><a></a><a target="_blank"></a>sklearn接口形式的LightGBM示例</h2>
   <p>这里主要以sklearn的使用形式来使用lightgbm算法，包含建模，训练，预测，网格参数优化。</p>
   <pre class="prettyprint"><code class="hljs python has-numbering"><span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span>&nbsp; make_classification<span class="hljs-comment"># 加载数据</span>print(<span class="hljs-string">'Load data...'</span>)iris = load_iris()data=iris.datatarget = iris.targetX_train,X_test,y_train,y_test =train_test_split(data,target,test_size=<span class="hljs-number">0.2</span>)<span class="hljs-comment"># df_train = pd.read_csv('../regression/regression.train', header=None, sep='\t')</span><span class="hljs-comment"># df_test = pd.read_csv('../regression/regression.test', header=None, sep='\t')</span><span class="hljs-comment"># y_train = df_train[0].values</span><span class="hljs-comment"># y_test = df_test[0].values</span><span class="hljs-comment"># X_train = df_train.drop(0, axis=1).values</span><span class="hljs-comment"># X_test = df_test.drop(0, axis=1).values</span>print(<span class="hljs-string">'Start training...'</span>)<span class="hljs-comment"># 创建模型，训练模型</span>gbm = lgb.LGBMRegressor(objective=<span class="hljs-string">'regression'</span>,num_leaves=<span class="hljs-number">31</span>,learning_rate=<span class="hljs-number">0.05</span>,n_estimators=<span class="hljs-number">20</span>)gbm.fit(X_train, y_train,eval_set=[(X_test, y_test)],eval_metric=<span class="hljs-string">'l1'</span>,early_stopping_rounds=<span class="hljs-number">5</span>)print(<span class="hljs-string">'Start predicting...'</span>)<span class="hljs-comment"># 测试机预测</span>y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)<span class="hljs-comment"># 模型评估</span>print(<span class="hljs-string">'The rmse of prediction is:'</span>, mean_squared_error(y_test, y_pred) ** <span class="hljs-number">0.5</span>)<span class="hljs-comment"># feature importances</span>print(<span class="hljs-string">'Feature importances:'</span>, list(gbm.feature_importances_))<span class="hljs-comment"># 网格搜索，参数优化</span>estimator = lgb.LGBMRegressor(num_leaves=<span class="hljs-number">31</span>)param_grid = {&nbsp;&nbsp;&nbsp; <span class="hljs-string">'learning_rate'</span>: [<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>],&nbsp;&nbsp;&nbsp; <span class="hljs-string">'n_estimators'</span>: [<span class="hljs-number">20</span>, <span class="hljs-number">40</span>]}gbm = GridSearchCV(estimator, param_grid)gbm.fit(X_train, y_train)print(<span class="hljs-string">'Best parameters found by grid search are:'</span>, gbm.best_params_)</code>
    <div class="hljs-button {2}"></div>
    <ul class="pre-numbering">
     <li>1</li>
     <li>2</li>
     <li>3</li>
     <li>4</li>
     <li>5</li>
     <li>6</li>
     <li>7</li>
     <li>8</li>
     <li>9</li>
     <li>10</li>
     <li>11</li>
     <li>12</li>
     <li>13</li>
     <li>14</li>
     <li>15</li>
     <li>16</li>
     <li>17</li>
     <li>18</li>
     <li>19</li>
     <li>20</li>
     <li>21</li>
     <li>22</li>
     <li>23</li>
     <li>24</li>
     <li>25</li>
     <li>26</li>
     <li>27</li>
     <li>28</li>
     <li>29</li>
     <li>30</li>
     <li>31</li>
     <li>32</li>
     <li>33</li>
     <li>34</li>
     <li>35</li>
     <li>36</li>
     <li>37</li>
     <li>38</li>
     <li>39</li>
     <li>40</li>
     <li>41</li>
     <li>42</li>
     <li>43</li>
     <li>44</li>
     <li>45</li>
     <li>46</li>
     <li>47</li>
     <li>48</li>
     <li>49</li>
     <li>50</li>
    </ul>
    <ul class="pre-numbering">
     <li>1</li>
    </ul></pre>
   <h2 id="原生形式使用lightgbm"><a></a><a target="_blank"></a>原生形式使用lightgbm</h2>
   <pre class="prettyprint"><code class="hljs python has-numbering"><span class="hljs-comment"># coding: utf-8</span><span class="hljs-comment"># pylint: disable = invalid-name, C0111</span><span class="hljs-keyword">import</span> json<span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span>&nbsp; make_classificationiris = load_iris()data=iris.datatarget = iris.targetX_train,X_test,y_train,y_test =train_test_split(data,target,test_size=<span class="hljs-number">0.2</span>)<span class="hljs-comment"># 加载你的数据</span><span class="hljs-comment"># print('Load data...')</span><span class="hljs-comment"># df_train = pd.read_csv('../regression/regression.train', header=None, sep='\t')</span><span class="hljs-comment"># df_test = pd.read_csv('../regression/regression.test', header=None, sep='\t')</span><span class="hljs-comment">#</span><span class="hljs-comment"># y_train = df_train[0].values</span><span class="hljs-comment"># y_test = df_test[0].values</span><span class="hljs-comment"># X_train = df_train.drop(0, axis=1).values</span><span class="hljs-comment"># X_test = df_test.drop(0, axis=1).values</span><span class="hljs-comment"># 创建成lgb特征的数据集格式</span>lgb_train = lgb.Dataset(X_train, y_train)lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)<span class="hljs-comment"># 将参数写成字典下形式</span>params = {&nbsp;&nbsp;&nbsp; <span class="hljs-string">'task'</span>: <span class="hljs-string">'train'</span>,&nbsp;&nbsp;&nbsp; <span class="hljs-string">'boosting_type'</span>: <span class="hljs-string">'gbdt'</span>,&nbsp; <span class="hljs-comment"># 设置提升类型</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'objective'</span>: <span class="hljs-string">'regression'</span>, <span class="hljs-comment"># 目标函数</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'metric'</span>: {<span class="hljs-string">'l2'</span>, <span class="hljs-string">'auc'</span>},&nbsp; <span class="hljs-comment"># 评估函数</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'num_leaves'</span>: <span class="hljs-number">31</span>,&nbsp;&nbsp; <span class="hljs-comment"># 叶子节点数</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.05</span>,&nbsp; <span class="hljs-comment"># 学习速率</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'feature_fraction'</span>: <span class="hljs-number">0.9</span>, <span class="hljs-comment"># 建树的特征选择比例</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'bagging_fraction'</span>: <span class="hljs-number">0.8</span>, <span class="hljs-comment"># 建树的样本采样比例</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'bagging_freq'</span>: <span class="hljs-number">5</span>,&nbsp; <span class="hljs-comment"># k 意味着每 k 次迭代执行bagging</span>&nbsp;&nbsp;&nbsp; <span class="hljs-string">'verbose'</span>: <span class="hljs-number">1</span> <span class="hljs-comment"># &lt;0 显示致命的, =0 显示错误 (警告), &gt;0 显示信息</span>}print(<span class="hljs-string">'Start training...'</span>)<span class="hljs-comment"># 训练 cv and train</span>gbm = lgb.train(params,lgb_train,num_boost_round=<span class="hljs-number">20</span>,valid_sets=lgb_eval,early_stopping_rounds=<span class="hljs-number">5</span>)print(<span class="hljs-string">'Save model...'</span>)<span class="hljs-comment"># 保存模型到文件</span>gbm.save_model(<span class="hljs-string">'model.txt'</span>)print(<span class="hljs-string">'Start predicting...'</span>)<span class="hljs-comment"># 预测数据集</span>y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)<span class="hljs-comment"># 评估模型</span>print(<span class="hljs-string">'The rmse of prediction is:'</span>, mean_squared_error(y_test, y_pred) ** <span class="hljs-number">0.5</span>)</code>
    <div class="hljs-button {2}"></div>
    <ul class="pre-numbering">
     <li>1</li>
     <li>2</li>
     <li>3</li>
     <li>4</li>
     <li>5</li>
     <li>6</li>
     <li>7</li>
     <li>8</li>
     <li>9</li>
     <li>10</li>
     <li>11</li>
     <li>12</li>
     <li>13</li>
     <li>14</li>
     <li>15</li>
     <li>16</li>
     <li>17</li>
     <li>18</li>
     <li>19</li>
     <li>20</li>
     <li>21</li>
     <li>22</li>
     <li>23</li>
     <li>24</li>
     <li>25</li>
     <li>26</li>
     <li>27</li>
     <li>28</li>
     <li>29</li>
     <li>30</li>
     <li>31</li>
     <li>32</li>
     <li>33</li>
     <li>34</li>
     <li>35</li>
     <li>36</li>
     <li>37</li>
     <li>38</li>
     <li>39</li>
     <li>40</li>
     <li>41</li>
     <li>42</li>
     <li>43</li>
     <li>44</li>
     <li>45</li>
     <li>46</li>
     <li>47</li>
     <li>48</li>
     <li>49</li>
     <li>50</li>
     <li>51</li>
     <li>52</li>
     <li>53</li>
     <li>54</li>
     <li>55</li>
     <li>56</li>
     <li>57</li>
     <li>58</li>
    </ul>
    <ul class="pre-numbering">
     <li>1</li>
    </ul></pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  </div> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
