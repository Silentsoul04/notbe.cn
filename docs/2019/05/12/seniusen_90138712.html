<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>RCAN——Image Super-Resolution Using Very Deep Residual Channel Attention Networks « NotBeCN</title>
  <meta name="description" content="                   1. 摘要       在图像超分辨领域，卷积神经网络的深度非常重要，但过深的网络却难以训练。低分辨率的输入以及特征包含丰富的低频信息，但却在通道间被平等对待，因此阻碍了网络的表示能力。          为了解决上述问题，作者提出了一个深度残差通道注意力网络（RCAN）。特...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/seniusen_90138712.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">RCAN——Image Super-Resolution Using Very Deep Residual Channel Attention Networks</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h3><a id="1__0"></a>1. 摘要</h3> 
  <blockquote> 
   <p>在图像超分辨领域，卷积神经网络的深度非常重要，但过深的网络却难以训练。低分辨率的输入以及特征包含丰富的低频信息，但却在通道间被平等对待，因此阻碍了网络的表示能力。</p> 
  </blockquote> 
  <blockquote> 
   <p>为了解决上述问题，作者提出了一个深度残差通道注意力网络（RCAN）。特别地，作者设计了一个残差中的残差（RIR）结构来构造深层网络，每个 RIR 结构由数个残差组（RG）以及长跳跃连接（LSC）组成，每个 RG 则包含一些残差块和短跳跃连接（SSC）。</p> 
  </blockquote> 
  <blockquote> 
   <p>RIR 结构允许丰富的低频信息通过多个跳跃连接直接进行传播，使主网络专注于学习高频信息。此外，我们还提出了一种通道注意力机制（CA），通过考虑通道之间的相互依赖性来自适应地重新调整特征。</p> 
  </blockquote> 
  <h3><a id="2__8"></a>2. 介绍</h3> 
  <p>网络的深度在许多视觉识别任务中展示了非常重要的作用，特别是在 ResNet 引入残差块之后，最近许多图像超分辨效果的重大提升都是基于网络表示的深度来改进的。</p> 
  <p>但是，另一方面，现在的大多数 CNN 都平等对待特征的每一个通道，这无疑缺少处理不同类型信息的灵活度。图像超分辨是为了尽可能多地恢复高频信息，而低分辨率的图片却包含着许多可以直接被传播到输出的低频信息，因此，特征的所有通道如果被平等对待则会使网络缺乏辨别学习能力。</p> 
  <p>基于上面的分析，作者提出了一个 RIR（Residual In Residual）架构，其中 RG（Residual Group）作为基本模块，LSC（Long Skip Connection）则用来进行粗略的残差学习，在每个 RG 内部则叠加数个简单的残差块和 SSC（Short Skip Connection）。LSC、SSC 和残差块内部的短连接可以允许丰富的低频信息直接通过恒等映射向后传播，这可以保证信息的流动，加速网络的训练。</p> 
  <p>进一步，作者提出了通道注意力（Channel Attention）机制，通过对特征通道之间的相互依赖性建模来自适应地重新缩放每个通道的特征。实验证明，这种机制允许网络专注于更有用的信道并增强辨别学习能力。</p> 
  <h3><a id="3__18"></a>3. 网络结构</h3> 
  <h4><a id="31_CA_20"></a>3.1. CA</h4> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-4725d2e1c1835f1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>如上图所示，输入是一个 H×W×C 的特征，我们先进行一个空间的全局平均池化得到一个 1×1×C 的通道描述。接着，再经过一个下采样层和一个上采样层得到每一个通道的权重系数，将权重系数和原来的特征相乘即可得到缩放后的新特征，整个过程实际上就是对不同通道的特征重新进行了加权分配。</p> 
  <p>其中，下采样和上采样层都利用 1×1 的卷积来实现，下采样层的通道数减少 r 倍，激活函数为 Relu，上采样层的激活函数为 Sigmoid。在论文中，作者采用的通道数 C=64，r = 16。</p> 
  <h4><a id="32_RCAB_28"></a>3.2. RCAB</h4> 
  <p>RCAB 就是将 CA 和残差思想融合在一起。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-fb7aa16a51b21af0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>输入一个特征 input，我们首先进行一个卷积-Relu-卷积操作得到 f，然后 f 再经过一个 CA 模块进行重新缩放得到 x，最后将 x 和 input 相加得到输出特征。其中，卷积操作都采用 3×3 的卷积核。</p> 
  <p>RCAB 的一个 TensorFlow 实现如下所示：</p> 
  <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">RCAB</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> reduction<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" @Image super-resolution using very deep residual channel attention networks Residual Channel Attention Block """</span>

    batch<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> channel <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, C)</span>
    f <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> channel<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, C)</span>
    f <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>f<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, C)</span>

    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>f<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># (B, 1, 1, C)</span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> channel <span class="token operator">//</span> reduction<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span>  <span class="token comment"># (B, 1, 1, C // r)</span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">)</span>  <span class="token comment"># (B, 1, 1, C)</span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">)</span>  <span class="token comment"># (B, W, H, C)</span>

    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>

    <span class="token keyword">return</span> x
</code></pre> 
  <h4><a id="33_RG_59"></a>3.3. RG</h4> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-5128784e2ad40168.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>一个 RG 则由 B 个 RCAB、一个卷积层和一个 SSC 组成，在本文中，B 取 20。</p> 
  <h4><a id="34_RCAN_65"></a>3.4. RCAN</h4> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-c00c5a49da92d407.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>输入一个低分辨率图片，先经过一个 3×3 的卷积提取特征 F，然后经过一个 RIR 模块：包含 10 个 RG、一个 3×3 的卷积和一个 LSC，最后是一个上采样层和一个 3×3 的卷积层，上采样层采取 ESPCNN。网络的损失函数是 L1 损失。</p> 
  <h3><a id="4__71"></a>4. 实验结果</h3> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-424eb30d743fff95.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>可以看到，如果移除 LSC 和 SSC 的话，无论有没有引入 CA 实验结果都很差，而添加这些跳跃连接后，模型的整体性能都会有所提升，说明 LSC 和 SSC 非常有效。同时，在同样的条件下，引入 CA 后模型性能也有所提升，验证了注意力机制的有效性。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-ddd62d33c3ac160f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>在几个数据集上的测试结果，也表明 RCAN 取得了比以往方法更好的效果。如果采用几个模型集成的话，效果还能再提升，如上面 RCAN+ 所示。</p> 
  <p>一个主观的超分辨效果如下所示，可以看到 RCAN 恢复出了更多的细节和纹理。</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-e1188aeea2cd861d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
  <p>获取更多精彩，请关注「seniusen」!</p> 
  <p><img src="https://upload-images.jianshu.io/upload_images/11895466-ee82f7655f20bfeb.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
