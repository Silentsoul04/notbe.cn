<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>李宏毅ML-02-Where does the error come from? 误差分析 « NotBeCN</title>
  <meta name="description" content="                  Where does the error come from?      Outline       误差分析：bias 和 variance    Cross Validation交叉验证         1 误差分析   1.1 两种误差   一般的，我们把误差分为两类： ...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/weixin_43238442_90138534.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">李宏毅ML-02-Where does the error come from? 误差分析</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="Where_does_the_error_come_from_0"></a>Where does the error come from?</h2> 
  <hr> 
  <h3><a id="Outline_2"></a>Outline</h3> 
  <ul> 
   <li>误差分析：bias 和 variance</li> 
   <li>Cross Validation交叉验证</li> 
  </ul> 
  <hr> 
  <h3><a id="1__7"></a>1 误差分析</h3> 
  <h4><a id="11__8"></a>1.1 两种误差</h4> 
  <p>一般的，我们把误差分为两类：</p> 
  <ul> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           b
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           s
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          bias
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span>偏差：指的是预测值的期望和真实值之间的偏差，表现了预测值的偏移程度；</li> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           v
          </mi>
          <mi>
           a
          </mi>
          <mi>
           r
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
          <mi>
           c
          </mi>
          <mi>
           e
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          variance
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">c</span><span class="mord mathit">e</span></span></span></span></span>方差：指的是预测数据的离散程度，和真实值无关。<br> 这两种误差分别对应着训练模型的不同问题。</li> 
  </ul> 
  <h4><a id="12__14"></a>1.2 误差和模型的关系</h4> 
  <ul> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           b
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           s
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          bias
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span><br> 模型越复杂<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           b
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           s
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          bias
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span>一般越小，在training set上表现越好, 拟合效果越好；同时受到training data的影响越大以至于最后<strong>overfitting</strong>；</li> 
   <li><span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           v
          </mi>
          <mi>
           a
          </mi>
          <mi>
           r
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
          <mi>
           c
          </mi>
          <mi>
           e
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          variance
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">c</span><span class="mord mathit">e</span></span></span></span></span><br> 模型越简单平滑，波动越小，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           v
          </mi>
          <mi>
           a
          </mi>
          <mi>
           r
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
          <mi>
           c
          </mi>
          <mi>
           e
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          variance
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">c</span><span class="mord mathit">e</span></span></span></span></span>越小；但是模型过于简单，预测结果虽然不离散但是<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           b
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           s
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          bias
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span>较大-<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           u
          </mi>
          <mi>
           n
          </mi>
          <mi>
           d
          </mi>
          <mi>
           e
          </mi>
          <mi>
           r
          </mi>
          <mi>
           f
          </mi>
          <mi>
           i
          </mi>
          <mi>
           t
          </mi>
          <mi>
           t
          </mi>
          <mi>
           i
          </mi>
          <mi>
           n
          </mi>
          <mi>
           g
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          underfitting
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8888799999999999em; vertical-align: -0.19444em;"></span><span class="mord mathit">u</span><span class="mord mathit">n</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit" style="margin-right: 0.10764em;">f</span><span class="mord mathit">i</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mord mathit" style="margin-right: 0.03588em;">g</span></span></span></span></span><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512112508138.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzIzODQ0Mg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 所以要在两种<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           e
          </mi>
          <mi>
           r
          </mi>
          <mi>
           r
          </mi>
          <mi>
           o
          </mi>
          <mi>
           r
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          error
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span></span></span></span></span>中找到平衡。</li> 
  </ul> 
  <h4><a id="13__22"></a>1.3 如何对待误差</h4> 
  <h5><a id="131_23"></a>1.3.1分辨误差</h5> 
  <ul> 
   <li>如果model能在training data上有不好的结果，取得了较大的<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           e
          </mi>
          <mi>
           r
          </mi>
          <mi>
           r
          </mi>
          <mi>
           o
          </mi>
          <mi>
           r
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          error
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span></span></span></span></span>，model可能具有较大的<span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           b
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           s
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          bias
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span>；我们称之为<strong>欠拟合，under fitting</strong>。</li> 
   <li>如果模型在training set 上取地了较好的结果但是在test set上误差很大，model可能具有较大的 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
       <math>
        <semantics>
         <mrow>
          <mi>
           v
          </mi>
          <mi>
           a
          </mi>
          <mi>
           r
          </mi>
          <mi>
           i
          </mi>
          <mi>
           a
          </mi>
          <mi>
           n
          </mi>
          <mi>
           c
          </mi>
          <mi>
           e
          </mi>
         </mrow>
         <annotation encoding="application/x-tex">
          variance
         </annotation>
        </semantics>
       </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">c</span><span class="mord mathit">e</span></span></span></span></span>，我们称之为<strong>过拟合，over fitting</strong>。</li> 
  </ul> 
  <h5><a id="132_27"></a>1.3.2如何减小误差</h5> 
  <ul> 
   <li>Large Variance</li> 
   <li>使用更多的数据：更多的数据是最要好的方法，足够的数据可以提供足够的信息；试想如果我们的training set包括了所有可能的数据那么训练出的模型就是适用于所有test set的。</li> 
   <li>正则化Regularization：前面的笔记中已经提到了，正则化可以帮助我们的到比较平滑的曲线，减小曲线的震荡程度；</li> 
   <li>Large Bias</li> 
   <li>使用更多的 feature 作为input；</li> 
   <li>重新设计更复杂的model；</li> 
  </ul> 
  <h4><a id="_36"></a>小结</h4> 
  <p>上面的关系总结一下就是<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          b
         </mi>
         <mi>
          i
         </mi>
         <mi>
          a
         </mi>
         <mi>
          s
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         bias
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span>：大-欠拟合，prefer较复杂的model；<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          v
         </mi>
         <mi>
          a
         </mi>
         <mi>
          r
         </mi>
         <mi>
          i
         </mi>
         <mi>
          a
         </mi>
         <mi>
          n
         </mi>
         <mi>
          c
         </mi>
         <mi>
          e
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         variance
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathit" style="margin-right: 0.03588em;">v</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right: 0.02778em;">r</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">c</span><span class="mord mathit">e</span></span></span></span></span>：大-过拟合，prefer较平滑的model；</p> 
  <hr> 
  <h3><a id="2_Cross_Validation_41"></a>2 Cross Validation</h3> 
  <p>为什么使用交叉验证？在评估模型好坏时，我们会使用test set，想看看model在检验集上表现得如何。但是每个test set不可能都是很完美的取样，训练集大多与现实中的数据之间有<span class="katex--inline"><span class="katex"><span class="katex-mathml">
      <math>
       <semantics>
        <mrow>
         <mi>
          b
         </mi>
         <mi>
          i
         </mi>
         <mi>
          a
         </mi>
         <mi>
          s
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         bias
        </annotation>
       </semantics>
      </math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span></span>（不是围绕数据中心的均匀取样）。所以这时候我们使用交叉验证来解决。</p> 
  <h4><a id="21__43"></a>2.1 简单交叉验证</h4> 
  <ul> 
   <li>我们随机的将training set分为两份，一份用于训练一份用于检验，这样就得到一个model即其准确率；</li> 
   <li>将数据打乱后重复第一步又能得到一个model及其准确率；</li> 
   <li>反复一二两步我们就能得到很多model，选择其中准确率最高的，再使用全体training set对其train一次产出我们的最终模型。</li> 
  </ul> 
  <h3><a id="22_Kfold_Cross_Validation_48"></a>2.2 K-fold Cross Validation</h3> 
  <p>将数据分为k份，k-1份用于训练生于一份用于test就得到了k个model。 选择最优的model，让其在整个training set上train一遍后得到最终的model。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
