<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>分布式爬虫实践（附带源码地址） « NotBeCN</title>
  <meta name="description" content="                       分布式爬虫优点：           可以充分利用多台机器的带宽      可以充分利用多台机器的ip地址（同一个局域网内用的还是一个，分布式没有用）      多台机器做，爬取效率更高          分布式爬虫需要解决的问题           分布式爬虫是好几...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://notbe.cn/2019/05/12/qq_39884947_90137651.html">
  <link rel="alternate" type="application/rss+xml" title="NotBeCN" href="https://notbe.cn/feed.xml" />
</head>


  <body>

    <div class="header-placeholder"></div>
<header class="header">
  <div class="wrapper">
    <div id="sidebar-toggle">TOC</div>
    <a class="site-title" href="/">NotBeCN</a>
    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/" target="_blank">关于</a>
      
        
        <a class="page-link" href="https://uzshare.com" target="_blank">社区</a>
      
        
        <a class="page-link" href="/donate/" target="_blank">Donate</a>
      
        
        <a class="page-link" href="/games/shejiyazi/" target="_blank">射个鸭子</a>
      
    </nav>
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">分布式爬虫实践（附带源码地址）</h1>
    <p class="post-meta">May 12, 2019</p>
  </header>

  <article class="post-content">
    <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-tomorrow-night-eighties"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <ul> 
   <li>分布式爬虫优点： 
    <ol> 
     <li>可以充分利用多台机器的带宽</li> 
     <li>可以充分利用多台机器的ip地址（同一个局域网内用的还是一个，分布式没有用）</li> 
     <li>多台机器做，爬取效率更高</li> 
    </ol> </li> 
   <li>分布式爬虫需要解决的问题 
    <ol> 
     <li>分布式爬虫是好几台机器在同时运行，如何保证不同的机器爬取页面的时候不会出现重复爬取的问题</li> 
     <li>同样，分布式爬虫在不同的机器上运行，如何把数据爬完后保证保存在同一个老地方<br></li> 
    </ol> </li> 
  </ul> 
  <p>scrapy-redis是一个组件不是框架，可以集成到scrapy框架中，使得爬虫可以进行分布式。可以充分的利用资源</p> 
  <pre><code>pip install scrapy-redis
</code></pre> 
  <p>编写scraoy-redis分布式爬虫：<br> 只要在基础的scrapy项目中修改以下三点就可以（基础的scrpay项目可以运行再修改为最佳）</p> 
  <ol> 
   <li>将scrapy.Spider变成scrapy_redis.spider.RedisSpider；或者是从scrapy.CrawlSpider变成scrapy_redis.spider.RedisCrawlSpider</li> 
   <li>将爬虫的start_urls删掉增加一个redis_key="XXX"这个是为了以后指明从redis上的key读取url</li> 
   <li>在setting文件配置项中添加如下配置</li> 
  </ol> 
  <pre><code>#确保再爬取过程中去重
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"
#确保request存储到redis
SCHEDULER = "scrapy_redis.scheduler.Scheduler"
#数据不消失（暂停 重启）
SCHEDULER_PERSIST = True
ITEM_PIPELINES = {
    'scrapy_redis.pipelines.RedisPipeline': 400,#数据存储在redis的pipeline中共享一个存储
}
REDIS_HOST=''
REDIS_PORT=''
</code></pre> 
  <ol start="4"> 
   <li>启动爬虫分为两个步骤 
    <ol> 
     <li>scrapy crawl spider 让爬虫就绪</li> 
     <li>在redis中输入lpush XXX urls让爬虫从这个url开始爬取（xxx 为上方第二个步骤redis_key urls为开始爬取的url地址）</li> 
    </ol> </li> 
  </ol> 
  <p><font size="4" color="blaci">以下是利用分布式爬取房天下的租房信息:</font><br> item.py文件：</p> 
  <pre><code># -*- coding: utf-8 -*-

# Define here the models for your scraped items
#
# See documentation in:
# https://doc.scrapy.org/en/latest/topics/items.html

import scrapy


class FangtianxiaItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    province=scrapy.Field()
    city=scrapy.Field()
    name=scrapy.Field()
    price=scrapy.Field()
    rooms=scrapy.Field()
    area=scrapy.Field()
    address=scrapy.Field()
    sale=scrapy.Field()
    origin_url=scrapy.Field()
class ESFItem(scrapy.Item):
    province = scrapy.Field()
    city = scrapy.Field()
    name = scrapy.Field()
    price = scrapy.Field()
    rooms = scrapy.Field()
    floor=scrapy.Field()
    toward=scrapy.Field()
    area = scrapy.Field()
    address = scrapy.Field()
    year=scrapy.Field()
    unity=scrapy.Field()
    origin_url = scrapy.Field()
</code></pre> 
  <p>spider.py文件(一部分修改成分布式的具体代码)</p> 
  <pre><code>mport scrapy
import re
from fangtianxia.items import FangtianxiaItem,ESFItem
from scrapy_redis.spiders import RedisSpider#导入scrapy-redis包
class SfwSpider(RedisSpider):#修改继承的类
    name = 'sfw'
    allowed_domains = ['fang.com']
    #start_urls = ['https://www.fang.com/SoufunFamily.html']
    #修改起始url地址
    redis_key = "fang:start_urls"#从这里读取url 随遗取即可
    def parse(self, response):
        trs=response.xpath("//div[@class='outCont']//tr")
        province=None
        for tr in trs:
            tds=tr.xpath(".//td[not(@class)]")
            province_td=tds[0]
            province_text=province_td.xpath(".//text()").get()
            province_text=re.sub(r"\s","",province_text)
            if province_text:
                province=province_text
            if province=='其它':
                #如果爬取的是海外城市则不进行爬取
                continue
            city_td=tds[1]
            city_links=city_td.xpath(".//a")
            for city_link in city_links:
                city=city_link.xpath(".//text()").get()
                city_url=city_link.xpath('.//@href').get()
                module=city_url.split('.')
                one = module[0]
                mid = module[1]
                last = module[2]
                newhouse_url=one + '.newhouse.' + mid + '.' + last + 'house/s/'
                esf_url=one+'.esf.'+mid+'.'+last
                if 'bj' in one:
                    newhouse_url='https://newhouse.fang.com/house/s/'
                    esf_url='https://esf.fang.com/'
                yield scrapy.Request(url=newhouse_url,callback=self.parse_newhouse,meta={'info':(province,city)})
                yield scrapy.Request(url=esf_url,callback=self.parse_esf,meta={'info':(province,city)},dont_filter=True)
    def parse_newhouse(self,response):
    	pass
    def parse_esf(self,response):
		pass
</code></pre> 
  <p>setting.py文件(针对scrapy-redis自u改的代码)</p> 
  <pre><code>#确保再爬取过程中去重
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"
#确保request存储到redis
SCHEDULER = "scrapy_redis.scheduler.Scheduler"
#使用队列的形式
SCHEDULER_QUEUE_CLASS = "scrapy_redis.queue.SpiderQueue"
#数据不消失（暂停 重启）
SCHEDULER_PERSIST = True
#SCHEDULER_QUEUE_CLASS = "scrapy_redis.queue.SpiderPriorityQueue"
#SCHEDULER_QUEUE_CLASS = "scrapy_redis.queue.SpiderQueue"
#SCHEDULER_QUEUE_CLASS = "scrapy_redis.queue.SpiderStack"

ITEM_PIPELINES = {
    'scrapy_redis.pipelines.RedisPipeline': 400,
    #也可自加一些pipelines文件
}
#redis的ip地址和端口
REDIS_HOST='XXXXX'
REDIS_PORT='xxx'
LOG_LEVEL = 'DEBUG'
</code></pre> 
  <p><font size="4" color="blac">完整代码已分享与<a href="https://github.com/BinXiaoEr/fangtianxia_spider" rel="nofollow">github</a>上请自行浏览fork</font></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>
  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="https://uzstatic-360cdn.belost.xyz/theme/default/images/logo.png" alt="柚子社区">
  <div class="col-box-title name">NotBeCN</div>
  <!-- <p>最新资讯</p> -->
  <p class="contact">
    
    <a href="mailto:fandyvon@163.com" target="_blank">邮箱</a>
    
    <a href="https://uzshare.com" target="_blank">柚子社区</a>
    
    <a href="https://uzzz.org" target="_blank">找组织</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">最新</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/2019/05/14/zxh1220_90138586.html">[原创软件] [软件发布] 定时备份文件发送邮箱，不再怕数据丢失了</a></li>
    
      <li><a class="post-link" href="/2019/05/14/weixin_45037290_90140056.html">Get智能写作满月记 ——产品篇</a></li>
    
      <li><a class="post-link" href="/2019/05/14/nulio__90138386.html">《深度探索C++对象模型》..............</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_41248707_90140031.html">mysql 多表联查之连接查询</a></li>
    
      <li><a class="post-link" href="/2019/05/13/qq_21122683_90125902.html">golang基础(二)</a></li>
    
      <li><a class="post-link" href="/2019/05/13/1557726108256.html">今日份的PTA刷题</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90137366.html">Android之折线图</a></li>
    
      <li><a class="post-link" href="/2019/05/12/zzzfffei_90136638.html">Android之实现选中时改变样式</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">目录</div>
</div>

<div class="col-box">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <!-- right_sidebar -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-8889449066804352"
       data-ad-slot="2081363239"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2019 
</div>
</footer>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$']]}});</script>
<script src="/js/easybook.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123344652-5');
</script>


<script data-ad-client="ca-pub-8889449066804352" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = true;
  hm.src = "https://hm.baidu.com/hm.js?9b378145d7399199b371d067f4c8be96";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




  </body>

</html>
